<<<<<<< HEAD
## - https://shorturl.at/SduTO
## ë°ì´í„°
## - https://shorturl.at/toAqE
## - https://shorturl.at/4LiWF
---
# ğŸ“˜ **3ë¶€. ìŠ¤ë§ˆíŠ¸ í—¬ìŠ¤ ê°œìš” ë° ê¸°ë°˜ ê¸°ìˆ **

# ğŸ“— **1ì¥. ìŠ¤ë§ˆíŠ¸ í—¬ìŠ¤ë€ ë¬´ì—‡ì¸ê°€**


## ğŸ”¹ 1. ìŠ¤ë§ˆíŠ¸ í—¬ìŠ¤ì˜ ì •ì˜ ë° ë“±ì¥ ë°°ê²½

ìŠ¤ë§ˆíŠ¸ í—¬ìŠ¤(Smart Health)ë€ ì •ë³´í†µì‹ ê¸°ìˆ (ICT), ì¸ê³µì§€ëŠ¥(AI), IoT ì„¼ì„œ, ë¹…ë°ì´í„° ë“±ì„ í™œìš©í•˜ì—¬ ê°œì¸ ë§ì¶¤í˜• ê±´ê°• ê´€ë¦¬ì™€ ì˜ˆë°© ì¤‘ì‹¬ì˜ í—¬ìŠ¤ì¼€ì–´ ì„œë¹„ìŠ¤ë¥¼ ì œê³µí•˜ëŠ” íŒ¨ëŸ¬ë‹¤ì„ì…ë‹ˆë‹¤. ê¸°ì¡´ì˜ ë³‘ì› ì¤‘ì‹¬ ì¹˜ë£Œ ìœ„ì£¼ì—ì„œ ë²—ì–´ë‚˜, **ì–¸ì œ ì–´ë””ì„œë‚˜ ê±´ê°• ì •ë³´ë¥¼ ìˆ˜ì§‘Â·ë¶„ì„í•˜ê³ , ì‹¤ì‹œê°„ìœ¼ë¡œ í”¼ë“œë°±ì„ ì œê³µ**í•¨ìœ¼ë¡œì¨ ì˜ˆë°©ê³¼ ìê¸° ì£¼ë„ ê±´ê°•ê´€ë¦¬ë¥¼ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤.

### â–ª ì£¼ìš” ë°°ê²½

* **ê³ ë ¹í™” ì‚¬íšŒì˜ ë„ë˜**: ë§Œì„±ì§ˆí™˜ ì¦ê°€ì™€ ì˜ë£Œë¹„ ë¶€ë‹´ ì¦ê°€
* **ICT ê¸°ìˆ  ë°œì „**: IoT ì„¼ì„œ, ì›¨ì–´ëŸ¬ë¸” ë””ë°”ì´ìŠ¤ ë³´ê¸‰
* **ë°ì´í„° ê¸°ë°˜ ì˜ë£Œ**: EHR, PHR, ì›¨ì–´ëŸ¬ë¸” ë¡œê·¸ ë“± ë‹¤ì–‘í•œ ì˜ë£Œ ë°ì´í„°
* **ì˜ë£Œ ìì›ì˜ ë¶ˆê· í˜•**: ì§€ì—­ ê°„ ì˜ë£Œ ì ‘ê·¼ì„± ê²©ì°¨ í•´ì†Œ í•„ìš”ì„±

---

## ğŸ”¹ 2. ê¸°ì¡´ í—¬ìŠ¤ì¼€ì–´ì™€ ìŠ¤ë§ˆíŠ¸ í—¬ìŠ¤ì˜ ë¹„êµ

| êµ¬ë¶„     | ê¸°ì¡´ í—¬ìŠ¤ì¼€ì–´      | ìŠ¤ë§ˆíŠ¸ í—¬ìŠ¤                  |
| ------ | ------------ | ----------------------- |
| ì¤‘ì‹¬ ë°©ì‹  | ë³‘ì› ë°©ë¬¸, ì§„ë£Œ ì¤‘ì‹¬ | ë¹„ëŒ€ë©´, ì‹¤ì‹œê°„ ë°ì´í„° ê¸°ë°˜         |
| ì‚¬ìš©ì ì—­í•  | ìˆ˜ë™ì (ì˜ì‚¬ ì£¼ë„)   | ëŠ¥ë™ì (ì‚¬ìš©ì ìŠ¤ìŠ¤ë¡œ ê±´ê°• ê´€ë¦¬)      |
| ë°ì´í„° ìˆ˜ì§‘ | ë³‘ì› ë‚´ ê²€ì‚¬      | ì„¼ì„œ, ì›¨ì–´ëŸ¬ë¸”, ìŠ¤ë§ˆíŠ¸í° ë“± ì‹¤ì‹œê°„ ìˆ˜ì§‘ |
| ê¸°ìˆ  í™œìš©  | ì œí•œì  (EMR ë“±)  | IoT, AI, ë¹…ë°ì´í„°, í´ë¼ìš°ë“œ í™œìš©  |
| ëª©ì      | ì§ˆë³‘ ì§„ë‹¨ ë° ì¹˜ë£Œ   | ì˜ˆë°©, ì¡°ê¸° ë°œê²¬, ê±´ê°• ì¦ì§„        |

---

## ğŸ”¹ 3. ìŠ¤ë§ˆíŠ¸ í—¬ìŠ¤ êµ¬ì„± ìš”ì†Œ

ìŠ¤ë§ˆíŠ¸ í—¬ìŠ¤ëŠ” ì—¬ëŸ¬ ê¸°ìˆ ê³¼ ì‹œìŠ¤í…œì´ í†µí•©ì ìœ¼ë¡œ ì‘ë™í•˜ì—¬ ê°œì¸ì˜ ê±´ê°•ì„ ê´€ë¦¬í•©ë‹ˆë‹¤. êµ¬ì„± ìš”ì†ŒëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.

| êµ¬ì„± ìš”ì†Œ            | ì„¤ëª…                                  |
| ---------------- | ----------------------------------- |
| **IoT ì„¼ì„œ/ë””ë°”ì´ìŠ¤**  | ì‹¬ë°•ìˆ˜, ìš´ë™ëŸ‰, ìˆ˜ë©´ ë“±ì„ ì‹¤ì‹œê°„ ì¸¡ì •í•˜ëŠ” ì›¨ì–´ëŸ¬ë¸” ê¸°ê¸°    |
| **ë°ì´í„° ìˆ˜ì§‘ ë° í†µì‹ **  | BLE, WiFi, NB-IoT ë“± ë‹¤ì–‘í•œ ë°©ì‹ìœ¼ë¡œ ë°ì´í„° ì „ì†¡ |
| **í—¬ìŠ¤ ë°ì´í„° í”Œë«í¼**   | ìˆ˜ì§‘ëœ ë°ì´í„°ë¥¼ í†µí•© ì €ì¥, ë¶„ì„ ê°€ëŠ¥í•œ í™˜ê²½           |
| **AI/ML ë¶„ì„ ê¸°ìˆ **  | ê±´ê°• ìƒíƒœ ì˜ˆì¸¡, ì´ìƒ ì§•í›„ ê°ì§€ ë“± ì§€ëŠ¥í˜• ë¶„ì„ ìˆ˜í–‰      |
| **í”¼ë“œë°± ë° ì•Œë¦¼ ì‹œìŠ¤í…œ** | ì‚¬ìš©ì ë§ì¶¤í˜• ê±´ê°• ë¦¬í¬íŠ¸, ê²½ê³  ë©”ì‹œì§€ ì œê³µ           |

---

## ğŸ”¹ 4. ìŠ¤ë§ˆíŠ¸ í—¬ìŠ¤ ê¸°ìˆ  ë°œì „ ì—°í‘œ

| ì—°ë„        | ì£¼ìš” ë°œì „ ë‚´ìš©                               |
| --------- | -------------------------------------- |
| 2010ë…„ëŒ€ ì´ˆë°˜ | ì›¨ì–´ëŸ¬ë¸” ê¸°ê¸°(ì˜ˆ: Fitbit, Jawbone) ìƒìš©í™”        |
| 2014ë…„     | ì• í”Œ í—¬ìŠ¤í‚·(HealthKit), êµ¬ê¸€ í•(Google Fit) ì¶œì‹œ |
| 2016ë…„     | ë”¥ëŸ¬ë‹ ê¸°ë°˜ í”¼ë¶€ë³‘, ì•ˆì € ë¶„ì„ ê¸°ìˆ  ìƒìš©í™”               |
| 2020ë…„ ì´í›„  | ì½”ë¡œë‚˜19 ëŒ€ì‘ ë¹„ëŒ€ë©´ ì§„ë£Œ, ìŠ¤ë§ˆíŠ¸ ë³‘ì› í™•ì‚°             |
| 2023ë…„ ì´í›„  | ìƒì²´ì‹ í˜¸ ê¸°ë°˜ ìŠ¤íŠ¸ë ˆìŠ¤, ìˆ˜ë©´, ì‹¬í˜ˆê´€ ë¦¬ìŠ¤í¬ ì˜ˆì¸¡ ì†”ë£¨ì…˜ ë“±ì¥    |

---

# ğŸ“— **2ì¥. ìŠ¤ë§ˆíŠ¸ í—¬ìŠ¤ë¥¼ ìœ„í•œ ë°ì´í„° ì´í•´**



## ğŸ”¹ 1. í—¬ìŠ¤ì¼€ì–´ ë°ì´í„°ì˜ ìœ í˜•

ìŠ¤ë§ˆíŠ¸ í—¬ìŠ¤ì—ì„œ í™œìš©ë˜ëŠ” ë°ì´í„°ëŠ” ë§¤ìš° ë‹¤ì–‘í•˜ë©°, ê°ê¸° ë‹¤ë¥¸ í˜•ì‹ê³¼ íŠ¹ì„±ì„ ê°€ì§‘ë‹ˆë‹¤. ëŒ€í‘œì ì¸ í—¬ìŠ¤ì¼€ì–´ ë°ì´í„°ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.

| ë°ì´í„° ìœ í˜•                              | ì„¤ëª…                      | ì˜ˆì‹œ                           |
| ----------------------------------- | ----------------------- | ---------------------------- |
| **EMR (Electronic Medical Record)** | ë³‘ì› ë‚´ì—ì„œ ìˆ˜ì§‘ë˜ëŠ” í™˜ì ì§„ë£Œ ê¸°ë¡    | ì§„ë‹¨ì½”ë“œ, íˆ¬ì•½ ë‚´ì—­, ê²€ì‚¬ ê²°ê³¼ ë“±         |
| **EHR (Electronic Health Record)**  | ì—¬ëŸ¬ ê¸°ê´€ ê°„ ê³µìœ  ê°€ëŠ¥í•œ ì˜ë£Œê¸°ë¡     | EMR + ìƒí™œìŠµê´€, ë°±ì‹ , ì˜ìƒ ë“±         |
| **PHR (Personal Health Record)**    | ê°œì¸ì´ ìˆ˜ì§‘/ê´€ë¦¬í•˜ëŠ” ê±´ê°• ë°ì´í„°      | ìŠ¤ë§ˆíŠ¸ì›Œì¹˜, ì•± ê¸°ë°˜ ìê°€ ê¸°ë¡ ë“±          |
| **ìƒì²´ì‹ í˜¸ (Biosignals)**               | ì‹ ì²´ ê¸°ëŠ¥ì—ì„œ ì¸¡ì •ë˜ëŠ” ì „ê¸°ì /ë¬¼ë¦¬ì  ì‹ í˜¸ | ECG, PPG, EMG, EEG, ì²´ì˜¨, í˜¸í¡ ë“± |
| **í–‰ë™ ë° í™˜ê²½ ë°ì´í„°**                     | ì‚¬ìš©ìì˜ ìš´ë™, ìˆ˜ë©´, ìœ„ì¹˜, ë‚ ì”¨ ë“±   | ê±¸ìŒ ìˆ˜, ìˆ˜ë©´ ì‹œê°„, GPS, ì˜¨ìŠµë„ ë“±      |

---

## ğŸ”¹ 2. ëŒ€í‘œì ì¸ ìƒì²´ì‹ í˜¸ì™€ íŠ¹ì§•

ìŠ¤ë§ˆíŠ¸ í—¬ìŠ¤ì—ì„œëŠ” ë‹¤ì–‘í•œ \*\*ìƒì²´ì‹ í˜¸(Biosignal)\*\*ë¥¼ ë¶„ì„í•˜ì—¬ ê±´ê°• ìƒíƒœë¥¼ ì¶”ì •í•©ë‹ˆë‹¤. ëŒ€í‘œì ì¸ ì‹ í˜¸ë“¤ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.

| ì‹ í˜¸              | ì¸¡ì • ëŒ€ìƒ      | ì£¼ìš” í™œìš©            | íŠ¹ì§•                 |
| --------------- | ---------- | ---------------- | ------------------ |
| **ECG (ì‹¬ì „ë„)**   | ì‹¬ì¥ ì „ê¸° ì‹ í˜¸   | ì‹¬ë°•ìˆ˜, HRV, ë¶€ì •ë§¥ ì§„ë‹¨ | ê³ í•´ìƒë„, R-peak ê²€ì¶œ    |
| **PPG (ê´‘ìš©ì ë§¥íŒŒ)** | í˜ˆë¥˜ ë³€í™”      | ë§¥ë°•ìˆ˜, í˜ˆì¤‘ ì‚°ì†Œí¬í™”ë„    | ì°©ìš© ê°„í¸, ìš´ë™ ì‹œ ë…¸ì´ì¦ˆ ë¯¼ê° |
| **EEG (ë‡ŒíŒŒ)**    | ë‡Œì˜ ì „ê¸°í™œë™    | ìˆ˜ë©´ ë¶„ì„, ë°œì‘ ê°ì§€     | ì±„ë„ ìˆ˜ ë§ê³  ì²˜ë¦¬ ë³µì¡      |
| **EMG (ê·¼ì „ë„)**   | ê·¼ìœ¡ ìˆ˜ì¶•      | ê·¼í”¼ë¡œë„ ë¶„ì„, ì¬í™œì¹˜ë£Œ    | ì§§ì€ ì‹œê°„ ì‹ í˜¸, ì¡ìŒ ì˜í–¥ í¼  |
| **í˜¸í¡/ì²´ì˜¨**       | í˜¸í¡ë¥ , ì²´ì˜¨ ë³€í™” | í˜¸í¡ê¸°ì§ˆí™˜, ë°œì—´ ê°ì§€     | í™˜ê²½ ì˜¨ë„ì— ì˜í–¥ ë°›ì„ ìˆ˜ ìˆìŒ  |

> ECG: [ìœ„í‚¤ë°±ê³¼ ì‹¬ì „ë„](https://ko.wikipedia.org/wiki/%EC%8B%AC%EC%A0%84%EB%8F%84)
> PPG: [LEDë¡œ ì‹¬ë°•ìˆ˜ë¥¼ ì¸¡ì •í•œë‹¤ê³ ? 'ê´‘í˜ˆë¥˜ì¸¡ì • ì„¼ì„œ(PPG)'](https://news.samsungdisplay.com/30140)
> EEG: [ìœ„í‚¤ë°±ê³¼ ë‡ŒíŒŒ](https://ko.wikipedia.org/wiki/%EB%87%8C%ED%8C%8C)
> EMG: [ìœ„í‚¤ë°±ê³¼ ê·¼ì „ë„ ê²€ì‚¬](https://ko.wikipedia.org/wiki/%EA%B7%BC%EC%A0%84%EB%8F%84_%EA%B2%80%EC%82%AC)
> í˜¸í¡ ì„¼ì„œ: [í˜¸í¡ë¶„ì„ê¸° 'PACER'](https://blog.naver.com/geekstarter/223752501610)
---


## ğŸ”¹ 3. ì›¨ì–´ëŸ¬ë¸” í—¬ìŠ¤ ì„¼ì„œì˜ ê°œìš”

ì›¨ì–´ëŸ¬ë¸” í—¬ìŠ¤ ì„¼ì„œëŠ” ì‚¬ìš©ìì˜ ìƒì²´ì‹ í˜¸ ë˜ëŠ” í–‰ë™ ì •ë³´ë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ì¸¡ì •í•˜ê³  ê¸°ë¡í•˜ëŠ” IoT ê¸°ë°˜ ì¥ì¹˜ì…ë‹ˆë‹¤. ì†ëª©, ê°€ìŠ´, ê·€, ë°œëª©, í”¼ë¶€ ë“±ì— ë¶€ì°©ë˜ì–´ ë™ì‘í•˜ë©°, ìŠ¤ë§ˆíŠ¸ í—¬ìŠ¤ì˜ í•µì‹¬ ë°ì´í„° ìˆ˜ì§‘ ë„êµ¬ë¡œ í™œìš©ë©ë‹ˆë‹¤.

| ì„¼ì„œ í˜•íƒœ | ì˜ˆì‹œ ê¸°ê¸°                       | ì¸¡ì • ì •ë³´            |
| ----- | --------------------------- | ---------------- |
| ì†ëª©í˜•   | Apple Watch, Galaxy Watch   | ì‹¬ë°•ìˆ˜, ìš´ë™ëŸ‰, ìˆ˜ë©´, ì²´ì˜¨ |
| íŒ¨ì¹˜í˜•   | Zephyr BioPatch, VitalPatch | ECG, PPG, í˜¸í¡, ì²´ì˜¨ |
| ê·€ê±¸ì´í˜•  | Earin, Cosinuss One         | ì‹¬ë°•ìˆ˜, ì²´ì˜¨          |
| ë°˜ì§€í˜•   | Oura Ring                   | HRV, ìˆ˜ë©´ ë‹¨ê³„       |
| ì˜ë¥˜í˜•   | Hexoskin, Athos             | í˜¸í¡, EMG, ì‹¬ì „ë„     |

---

## ğŸ”¹ 4. ì„¼ì„œì˜ ì¸¡ì • ì›ë¦¬

| ì„¼ì„œ ì¢…ë¥˜            | ì¸¡ì • ì›ë¦¬                    | ì¸¡ì • í•­ëª©               |
| ---------------- | ------------------------ | ------------------- |
| **ECG ì„¼ì„œ**       | í”¼ë¶€ í‘œë©´ ì „ê·¹ì„ í†µí•´ ì‹¬ì¥ ì „ê¸°ì‹ í˜¸ ì¸¡ì •  | ì‹¬ë°•ìˆ˜, R-R ê°„ê²©, ë¶€ì •ë§¥ íƒì§€ |
| **PPG ì„¼ì„œ**       | ì ì™¸ì„ /ë…¹ìƒ‰ê´‘ì„ í˜ˆê´€ì— ì¡°ì‚¬í•˜ì—¬ ë°˜ì‚¬ê´‘ ì¸¡ì • | ë§¥ë°•ìˆ˜, í˜ˆì¤‘ ì‚°ì†Œí¬í™”ë„       |
| **IMU (ê´€ì„±ì¸¡ì •ì„¼ì„œ)** | ê°€ì†ë„ê³„ì™€ ìì´ë¡œìŠ¤ì½”í”„ ê¸°ë°˜          | ê±¸ìŒ ìˆ˜, ìì„¸, í™œë™ ì¸ì‹     |
| **ì²´ì˜¨ ì„¼ì„œ**        | ì„œë¯¸ìŠ¤í„°, ì ì™¸ì„  ì¸¡ì •             | í”¼ë¶€ ì˜¨ë„, ì¤‘ì‹¬ ì²´ì˜¨ ì¶”ì •     |
| **í˜¸í¡ ì„¼ì„œ**        | ì••ë ¥ ë³€í™”, ìŠ¤íŠ¸ë ˆì¸ ê²Œì´ì§€ í™œìš©       | í˜¸í¡ë¥ , íí™œëŸ‰ ì¶”ì •         |

---

## ğŸ”¹ 5. ë°ì´í„° ì „ì†¡ ë° í†µì‹  ê¸°ìˆ 

ì›¨ì–´ëŸ¬ë¸” ì„¼ì„œëŠ” ìˆ˜ì§‘ëœ ë°ì´í„°ë¥¼ ìŠ¤ë§ˆíŠ¸í° ë˜ëŠ” í´ë¼ìš°ë“œë¡œ ì „ì†¡í•˜ê¸° ìœ„í•´ ë‹¤ì–‘í•œ í†µì‹  ê¸°ìˆ ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.

| í†µì‹  ê¸°ìˆ                           | íŠ¹ì§•               | ì ìš© ì‚¬ë¡€               |
| ------------------------------ | ---------------- | ------------------- |
| **BLE (Bluetooth Low Energy)** | ì§§ì€ ê±°ë¦¬, ì €ì „ë ¥       | ìŠ¤ë§ˆíŠ¸ì›Œì¹˜ â†” ìŠ¤ë§ˆíŠ¸í°        |
| **Wi-Fi**                      | ë¹ ë¥¸ ì†ë„, ì „ë ¥ ì†Œëª¨ í¼   | ìŠ¤ë§ˆíŠ¸ ì²´ì¤‘ê³„ â†” ê°€ì •ìš© Wi-Fi |
| **NB-IoT / LTE-M**             | ì €ì „ë ¥, ì¥ê±°ë¦¬, ì…€ë£°ëŸ¬ ê¸°ë°˜ | ë³‘ì› ì„œë²„ë¡œ ë°ì´í„° ì „ì†¡       |
| **ZigBee**                     | ì €ì „ë ¥, ë‹¤ìˆ˜ ì„¼ì„œ ì—°ê²°    | ì‹¤ë‚´ìš© ê±´ê°• ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ     |
| **UWB (ì´ˆê´‘ëŒ€ì—­)**                 | ìœ„ì¹˜ ì •í™•ë„ ë†’ìŒ        | ì‹¤ë‚´ í™˜ì ì¶”ì , ë‚™ìƒ ê°ì§€     |

---

## ğŸ”¹ 4. ì›¨ì–´ëŸ¬ë¸” ì„¼ì„œì˜ ë°ì´í„° íŠ¹ì„±

* **ì—°ì†ì„±**: ì‹¤ì‹œê°„ ì—°ì† ì¸¡ì •ìœ¼ë¡œ ì‹œê³„ì—´ ë°ì´í„° ìƒì„±
* **ë…¸ì´ì¦ˆ í¬í•¨**: ì›€ì§ì„, í”¼ë¶€ ì ‘ì´‰ ë¶ˆëŸ‰ ë“±ìœ¼ë¡œ ì¸í•œ ì¡ìŒ ì¡´ì¬
* **ì‚¬ìš©ì ê°„ ë‹¤ì–‘ì„±**: ìƒë¦¬ì  ì°¨ì´ë¡œ ì¸í•´ ê°œì¸ë³„ ê¸°ì¤€ ìƒì´
* **ì „ë ¥ ì†Œëª¨ ê³ ë ¤ í•„ìš”**: ì„¼ì„œ ì„¤ê³„ ë° ìˆ˜ì§‘ ì£¼ê¸° ìµœì í™” í•„ìš”

---

## ğŸ”¹ 6. ì›¨ì–´ëŸ¬ë¸” ì„¼ì„œ ì„ íƒ ì‹œ ê³ ë ¤ ìš”ì†Œ

| ê³ ë ¤ í•­ëª©       | ì„¤ëª…                         |
| ----------- | -------------------------- |
| **ì •í™•ë„**     | ì˜ë£Œ ê¸°ì¤€ ì¶©ì¡± ì—¬ë¶€ (ì˜ˆ: FDA ì¸ì¦ ì—¬ë¶€) |
| **ë°°í„°ë¦¬ ìˆ˜ëª…**  | ì§€ì†ì ì¸ ì¸¡ì • ê°€ëŠ¥ ì‹œê°„              |
| **í¸ì˜ì„±**     | ì‚¬ìš©ìì˜ ì°©ìš©ê°, ìœ„ì¹˜ ì œí•œ            |
| **í†µì‹  ë°©ì‹**   | ì‚¬ìš© í™˜ê²½ì— ë§ëŠ” ì—°ê²°ì„±              |
| **ë°ì´í„° ì ‘ê·¼ì„±** | API ì œê³µ ì—¬ë¶€, ë°ì´í„° ë‚´ë³´ë‚´ê¸° ê°€ëŠ¥ì„±    |

---

# ğŸ“— **4ì¥. ìŠ¤ë§ˆíŠ¸ í—¬ìŠ¤ ì„œë¹„ìŠ¤ ì‚¬ë¡€**



## ğŸ”¹ 1. ìŠ¤ë§ˆíŠ¸ í—¬ìŠ¤ ì„œë¹„ìŠ¤ì˜ ë¶„ë¥˜

ìŠ¤ë§ˆíŠ¸ í—¬ìŠ¤ ì„œë¹„ìŠ¤ëŠ” ì œê³µ ì£¼ì²´ì™€ ê¸°ìˆ  ë°©ì‹ì— ë”°ë¼ ë‹¤ìŒê³¼ ê°™ì´ êµ¬ë¶„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

| ìœ í˜•            | ì„¤ëª…                 | ì˜ˆì‹œ                           |
| ------------- | ------------------ | ---------------------------- |
| **ê°œì¸ ê±´ê°• ê´€ë¦¬í˜•** | ì›¨ì–´ëŸ¬ë¸” ê¸°ë°˜ ì‹¤ì‹œê°„ ê±´ê°• ê´€ë¦¬  | Apple Health, Samsung Health |
| **ì§ˆë³‘ ì˜ˆì¸¡/ì§„ë‹¨í˜•** | AI ê¸°ë°˜ ì¡°ê¸° ì§„ë‹¨, ìœ„í—˜ ì˜ˆì¸¡ | SkinVision, Lunit INSIGHT    |
| **ì›ê²© ëª¨ë‹ˆí„°ë§í˜•**  | ë³‘ì›ê³¼ í™˜ì ê°„ ì—°ê²°, ì§€ì† ì¶”ì  | Livongo, Dexcom              |
| **ìŠ¤ë§ˆíŠ¸ ë³‘ì›í˜•**   | ë³‘ì› ë‚´ ë””ì§€í„¸ ì‹œìŠ¤í…œ í†µí•©    | ì„¸ë¸Œë€ìŠ¤ ìŠ¤ë§ˆíŠ¸ ë³‘ì›, Mayo Clinic     |

---

## ğŸ”¹ 2. ìŠ¤ë§ˆíŠ¸ í—¬ìŠ¤ ì„œë¹„ìŠ¤ ì‚¬ë¡€

### (1) **Apple Health [(ì• í”Œ í—¬ìŠ¤)](https://www.apple.com/health/)**

* **ê¸°ëŠ¥**: ì‹¬ë°•ìˆ˜, ìš´ë™ëŸ‰, ìˆ˜ë©´ ê¸°ë¡, ì‹¬ë°©ì„¸ë™ ê°ì§€
* **ì„¼ì„œ**: Apple Watch (ECG, PPG, IMU ë“± ë‚´ì¥)
* **ë¶„ì„**: iOS ê¸°ë°˜ì˜ ê±´ê°• ì•±ì—ì„œ ì‹œê°í™”
* **íŠ¹ì§•**: EHR ì—°ë™, ë¯¸êµ­ ë‚´ ì¼ë¶€ ë³‘ì›ê³¼ ì§ì ‘ ì—°ê²° ê°€ëŠ¥

### (2) **Fitbit [(by Google)](https://store.google.com/gb/category/watches_trackers?hl=en-GB)**

* **ê¸°ëŠ¥**: ìš´ë™, ìˆ˜ë©´, ìŠ¤íŠ¸ë ˆìŠ¤ ì¶”ì 
* **AI ê¸°ìˆ **: ìˆ˜ë©´ ì ìˆ˜ ê³„ì‚°, HRV ê¸°ë°˜ ìŠ¤íŠ¸ë ˆìŠ¤ ì§€ìˆ˜
* **ë°ì´í„° í†µí•©**: Fitbit ì•± + Google Health í†µí•© í”Œë«í¼
* **íŠ¹ì§•**: FDA ìŠ¹ì¸ ECG ê¸°ëŠ¥ ì œê³µ

### (3) **SkinVision [(ë„¤ëœë€ë“œ)](https://www.skinvision.com/)**

* **ê¸°ëŠ¥**: í”¼ë¶€ì•” ìœ„í—˜ë„ ìê°€ ì§„ë‹¨
* **ê¸°ìˆ **: ìŠ¤ë§ˆíŠ¸í° ì¹´ë©”ë¼ ê¸°ë°˜ CNN í”¼ë¶€ ë¶„ì„
* **ì„±ê³¼**: í‘ìƒ‰ì¢… ì¡°ê¸° ë°œê²¬ ì •í™•ë„ 95% ì´ìƒ
* **í™œìš©**: ì‚¬ìš©ìê°€ ì£¼ê¸°ì  ì‚¬ì§„ ì´¬ì˜ â†’ AI ë¶„ì„ ê²°ê³¼ í™•ì¸


### (4) **ì‚¼ì„± í—¬ìŠ¤ [(Samsung Health)](https://www.samsung.com/sec/apps/samsung-health/)**

* **ê¸°ëŠ¥**: ê±¸ìŒ ìˆ˜, ìˆ˜ë©´, ìŠ¤íŠ¸ë ˆìŠ¤, í˜ˆì¤‘ ì‚°ì†Œí¬í™”ë„ ì¸¡ì •
* **ì„¼ì„œ ì—°ë™**: Galaxy Watch ì‹œë¦¬ì¦ˆ
* **ë¶„ì„**: HRV ê¸°ë°˜ ìŠ¤íŠ¸ë ˆìŠ¤ ì¶”ì •, ìˆ˜ë©´ ë‹¨ê³„ ìë™ ë¶„ì„
* **íŠ¹ì§•**: ì‚¼ì„± ìŠ¤ë§ˆíŠ¸í°ê³¼ ìë™ ì—°ë™, ê¸€ë¡œë²Œ 1ì–µ ì´ìƒ ì‚¬ìš©ì

---

## ğŸ”¹ 3. ìŠ¤ë§ˆíŠ¸ í—¬ìŠ¤ ì„œë¹„ìŠ¤ ì„¤ê³„ ì‹œ ê³ ë ¤ì‚¬í•­

| í•­ëª©             | ê³ ë ¤ ìš”ì†Œ                     |
| -------------- | ------------------------- |
| **ë°ì´í„° ì •í™•ì„±**    | ì˜ë£Œê¸°ê¸° ìˆ˜ì¤€ ì¸ì¦ í•„ìš” (FDA, CE ë“±) |
| **ê°œì¸í™” ìˆ˜ì¤€**     | ì—°ë ¹, ì„±ë³„, ìƒíƒœë³„ ë§ì¶¤í˜• ì•Œê³ ë¦¬ì¦˜      |
| **ì—°ë™ì„±**        | EHR, ë³‘ì› ì‹œìŠ¤í…œ, ëª¨ë°”ì¼ ì•± ì—°ê³„ ê°€ëŠ¥ì„± |
| **ì„¤ëª… ê°€ëŠ¥ì„±**     | AI ê²°ê³¼ì˜ ê·¼ê±° ì œì‹œ ì—¬ë¶€           |
| **ë³´ì•ˆ ë° í”„ë¼ì´ë²„ì‹œ** | ìƒì²´ì •ë³´ ì•”í˜¸í™”, GDPR/ê°œì¸ì •ë³´ë³´í˜¸ë²• ì¤€ìˆ˜ |

---

# 4ë¶€: ë¨¸ì‹ ëŸ¬ë‹ì˜ ì´í•´ì™€ í™œìš©

---

# ğŸ“– **1ì¥. ë¨¸ì‹ ëŸ¬ë‹ ê°œìš”**



## âœ¨ 1. ë¨¸ì‹ ëŸ¬ë‹ì´ë€ ë¬´ì—‡ì¸ê°€

ë¨¸ì‹ ëŸ¬ë‹(Machine Learning)ì´ë€,  
ëª…ì‹œì ìœ¼ë¡œ í”„ë¡œê·¸ë¨ì„ ì‘ì„±í•˜ì§€ ì•Šê³ ë„ ë°ì´í„°ë¥¼ ì´ìš©í•˜ì—¬ ì»´í“¨í„°ê°€ ìŠ¤ìŠ¤ë¡œ í•™ìŠµí•˜ê³  ì„±ëŠ¥ì„ ê°œì„ í•˜ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤.

Arthur Samuelì€ ë¨¸ì‹ ëŸ¬ë‹ì„ "**ëª…ì‹œì ìœ¼ë¡œ í”„ë¡œê·¸ë˜ë°í•˜ì§€ ì•Šê³  ì»´í“¨í„°ê°€ í•™ìŠµí•  ìˆ˜ ìˆê²Œ í•˜ëŠ” ì—°êµ¬ ë¶„ì•¼**"ë¼ê³  ì •ì˜í•˜ì˜€ìŠµë‹ˆë‹¤.

ë¨¸ì‹ ëŸ¬ë‹ì€ ì…ë ¥ ë°ì´í„°ë¡œë¶€í„° íŒ¨í„´ì„ í•™ìŠµí•˜ì—¬,  
**ìƒˆë¡œìš´ ë°ì´í„°ì— ëŒ€í•´ ì˜ˆì¸¡í•˜ê±°ë‚˜ ë¶„ë¥˜í•˜ëŠ” ëª¨ë¸**ì„ êµ¬ì¶•í•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•©ë‹ˆë‹¤.

### â¡ï¸ ë¨¸ì‹ ëŸ¬ë‹ ê¸°ë³¸ êµ¬ì„± ìš”ì†Œ
| êµ¬ì„± ìš”ì†Œ | ì„¤ëª… |
|:--|:--|
| ë°ì´í„° | í•™ìŠµ ë° ì˜ˆì¸¡ì„ ìœ„í•œ ì…ë ¥ ìë£Œ |
| ëª¨ë¸ | ë°ì´í„°ì˜ íŒ¨í„´ì„ í•™ìŠµí•˜ëŠ” êµ¬ì¡° |
| í•™ìŠµ ì•Œê³ ë¦¬ì¦˜ | ëª¨ë¸ì„ ìµœì í™”í•˜ëŠ” ë°©ë²• |
| ì˜ˆì¸¡ | í•™ìŠµí•œ ëª¨ë¸ë¡œ ìƒˆë¡œìš´ ë°ì´í„°ì— ëŒ€í•œ ê²°ê³¼ ìƒì„± |

## âœ¨ 2. ë¨¸ì‹ ëŸ¬ë‹ì˜ ì£¼ìš” ë¶„ë¥˜

ë¨¸ì‹ ëŸ¬ë‹ì€ í•™ìŠµ ë°©ì‹ì— ë”°ë¼ í¬ê²Œ ì„¸ ê°€ì§€ë¡œ ë¶„ë¥˜ë©ë‹ˆë‹¤.

| ë¶„ë¥˜ | ì„¤ëª… | ì˜ˆì‹œ |
|:--|:--|:--|
| ì§€ë„í•™ìŠµ (Supervised Learning) | ì…ë ¥ê³¼ ì •ë‹µ(label)ì„ ì´ìš©í•˜ì—¬ í•™ìŠµ | ë¶„ë¥˜(Classification), íšŒê·€(Regression) |
| ë¹„ì§€ë„í•™ìŠµ (Unsupervised Learning) | ì •ë‹µ ì—†ì´ ë°ì´í„° êµ¬ì¡°ë¥¼ í•™ìŠµ | í´ëŸ¬ìŠ¤í„°ë§(Clustering), ì°¨ì› ì¶•ì†Œ(Dimensionality Reduction) |
| ê°•í™”í•™ìŠµ (Reinforcement Learning) | ë³´ìƒì„ í†µí•´ ìµœì  í–‰ë™ì„ í•™ìŠµ | ê²Œì„ í”Œë ˆì´, ë¡œë´‡ ì œì–´ |


---

## âœ¨ 3. ë¨¸ì‹ ëŸ¬ë‹ ì›Œí¬í”Œë¡œìš°

ë¨¸ì‹ ëŸ¬ë‹ í”„ë¡œì íŠ¸ëŠ” ë‹¤ìŒê³¼ ê°™ì€ ë‹¨ê³„ë¥¼ ê±°ì¹©ë‹ˆë‹¤.

### â¡ï¸ ì „í˜•ì ì¸ ë¨¸ì‹ ëŸ¬ë‹ ì›Œí¬í”Œë¡œìš°

1. **ë¬¸ì œ ì •ì˜**
2. **ë°ì´í„° ìˆ˜ì§‘**
3. **ë°ì´í„° ì „ì²˜ë¦¬ ë° íƒìƒ‰**
4. **íŠ¹ì„± ì„ íƒ ë° ìƒì„±**
5. **ëª¨ë¸ ì„ íƒ ë° í•™ìŠµ**
6. **ëª¨ë¸ í‰ê°€**
7. **ëª¨ë¸ ê°œì„  ë° ìµœì í™”**
8. **ìµœì¢… ëª¨ë¸ ë°°í¬**

```
ë°ì´í„° ìˆ˜ì§‘ â†’ ë°ì´í„° ì „ì²˜ë¦¬ â†’ ëª¨ë¸ í•™ìŠµ â†’ ëª¨ë¸ í‰ê°€ â†’ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ â†’ ìµœì¢… ì˜ˆì¸¡
```

- ì´ ê³¼ì •ì—ì„œ **ë°ì´í„° ì „ì²˜ë¦¬ì™€ ëª¨ë¸ ì„ íƒ**ì´ ì„±ëŠ¥ì— ê°€ì¥ í° ì˜í–¥ì„ ë¯¸ì¹©ë‹ˆë‹¤.
---

# ğŸ“– **2ì¥. ë°ì´í„° ì „ì²˜ë¦¬ì™€ íŠ¹ì„± ê³µí•™**



## âœ¨ 1. ê²°ì¸¡ì¹˜ ì²˜ë¦¬ì™€ ì´ìƒê°’ íƒì§€

### â¡ï¸ ê²°ì¸¡ì¹˜(Missing Value) ì²˜ë¦¬

ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì€ ê²°ì¸¡ê°’ì„ í¬í•¨í•˜ëŠ” ë°ì´í„°ë¥¼ ì§ì ‘ ë‹¤ë£¨ì§€ ëª»í•˜ëŠ” ê²½ìš°ê°€ ë§ìŠµë‹ˆë‹¤.  
ë”°ë¼ì„œ ì ì ˆí•œ ë°©ë²•ìœ¼ë¡œ ê²°ì¸¡ê°’ì„ ì²˜ë¦¬í•´ì•¼ í•©ë‹ˆë‹¤.

| ë°©ë²• | ì„¤ëª… | ì˜ˆì‹œ |
|:--|:--|:--|
| ì‚­ì œ (Drop) | ê²°ì¸¡ì¹˜ê°€ ìˆëŠ” í–‰ ë˜ëŠ” ì—´ì„ ì œê±° | `dropna()` |
| ëŒ€ì²´ (Imputation) | í‰ê· , ì¤‘ì•™ê°’, ìµœë¹ˆê°’ ë“±ìœ¼ë¡œ ëŒ€ì²´ | `fillna(value)` |

> âœ… ë°ì´í„°ì˜ ë¶„í¬ë¥¼ ê³ ë ¤í•˜ì—¬ ëŒ€ì²´í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤.

### â¡ï¸ ì´ìƒê°’(Outlier) íƒì§€

ì´ìƒê°’ì€ ë°ì´í„° ë¶„í¬ì—ì„œ ë²—ì–´ë‚œ ê°’ì…ë‹ˆë‹¤.  
ì£¼ë¡œ IQR, Z-Score ë“±ì„ í™œìš©í•˜ì—¬ íƒì§€í•©ë‹ˆë‹¤.

| ë°©ë²• | ì„¤ëª… |
|:--|:--|
| IQR ë°©ë²• | Q1, Q3 ê¸°ì¤€ìœ¼ë¡œ ì´ìƒ ë²”ìœ„ ì™¸ ê°’ íƒì§€ |
| Z-Score ë°©ë²• | í‰ê·  ëŒ€ë¹„ í‘œì¤€í¸ì°¨ ë²”ìœ„ë¥¼ ë²—ì–´ë‚œ ê°’ íƒì§€ |

---

## âœ¨ 2. ë²”ì£¼í˜• ë³€ìˆ˜ ì¸ì½”ë”©

ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì€ ìˆ˜ì¹˜í˜• ë°ì´í„°ë§Œ ì…ë ¥ìœ¼ë¡œ ë°›ê¸° ë•Œë¬¸ì—,  
ë²”ì£¼í˜•(categorical) ë°ì´í„°ëŠ” ìˆ˜ì¹˜ë¡œ ë³€í™˜í•´ì•¼ í•©ë‹ˆë‹¤.

| ì¸ì½”ë”© ë°©ë²• | ì„¤ëª… | ì˜ˆì‹œ |
|:--|:--|:--|
| ë ˆì´ë¸” ì¸ì½”ë”© (Label Encoding) | ê° ì¹´í…Œê³ ë¦¬ë¥¼ ì •ìˆ˜ë¡œ ë§¤í•‘ | Male â†’ 0, Female â†’ 1 |
| ì›-í•« ì¸ì½”ë”© (One-Hot Encoding) | ê° ì¹´í…Œê³ ë¦¬ë¥¼ 0/1ë¡œ ë³€í™˜í•˜ëŠ” ë²¡í„° ìƒì„± | `get_dummies(), to_categorical()` ì‚¬ìš© |

> âœ… ë² ì´ì§€ì•ˆ ë£°, íŠ¸ë¦¬ ê¸°ë°˜ ëª¨ë¸ì€ ë ˆì´ë¸” ì¸ì½”ë”©ì„ ì‚¬ìš©í•´ë„ ê´œì°®ì§€ë§Œ,  
> âœ… ì„ í˜• ëª¨ë¸(SVM, ë¡œì§€ìŠ¤í‹± íšŒê·€ ë“±)ì—ì„œëŠ” ì›-í•« ì¸ì½”ë”©ì´ ë” ì í•©í•©ë‹ˆë‹¤.

---

## âœ¨ 3. ì •ê·œí™”ì™€ í‘œì¤€í™”

íŠ¹ì„±(feature)ë“¤ì˜ ìŠ¤ì¼€ì¼ì´ ë‹¤ë¥¼ ê²½ìš°,  
ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì€ íŠ¹ì • íŠ¹ì„±ì— ì§€ë‚˜ì¹˜ê²Œ ë¯¼ê°í•˜ê²Œ ë°˜ì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  
ì´ë¥¼ ë°©ì§€í•˜ê¸° ìœ„í•´ ìŠ¤ì¼€ì¼ ì¡°ì •ì´ í•„ìš”í•©ë‹ˆë‹¤.

| ë°©ë²• | ì„¤ëª… | ìˆ˜ì‹ |
|:--|:--|:--|
| ì •ê·œí™” (Normalization) | ëª¨ë“  ê°’ì„ 0~1 ë²”ìœ„ë¡œ ë³€í™˜ | $x' = \frac{x - x_{min}}{x_{max} - x_{min}}$ |
| í‘œì¤€í™” (Standardization) | í‰ê·  0, í‘œì¤€í¸ì°¨ 1ë¡œ ë³€í™˜ | $x' = \frac{x - \mu}{\sigma}$ |

> âœ… KNN, SVM ê°™ì€ ê±°ë¦¬ ê¸°ë°˜ ì•Œê³ ë¦¬ì¦˜ì€ ì •ê·œí™”/í‘œì¤€í™”ê°€ ë§¤ìš° ì¤‘ìš”í•©ë‹ˆë‹¤.

---

## âœ¨ 4. íŠ¹ì„± ì„ íƒê³¼ ì°¨ì› ì¶•ì†Œ

ëª¨ë“  íŠ¹ì„±ì´ ì˜ˆì¸¡ì— ìœ ìš©í•œ ê²ƒì€ ì•„ë‹™ë‹ˆë‹¤.  
**íŠ¹ì„± ì„ íƒ(Feature Selection)** ì€ ì¤‘ìš”í•œ íŠ¹ì„±ë§Œ ê³¨ë¼ ëª¨ë¸ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” ê³¼ì •ì…ë‹ˆë‹¤.

| ë°©ë²• | ì„¤ëª… |
|:--|:--|
| í•„í„° ë°©ì‹ (Filter) | í†µê³„ì  ê¸°ì¤€(ìƒê´€ê³„ìˆ˜ ë“±)ìœ¼ë¡œ ì„ íƒ |
| ë˜í¼ ë°©ì‹ (Wrapper) | ëª¨ë¸ì„ í†µí•´ ìµœì  íŠ¹ì„± ì¡°í•© íƒìƒ‰ |
| ì„ë² ë””ë“œ ë°©ì‹ (Embedded) | ëª¨ë¸ í•™ìŠµ ì¤‘ íŠ¹ì„± ì„ íƒ (ex. Lasso) |

ë˜í•œ ê³ ì°¨ì› ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´  
**ì°¨ì› ì¶•ì†Œ(Dimensionality Reduction)** ê¸°ë²•(PCA ë“±)ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

---

## âœ¨ 5. ë°ì´í„° ë¶„í• : í•™ìŠµ/ê²€ì¦/í…ŒìŠ¤íŠ¸ì…‹

ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ì •í™•íˆ í‰ê°€í•˜ê¸° ìœ„í•´, ë°ì´í„°ë¥¼ ë‹¤ìŒê³¼ ê°™ì´ ë¶„í• í•©ë‹ˆë‹¤.

| êµ¬ë¶„ | ì„¤ëª… | ì¼ë°˜ì ì¸ ë¹„ìœ¨ |
|:--|:--|:--|
| í•™ìŠµì…‹ (Training Set) | ëª¨ë¸ì„ í•™ìŠµì‹œí‚¤ëŠ” ë°ì´í„° | 60~80% |
| ê²€ì¦ì…‹ (Validation Set) | í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ìš© ë°ì´í„° | 10~20% |
| í…ŒìŠ¤íŠ¸ì…‹ (Test Set) | ìµœì¢… ì„±ëŠ¥ í‰ê°€ìš© ë°ì´í„° | 10~20% |

> âœ… êµì°¨ ê²€ì¦(Cross Validation) ê¸°ë²•ì„ ì‚¬ìš©í•˜ë©´ ë³´ë‹¤ ì•ˆì •ì ì¸ í‰ê°€ê°€ ê°€ëŠ¥í•©ë‹ˆë‹¤.

---

## ğŸ› ï¸ ì‹¤ìŠµ: íƒ€ì´íƒ€ë‹‰ ë°ì´í„° ì „ì²˜ë¦¬ 

```python
# íƒ€ì´íƒ€ë‹‰ ë°ì´í„° ì „ì²˜ë¦¬

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

# ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
titanic = pd.read_csv('https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv')
print(titanic.info())
print(titanic.head(10))

# 1. ê²°ì¸¡ì¹˜ ì²˜ë¦¬
titanic['Age'] = titanic['Age'].fillna(titanic['Age'].median())
titanic['Embarked'] = titanic['Embarked'].fillna(titanic['Embarked'].mode()[0])
print(titanic.info())
print(titanic.head(10))

# 2. ë²”ì£¼í˜• ë³€ìˆ˜ ì¸ì½”ë”©
print(titanic['Sex'].value_counts())
print(titanic['Embarked'].value_counts())
titanic['Sex'] = titanic['Sex'].map({'female': 0, 'male': 1})
titanic['Embarked'] = titanic['Embarked'].map({'C':0, 'S':1, 'Q':2})
print(titanic.head(10))

# 3. ë¶ˆí•„ìš”í•œ ì—´ ì œê±°
titanic.drop(['Name', 'Ticket', 'Cabin', 'PassengerId'], axis=1, inplace=True)
print(titanic.head(10))

# 4. íŠ¹ì„±ê³¼ íƒ€ê¹ƒ ë¶„ë¦¬
X = titanic.drop('Survived', axis=1)
y = titanic['Survived']

# 5. ë°ì´í„° ë¶„í• 
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 6. ì •ê·œí™” (í‘œì¤€í™”)
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

print("íƒ€ì´íƒ€ë‹‰ ë°ì´í„° ì „ì²˜ë¦¬ ì™„ë£Œ!")
print("í›ˆë ¨ ë°ì´í„° í¬ê¸°:", X_train.shape)
print("í…ŒìŠ¤íŠ¸ ë°ì´í„° í¬ê¸°:", X_test.shape)
```
---


# ğŸ“˜ 3ì¥. íšŒê·€ ë¶„ì„(Regression)

íšŒê·€ ë¶„ì„ì€ **ì—°ì†ì ì¸ ê°’ì„ ì˜ˆì¸¡**í•  ë•Œ ì‚¬ìš©í•˜ëŠ” ëŒ€í‘œì ì¸ ê¸°ê³„í•™ìŠµ ì•Œê³ ë¦¬ì¦˜ì…ë‹ˆë‹¤.

| í•­ëª©      | ì„¤ëª…                                                |
| ------- | ------------------------------------------------- |
| ëª©ì       | ì…ë ¥ ë³€ìˆ˜ë¡œë¶€í„° ìˆ˜ì¹˜í˜• ì¶œë ¥ê°’ ì˜ˆì¸¡                               |
| ì˜ˆì‹œ      | ê¸°ì˜¨, ìŠµë„ â†’ ì‘ë¬¼ ìƒì¥ëŸ‰, ìˆ˜í™•ëŸ‰ ì˜ˆì¸¡                           |
| ëŒ€í‘œ ì•Œê³ ë¦¬ì¦˜ | ì„ í˜• íšŒê·€(Linear Regression), ë¦¿ì§€ íšŒê·€(Ridge), ë¼ì˜(Lasso) |

### ì ìš© ì˜ˆ

* ê¸°ìƒ ë°ì´í„° ê¸°ë°˜ **ìˆ˜í™•ëŸ‰ ì˜ˆì¸¡**
* ì´ì‚°í™”íƒ„ì†Œ ë†ë„ì— ë”°ë¥¸ **ìƒìœ¡ ì†ë„ ì˜ˆì¸¡**
---

# ğŸ”¹ ì„ í˜• íšŒê·€ (Linear Regression)



## 1. ì—­ì‚¬ì  ë°°ê²½


#### 1.. ê¸°ì›

* **1805ë…„**: í”„ë‘ìŠ¤ ìˆ˜í•™ì **Adrien-Marie Legendre**ê°€ â€˜ìµœì†Œì œê³±ë²•(Least Squares Method)â€™ì„ ë„ì…í•˜ì—¬ ì²œë¬¸í•™ì  ê´€ì¸¡ ë°ì´í„°ì˜ ì˜¤ì°¨ë¥¼ ìµœì†Œí™”í•˜ë ¤ í–ˆìŠµë‹ˆë‹¤.
* **1809ë…„**: ë…ì¼ ìˆ˜í•™ì **Carl Friedrich Gauss**ë„ ë™ì¼í•œ ë°©ë²•ì„ ë…ìì ìœ¼ë¡œ ê°œë°œí•˜ì—¬ **ì •ê·œë¶„í¬ì™€ì˜ ì—°ê²°**ì„ ì´ë¡ í™”í•˜ì˜€ìŠµë‹ˆë‹¤.

#### 2.. í†µê³„í•™ìœ¼ë¡œì˜ í™•ì¥

* **19ì„¸ê¸° í›„ë°˜**: í†µê³„í•™ì **Francis Galton**ì´ ì¸ê°„ í‚¤ì˜ ìƒê´€ê´€ê³„ ë¶„ì„ì„ í†µí•´ â€˜íšŒê·€(regression)â€™ë¼ëŠ” ìš©ì–´ë¥¼ ë„ì…í•˜ì˜€ìŠµë‹ˆë‹¤.

  * ì•„ë²„ì§€ í‚¤ì™€ ì•„ë“¤ í‚¤ ê°„ì˜ ê´€ê³„ì—ì„œ í‰ê· ìœ¼ë¡œ ë˜ëŒì•„ê°€ëŠ” ì„±ì§ˆ â†’ â€œíšŒê·€(regression) toward the meanâ€

#### 3.. ì»´í“¨í„° ì‹œëŒ€ ì´í›„

* 20ì„¸ê¸° ì¤‘ë°˜ ì´í›„ íšŒê·€ ë¶„ì„ì€ ì»´í“¨í„°ë¥¼ í†µí•´ ìë™í™”ë˜ë©° í†µê³„í•™, ê²½ì œí•™, ê³µí•™, ìƒë¬¼í•™ ë“± ë‹¤ì–‘í•œ ë¶„ì•¼ì—ì„œ **ê¸°ì´ˆ ì˜ˆì¸¡ ë„êµ¬**ë¡œ ìë¦¬ì¡ê²Œ ë©ë‹ˆë‹¤.

---

## 2. ì´ë¡ ì  ì•Œê³ ë¦¬ì¦˜ 

#### 1.. ëª©í‘œ
ì…ë ¥ ë³€ìˆ˜ $X$ì™€ ì¶œë ¥ ë³€ìˆ˜ $y$ ì‚¬ì´ì˜ **ì„ í˜• ê´€ê³„**ë¥¼ ëª¨ë¸ë§í•˜ì—¬, ìƒˆë¡œìš´ ì…ë ¥ ê°’ì— ëŒ€í•œ **ì—°ì†ì  ì¶œë ¥ ê°’**ì„ ì˜ˆì¸¡í•˜ëŠ” ê²ƒ.

#### 2.. ìˆ˜ì‹ í‘œí˜„

$$
\hat{y} = w_1 x_1 + w_2 x_2 + \cdots + w_n x_n + b = \mathbf{Xw} + b
$$

* $\hat{y}$: ì˜ˆì¸¡ê°’
* $\mathbf{X}$: ì…ë ¥ ë²¡í„°
* $\mathbf{w}$: ê°€ì¤‘ì¹˜ ë²¡í„°
* $b$: ì ˆí¸(intercept)

#### 3.. ëª©ì  í•¨ìˆ˜ (ë¹„ìš© í•¨ìˆ˜, Loss Function)

\*\*MSE (Mean Squared Error)\*\*ë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜¤ì°¨ë¥¼ ìµœì†Œí™”í•©ë‹ˆë‹¤:

$$
J(\mathbf{w}, b) = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2
$$

---

## 3. ê°€ì • ì¡°ê±´

ì„ í˜• íšŒê·€ëŠ” ë‹¤ìŒì˜ í†µê³„ì  ê°€ì •ì„ ì „ì œë¡œ í•©ë‹ˆë‹¤:

| ê°€ì •                              | ì„¤ëª…                    |
| ------------------------------- | --------------------- |
| ì„ í˜•ì„± (Linearity)                 | ì…ë ¥ ë³€ìˆ˜ì™€ ì¶œë ¥ ë³€ìˆ˜ ê°„ì˜ ì„ í˜• ê´€ê³„ |
| ë…ë¦½ì„± (Independence)              | ê´€ì¸¡ê°’ ê°„ì˜ ë…ë¦½ì„±            |
| ë“±ë¶„ì‚°ì„± (Homoscedasticity)         | ì˜¤ì°¨ì˜ ë¶„ì‚°ì´ ì¼ì •í•¨           |
| ì •ê·œì„± (Normality)                 | ì”ì°¨(ì˜¤ì°¨)ê°€ ì •ê·œ ë¶„í¬ë¥¼ ë”°ë¦„     |
| ë‹¤ì¤‘ê³µì„ ì„± ì—†ìŒ (No multicollinearity) | ì…ë ¥ ë³€ìˆ˜ ê°„ ê³¼ë„í•œ ìƒê´€ê´€ê³„ ì—†ìŒ   |

---

## 4. íšŒê·€ë¶„ì„ í”„ë¡œì íŠ¸ ì‚¬ë¡€

### ğŸ”¹ 1. ì‘ë¬¼ ìƒì¥ ì˜ˆì¸¡ 

íšŒê·€ ë¶„ì„ì€ ì‘ë¬¼ì˜ ìƒì¥ëŸ‰(ì˜ˆ: ì ë©´ì , í‚¤, ìƒì¤‘ëŸ‰ ë“±)ì„ ì˜ˆì¸¡í•˜ê¸° ìœ„í•´ ì£¼ë¡œ ì‚¬ìš©ë©ë‹ˆë‹¤. ì…ë ¥ ë³€ìˆ˜ë¡œëŠ” ì˜¨ë„, ìŠµë„, COâ‚‚, ì¼ì¡°ëŸ‰ ë“±ì˜ **í™˜ê²½ ì •ë³´**ê°€ ì‚¬ìš©ë˜ë©°, ì¶œë ¥ì€ **ìƒìœ¡ ì§€í‘œì˜ ì—°ì†ì  ìˆ˜ì¹˜**ì…ë‹ˆë‹¤.

#### íšŒê·€ ë¶„ì„ íë¦„

1. ë°ì´í„° ìˆ˜ì§‘: ì‹œê³„ì—´ ì„¼ì„œ + ìƒìœ¡ ì¸¡ì • ë°ì´í„°
2. íŠ¹ì„± ì„ íƒ: í‰ê·  ì˜¨ë„, ëˆ„ì  ì¼ì¡°ëŸ‰ ë“±
3. ëª¨ë¸ í•™ìŠµ: ì„ í˜• íšŒê·€ ë˜ëŠ” ë‹¤í•­ íšŒê·€
4. ì„±ëŠ¥ í‰ê°€: MAE, RMSE, RÂ²

---

### ğŸ”¹ 2. ë‚ ì”¨ ë°ì´í„° ê¸°ë°˜ ìˆ˜í™• ì‹œê¸° ì˜ˆì¸¡

ìˆ˜í™• ì‹œê¸° ì˜ˆì¸¡ì€ ìƒìœ¡ë¥ ê³¼ ì™¸ë¶€ í™˜ê²½ ìš”ì¸ì„ ê¸°ë°˜ìœ¼ë¡œ ì‘ë¬¼ì˜ **ìµœì  ìˆ˜í™• ì‹œì **ì„ ë¶„ë¥˜í•˜ê±°ë‚˜ íšŒê·€ ë¬¸ì œë¡œ ëª¨ë¸ë§í•©ë‹ˆë‹¤.

| ì…ë ¥ ë³€ìˆ˜ | ì„¤ëª…            |
| ----- | ------------- |
| ìƒìœ¡ì¼ìˆ˜  | íŒŒì¢… í›„ ê²½ê³¼ ì¼ìˆ˜    |
| í‰ê·  ê¸°ì˜¨ | ìƒìœ¡ê¸° í‰ê·  ê¸°ì˜¨     |
| ì´ ì¼ì¡°ëŸ‰ | ëˆ„ì  ì¼ì¡° ì‹œê°„      |
| ê°•ìˆ˜ëŸ‰   | ìˆ˜ë¶„ ìŠ¤íŠ¸ë ˆìŠ¤ ì˜í–¥ ê³ ë ¤ |

####  ì˜ˆì¸¡ ì ‘ê·¼ ë°©ì‹

* **íšŒê·€ ëª¨ë¸**: ìˆ˜í™•ê¹Œì§€ ë‚¨ì€ ì¼ìˆ˜ ì˜ˆì¸¡
* **ì´ì§„ ë¶„ë¥˜ ëª¨ë¸**: â€˜ìˆ˜í™• ì ê¸° ì—¬ë¶€â€™ (ì˜ˆ/ì•„ë‹ˆì˜¤)


---

## ì‹¤ìŠµ 1: ë‹¤ì¤‘ ì„ í˜• íšŒê·€ë¥¼ í™œìš©í•œ ë³´ìŠ¤í„´ ì£¼íƒ ê°€ê²© ì˜ˆì¸¡



**Boston Housing ë°ì´í„°ì…‹**ì€ ë¯¸êµ­ ë³´ìŠ¤í„´ ì§€ì—­ì˜ ì£¼íƒ ê°€ê²©ì— ì˜í–¥ì„ ì£¼ëŠ” ë‹¤ì–‘í•œ ë³€ìˆ˜ë“¤(ë°© ìˆ˜, ì§€ì—­ ë²”ì£„ìœ¨, êµìœ¡ ìˆ˜ì¤€ ë“±)ì„ í¬í•¨í•œ ë°ì´í„°ì…ë‹ˆë‹¤.
ë‹¤ì¤‘ ì„ í˜• íšŒê·€ ëª¨ë¸ì„ í•™ìŠµì‹œì¼œ, **ì£¼ì–´ì§„ íŠ¹ì„±ë“¤ë¡œë¶€í„° ì§‘ê°’ì„ ì˜ˆì¸¡**í•˜ëŠ” ëª¨ë¸ì„ êµ¬í˜„í•©ë‹ˆë‹¤.
> OpenMLì—ì„œ ë³´ìŠ¤í„´ ì£¼íƒ ë°ì´í„°ì…‹ì„ ê°€ì ¸ì˜´.


### ë°ì´í„° ì •ë³´

Boston Housing ë°ì´í„°ì…‹ì—ëŠ” ë‹¤ìŒê³¼ ê°™ì€ íŠ¹ì„±(Feature)ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤:

| ë³€ìˆ˜ëª…      | ì„¤ëª…                        |
| -------- | ------------------------- |
| CRIM     | ì§€ì—­ ë²”ì£„ìœ¨                    |
| ZN       | 25,000 í‰ë°©í”¼íŠ¸ ì´ìƒ ê±°ì£¼ì§€ì—­ ë¹„ìœ¨    |
| INDUS    | ë¹„ì†Œë§¤ìƒì—…ì§€ì—­ ë©´ì  ë¹„ìœ¨             |
| CHAS     | ì°°ìŠ¤ê°• ì¸ì ‘ ì—¬ë¶€ (1: ì¸ì ‘, 0: ê·¸ ì™¸) |
| NOX      | ì¼ì‚°í™”ì§ˆì†Œ ë†ë„                  |
| RM       | ì£¼íƒ 1ê°€êµ¬ë‹¹ í‰ê·  ë°© ê°œìˆ˜           |
| AGE      | 1940ë…„ ì´ì „ì— ì§€ì–´ì§„ ì£¼íƒ ë¹„ìœ¨       |
| DIS      | 5ê°œ ë³´ìŠ¤í„´ ê³ ìš©ì„¼í„°ê¹Œì§€ ê±°ë¦¬          |
| RAD      | ë°©ì‚¬í˜• ê³ ì†ë„ë¡œ ì ‘ê·¼ì„± ì§€ìˆ˜           |
| TAX      | ì¬ì‚°ì„¸ìœ¨                      |
| PTRATIO  | í•™ìƒ-êµì‚¬ ë¹„ìœ¨                  |
| B        | í‘ì¸ ì¸êµ¬ ë¹„ìœ¨ ì§€í‘œ               |
| LSTAT    | ì €ì†Œë“ì¸µ ë¹„ìœ¨ (%)               |
| **MEDV** | ì£¼íƒ ê°€ê²© (ëª©í‘œê°’, ë‹¨ìœ„: \$1000s)  |



```python
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.datasets import fetch_openml

# 1. ë°ì´í„° ë¡œë”©
boston = fetch_openml(name='boston', version=1, as_frame=True)
X = boston.data
y = boston.target

print(X.info())

# categorical ë³€ìˆ˜ --> ìˆ˜ì¹˜í˜•ìœ¼ë¡œ ë³€ê²½
X['CHAS'] = X['CHAS'].astype(int)
X['RAD'] = X['RAD'].astype(int)

# 2. í›ˆë ¨/í…ŒìŠ¤íŠ¸ ë¶„í• 
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 3. ëª¨ë¸ í•™ìŠµ
model = LinearRegression()
model.fit(X_train, y_train)

# ì˜ˆì¸¡ ë° í‰ê°€
y_pred = model.predict(X_test)
mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)
r2 = r2_score(y_test, y_pred)

print("âœ… ëª¨ë¸ í‰ê°€")
print(f"â–¶ MSE: {mse:.2f}")
print(f"â–¶ RMSE: {rmse:.2f}")
print(f"â–¶ RÂ² Score: {r2:.2f}")

# 4. íšŒê·€ ê³„ìˆ˜ ì¶œë ¥ ë° í•´ì„
coefficients = pd.Series(model.coef_, index=X.columns)

print("\nâœ… íšŒê·€ ê³„ìˆ˜:")
print(coefficients.sort_values(ascending=False))

print("\nâœ… ì£¼ìš” ë³€ìˆ˜ í•´ì„:")
print(f"NOX (ì¼ì‚°í™”ì§ˆì†Œ ë†ë„): {coefficients['NOX']:.3f} â†’ ì¼ì‚°í™”ì§ˆì†Œ ë†ë„ ë†’ì„ìˆ˜ë¡ ì§‘ê°’ í•˜ë½")
print(f"RM (ë°© ê°œìˆ˜): {coefficients['RM']:.3f} â†’ ë°©ì´ ë§ì„ìˆ˜ë¡ ì§‘ê°’ ìƒìŠ¹")
print(f"CHAS (ì°°ìŠ¤ê°• ì¸ì ‘ ì—¬ë¶€): {coefficients['CHAS']:.3f} â†’ ì°°ìŠ¤ê°• ì¸ì ‘í• ìˆ˜ë¡ ì§‘ê°’ ìƒìŠ¹")
```
---
## ì‹¤ìŠµ 2: GreenHouse ìˆ˜í™•ëŸ‰ ì˜ˆì¸¡

### ë°ì´í„° ì…‹
- Autonomous Greenhouse Challenge (AGC) ë°ì´í„°ì…‹
- ë§í¬: https://www.kaggle.com/datasets/piantic/autonomous-greenhouse-challengeagc-2nd-2019/data
- **Autonomous Greenhouse Challenge (AGC)** ë°ì´í„°ì…‹ì—ëŠ” ì—¬ëŸ¬ í´ë”ê°€ ì¡´ì¬í•˜ëŠ”ë°, ê°ê°ì´ ì˜ë¯¸í•˜ëŠ” ë°”ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:


### í´ë” êµ¬ì¡° ë° ì„¤ëª…

| í´ë”ëª…            | ì„¤ëª…                                                                                                             |
| -------------- | -------------------------------------------------------------------------------------------------------------- |
| **AICU**       | 2019â€“2020ë…„ ì±Œë¦°ì§€ì— ì°¸ê°€í•œ **AiCU íŒ€**ì´ ì‚¬ìš©í•œ ì˜¨ì‹¤ ë°ì´í„°ë¥¼ í¬í•¨í•©ë‹ˆë‹¤. ì„¼ì„œ ì…ë ¥ ê°’(ì˜¨ë„, ìŠµë„, COâ‚‚, PAR, í† ì–‘ ìˆ˜ë¶„ ë“±)ê³¼ AI ê¸°ë°˜ ì œì–´ ì „ëµì´ ê¸°ë¡ë˜ì–´ ìˆìŠµë‹ˆë‹¤. |
| **Automatoes** | **Automatoes íŒ€** (2ë“± ë˜ëŠ” ìš°ìŠ¹ íŒ€)ì˜ ë°ì´í„°ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. ì´ë²ˆ ëŒ€íšŒì—ì„œ í† ë§ˆí†  ì¬ë°°ì— ì‚¬ìš©ëœ í™˜ê²½ ì¡°ì‘ ì „ëµê³¼ í•´ë‹¹ ì„¼ì„œ ë°ì´í„°ë¥¼ í¬í•¨í•©ë‹ˆë‹¤.                     |
| **Dialog**     | ë°ì´í„°ì…‹ ì œê³µ êµ¬ì¡°ìƒ **Dialog**ëŠ” ì±Œë¦°ì§€ì˜ â€œì°¸ê°€ìâ€“ì£¼ìµœ ì¸¡ ê°„ ëŒ€í™” ë°ì´í„°â€ì¼ ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤. ì‹¤ì œ í™˜ê²½ ì„¼ì„œ ê°’ì´ë‚˜ ì‹¤í—˜ ë°ì´í„°ë¥¼ ë‹´ê³  ìˆì§€ëŠ” ì•Šì„ í™•ë¥ ì´ í½ë‹ˆë‹¤.           |

### ì‚¬ìš© í´ë”:  **Automatoes** 

### ì‚¬ìš© íŒŒì¼ ëª©ë¡

| íŒŒì¼ëª…                     | ì„¤ëª…                          | ì‚¬ìš© ëª©ì          |
| ----------------------- | --------------------------- | ------------- |
| `GreenhouseClimate.csv` | ì˜¨ì‹¤ ë‚´ë¶€ ì˜¨ë„, ìŠµë„, COâ‚‚, ê´‘ëŸ‰, ê¸‰ìˆ˜ ë“± | **ì…ë ¥ ë³€ìˆ˜ (X)** |
| `Production.csv`        | í’ˆì§ˆ ë“±ê¸‰ë³„ ìˆ˜í™•ëŸ‰ (A, B), ìˆ˜í™• ì¼ì í¬í•¨ | **ëª©í‘œ ë³€ìˆ˜ (y)** |


### ì„ íƒëœ ì£¼ìš” ë³€ìˆ˜

| ë³€ìˆ˜ëª…       | ì„¤ëª…                          | ë‹¨ìœ„        | íŒŒì¼                |
| --------- | --------------------------- | --------- | ----------------- |
| `Tair`    | ì˜¨ì‹¤ ë‚´ ê³µê¸° ì˜¨ë„                  | Â°C        | GreenhouseClimate |
| `Rhair`   | ì˜¨ì‹¤ ë‚´ ìƒëŒ€ ìŠµë„                  | %         | GreenhouseClimate |
| `CO2air`  | ì˜¨ì‹¤ ë‚´ COâ‚‚ ë†ë„                 | ppm       | GreenhouseClimate |
| `Tot_PAR` | ì´ ê´‘í•©ì„± ìœ íš¨ ë³µì‚¬ëŸ‰ (íƒœì–‘ + LED/HPS) | Î¼mol/mÂ²/s | GreenhouseClimate |
| `Cum_irr` | í•˜ë£¨ ëˆ„ì  ê´€ìˆ˜ëŸ‰                   | L/mÂ²      | GreenhouseClimate |
| `ProdA`   | ìƒê¸‰ í’ˆì§ˆ í† ë§ˆí†  ìˆ˜í™•ëŸ‰               | kg/mÂ²     | Production        |

â€» ì‹œê°„ ë‹¨ìœ„ëŠ” 5ë¶„ ê°„ê²©ì´ë©°, ì¼ ë‹¨ìœ„ë¡œ ë¦¬ìƒ˜í”Œë§ í›„ ì‚¬ìš©í•©ë‹ˆë‹¤.


* ë¨¼ì €, AICU í´ë”ì˜ GreenhouseClimate.csvì™€ Production.csv ë¥¼ ì—…ë¡œë“œí•©ë‹ˆë‹¤. 

```python
import pandas as pd
import numpy as np
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, r2_score
import matplotlib.pyplot as plt

# 1. íŒŒì¼ ê²½ë¡œ ì„¤ì •
climate_path = "/content/GreenhouseClimate.csv"
prod_path = "/content/Production.csv"

# 2. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
climate = pd.read_csv(climate_path)
climate['Time'] = pd.to_datetime(climate['Time'], unit='D', origin='1900-01-01')

production = pd.read_csv(prod_path)
production['Time'] = pd.to_datetime(production['Time'], unit='D', origin='1900-01-01')

# 3. í•„ìš”í•œ ë³€ìˆ˜ë§Œ ì¶”ì¶œ
climate = climate[['Time', 'Tair', 'Rhair', 'CO2air', 'Tot_PAR', 'Cum_irr']]
production = production[['Time', 'ProdA']]  # ëª©í‘œ: Class A ìˆ˜í™•ëŸ‰

# 4. ì‹œê°„ ë‹¨ìœ„ í‰ê·  (í•˜ë£¨ ë‹¨ìœ„ë¡œ)
climate_indexed = climate.set_index('Time') 
production_indexed = production.set_index('Time')

numerical_cols = ['Tair', 'Rhair', 'CO2air', 'Tot_PAR', 'Cum_irr']
for col in numerical_cols:
    climate_indexed[col] = pd.to_numeric(climate_indexed[col], errors='coerce')

climate_daily = climate_indexed[numerical_cols].resample('D').mean().reset_index()
production_daily = production_indexed.resample('D').sum().reset_index()

# 5. ë³‘í•©
df = pd.merge(climate_daily, production_daily, on='Time')

# 6. ê²°ì¸¡ì¹˜ ì œê±°
df.dropna(inplace=True)

# 7. X, y ë¶„ë¦¬
X = df[numerical_cols]
y = df['ProdA']

# 8. í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë¶„í• 
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 9. ìŠ¤ì¼€ì¼ë§
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# 10. ëª¨ë¸ í›ˆë ¨ (Linear Regression)
model = LinearRegression()
model.fit(X_train_scaled, y_train)

# 11. ì˜ˆì¸¡ ë° í‰ê°€
y_pred = model.predict(X_test_scaled)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

print(f"RMSE: {rmse:.2f}")
print(f"RÂ² Score: {r2:.2f}")

# 12. ì‹œê°í™”
plt.figure(figsize=(10, 5))
plt.plot(y_test.values, label='Ground Truth')
plt.plot(y_pred, label='Predicted (LinearReg)', linestyle='--')
plt.title("Tomato Production Prediction (Linear Regression)")
plt.xlabel("Sample Index")
plt.ylabel("Production (kg/mÂ²)")
plt.legend()
plt.grid()
plt.show()
```


---
# ğŸ”¹ ë¡œì§€ìŠ¤í‹± íšŒê·€(Logistic Regression)


## 1. ë¡œì§€ìŠ¤í‹± íšŒê·€ë€?


ë¡œì§€ìŠ¤í‹± íšŒê·€ëŠ” **ë¶„ë¥˜(classification)** ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” ì§€ë„ í•™ìŠµ ì•Œê³ ë¦¬ì¦˜ì…ë‹ˆë‹¤. ì´ë¦„ì€ "íšŒê·€"ì´ì§€ë§Œ, ì‹¤ì œë¡œëŠ” **ì¶œë ¥ê°’ì„ í™•ë¥ ë¡œ ì˜ˆì¸¡í•˜ê³ , ì´ í™•ë¥ ì„ ë°”íƒ•ìœ¼ë¡œ í´ë˜ìŠ¤(0 ë˜ëŠ” 1)ë¥¼ ë¶„ë¥˜**í•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤.


* ì¶œë ¥ê°’ì€ **0ê³¼ 1 ì‚¬ì´ì˜ í™•ë¥ **ë¡œ í‘œí˜„ë©ë‹ˆë‹¤.
* **ì‹œê·¸ëª¨ì´ë“œ í•¨ìˆ˜**ë¥¼ ì‚¬ìš©í•´ ì„ í˜• ì¡°í•©ì„ í™•ë¥ ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
* **ì´ì§„ ë¶„ë¥˜**ì— ì£¼ë¡œ ì‚¬ìš©ë˜ë©°, **ë‹¤ì¤‘ í´ë˜ìŠ¤ í™•ì¥**ë„ ê°€ëŠ¥í•©ë‹ˆë‹¤.



| í•­ëª©    | ì„¤ëª…                                      |
| ----- | --------------------------------------- |
| ëª©ì     | í™•ë¥  ê¸°ë°˜ ì´ì§„ ë¶„ë¥˜                             |
| ì˜ˆì¸¡ê°’   | ì‹œê·¸ëª¨ì´ë“œ í•¨ìˆ˜ ì¶œë ¥ $\hat{y} \in (0,1)$         |
| ê²°ì • ê¸°ì¤€ | $\hat{y} \ge 0.5 \rightarrow 1$, ê·¸ ì™¸ëŠ” 0 |
| ì†ì‹¤ í•¨ìˆ˜ | ë¡œì§€ìŠ¤í‹± ì†ì‹¤ (Binary Cross-Entropy)          |
| ìµœì í™”   | ê²½ì‚¬í•˜ê°•ë²• ë“± ì‚¬ìš©                              |
| í™•ì¥    | Scikit-learnì€ ë‹¤ì¤‘ í´ë˜ìŠ¤ ë¶„ë¥˜ ê°€ëŠ¥                |

---

### ë¬¸ì œ 1. ë¡œì§€ìŠ¤í‹± íšŒê·€ì—ì„œ ì˜ˆì¸¡ê°’ $\hat{y}$ëŠ” ì–´ë–¤ ë²”ìœ„ë¥¼ ê°€ì§€ëŠ”ê°€?

â‘  0 ë˜ëŠ” 1
â‘¡ ìŒìˆ˜ì—ì„œ ì–‘ìˆ˜
â‘¢ 0 ì´ìƒ 1 ì´í•˜ì˜ ì‹¤ìˆ˜
â‘£ ì •ìˆ˜

**ì •ë‹µ**: â‘¢ 0 ì´ìƒ 1 ì´í•˜ì˜ ì‹¤ìˆ˜
**í•´ì„¤**: ì‹œê·¸ëª¨ì´ë“œ í•¨ìˆ˜ì˜ ì¶œë ¥ê°’ì€ í•­ìƒ **(0, 1)** ì‚¬ì´ì˜ **í™•ë¥ ê°’**ì…ë‹ˆë‹¤.


### ë¬¸ì œ 2. ë¡œì§€ìŠ¤í‹± íšŒê·€ì—ì„œ ì‹œê·¸ëª¨ì´ë“œ í•¨ìˆ˜ì˜ ì—­í• ì€?

â‘  íŠ¹ì„± ì„ íƒ
â‘¡ ì •ê·œí™”
â‘¢ ì„ í˜• ì¡°í•©ì„ í™•ë¥ ê°’ìœ¼ë¡œ ë³€í™˜
â‘£ ê°€ì¤‘ì¹˜ ê°ì†Œ

**ì •ë‹µ**: â‘¢ ì„ í˜• ì¡°í•©ì„ í™•ë¥ ê°’ìœ¼ë¡œ ë³€í™˜
**í•´ì„¤**: $\sigma(z) = \frac{1}{1 + e^{-z}}$ì€ ì„ í˜• ì¡°í•© $z$ë¥¼ 0\~1 ì‚¬ì´ì˜ í™•ë¥ ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.

---
## 2. ë¡œì§€ìŠ¤í‹± íšŒê·€ ì‹¤ìŠµ


### ğŸ“¦ ë°ì´í„°ì…‹: Ai4I 2020 Predictive Maintenance Dataset

ì´ ë°ì´í„°ì…‹ì€ **ìŠ¤ë§ˆíŠ¸ ì œì¡° í™˜ê²½ì—ì„œì˜ ì˜ˆì¸¡ ìœ ì§€ë³´ìˆ˜**ë¥¼ ìœ„í•œ ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„°ë¡œ, ì„¼ì„œ ì¸¡ì •ê°’ê³¼ ê¸°ê³„ ê³ ì¥ ì—¬ë¶€ë¥¼ í¬í•¨í•©ë‹ˆë‹¤. ê³µê°œì ìœ¼ë¡œ ì ‘ê·¼ ê°€ëŠ¥í•œ ì´ ë°ì´í„°ì…‹ì€ ë‹¤ì–‘í•œ ì—°êµ¬ì— í™œìš©ë˜ê³  ìˆìŠµë‹ˆë‹¤.


* **ì¶œì²˜**: UCI Machine Learning Repository
* **ë°ì´í„° í˜•íƒœ**: CSV (ì•½ 10,000ê°œ ìƒ˜í”Œ, 14ê°œ ì—´)
* **ëª©ì **: ê³µì¥ ì„¤ë¹„ì—ì„œ ë°œìƒí•  ìˆ˜ ìˆëŠ” \*\*ê¸°ê³„ ê³ ì¥(Machine Failure)\*\*ì„ ì˜ˆì¸¡í•˜ê¸° ìœ„í•œ **ì´ì§„ ë¶„ë¥˜(binary classification)** ë¬¸ì œì…ë‹ˆë‹¤.



#### ì „ì²´ ì»¬ëŸ¼ ì„¤ëª…í‘œ

| ë³€ìˆ˜ëª… (ì»¬ëŸ¼ëª…)                 | ë°ì´í„° ìœ í˜•     | ì„¤ëª…                                    |
| ------------------------- | ---------- | ------------------------------------- |
| `UDI`                     | ì •ìˆ˜ (int)   | ê³ ìœ  ì‹ë³„ì (Unique ID)                    |
| `Product ID`              | ë¬¸ìì—´ (str)  | ì œí’ˆ ê³ ìœ  ì‹ë³„ì                             |
| `Type`                    | ë¬¸ìì—´ (str)  | ì œí’ˆ ìœ í˜• (L, M, H ì„¸ ê°€ì§€ íƒ€ì…)               |
| `Air temperature [K]`     | ì‹¤ìˆ˜ (float) | ê³µê¸° ì˜¨ë„ (ì¼ˆë¹ˆ ë‹¨ìœ„)                         |
| `Process temperature [K]` | ì‹¤ìˆ˜ (float) | ê³µì • ì˜¨ë„ (ì¼ˆë¹ˆ ë‹¨ìœ„)                         |
| `Rotational speed [rpm]`  | ì‹¤ìˆ˜ (float) | íšŒì „ ì†ë„ (ë¶„ë‹¹ íšŒì „ìˆ˜, rpm)                   |
| `Torque [Nm]`             | ì‹¤ìˆ˜ (float) | í† í¬ (Nm)                               |
| `Tool wear [min]`         | ì‹¤ìˆ˜ (float) | ê³µêµ¬ ë§ˆëª¨ ì‹œê°„ (ë¶„)                          |
| `TWF`                     | 0/1 (int)  | Tool Wear Failure (ê³µêµ¬ ë§ˆëª¨ ê³ ì¥ ì—¬ë¶€)       |
| `HDF`                     | 0/1 (int)  | Heat Dissipation Failure (ì—´ ë°©ì¶œ ê³ ì¥ ì—¬ë¶€) |
| `PWF`                     | 0/1 (int)  | Power Failure (ì „ë ¥ ê³ ì¥ ì—¬ë¶€)              |
| `OSF`                     | 0/1 (int)  | Overstrain Failure (ê³¼ë¶€í•˜ ê³ ì¥ ì—¬ë¶€)        |
| `RNF`                     | 0/1 (int)  | Random Failures (ì„ì˜ ê³ ì¥ ì—¬ë¶€)            |
| `Machine failure`         | 0/1 (int)  | **ìµœì¢… ê³ ì¥ ë°œìƒ ì—¬ë¶€ (Target ë³€ìˆ˜)**           |

---

#### íƒ€ê²Ÿ ë³€ìˆ˜ (Machine failure)

* `Machine failure`ëŠ” ìœ„ì˜ TWF, HDF, PWF, OSF, RNF ë‹¤ì„¯ ê°œì˜ ê³ ì¥ ì¤‘ **í•˜ë‚˜ë¼ë„ ë°œìƒí•˜ë©´ 1**, ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ 0ì…ë‹ˆë‹¤.

$$
\text{Machine failure} = \begin{cases}
1 & \text{(TWF or HDF or PWF or OSF or RNF = 1)} \\
0 & \text{(ëª¨ë‘ 0)}
\end{cases}
$$


#### ì˜ˆì‹œ í–‰ ë°ì´í„°

| UDI | Product ID | Type | Air Temp \[K] | Proc Temp \[K] | Rot Speed | Torque | Tool Wear | TWF | HDF | PWF | OSF | RNF | Machine failure |
| --- | ---------- | ---- | ------------- | -------------- | --------- | ------ | --------- | --- | --- | --- | --- | --- | --------------- |
| 1   | M14860     | M    | 298.1         | 308.6          | 1551      | 42.8   | 0         | 0   | 0   | 0   | 0   | 0   | 0               |


#### ì£¼ìš” ë¶„ì„ í¬ì¸íŠ¸

* **ì œí’ˆ ìœ í˜•(Type)**: L, M, H ê°„ ì„±ëŠ¥ ì°¨ì´ ì¡´ì¬ ê°€ëŠ¥
* **ì˜¨ë„/íšŒì „ìˆ˜/í† í¬ ë“± ë¬¼ë¦¬ ì„¼ì„œ ë³€ìˆ˜**ì™€ **ê³ ì¥ ë°œìƒ ì—¬ë¶€** ê°„ ê´€ê³„ ë¶„ì„ ê°€ëŠ¥
* **ê³ ì¥ ë¹„ìœ¨ì´ ë‚®ì•„ í´ë˜ìŠ¤ ë¶ˆê· í˜• ë¬¸ì œê°€ ì¡´ì¬í•  ìˆ˜ ìˆìŒ**


#### í™œìš© ê°€ëŠ¥ ë¬¸ì œ ìœ í˜•

| ë¬¸ì œ ìœ í˜• | ê°€ëŠ¥ ì—¬ë¶€ | ì„¤ëª…                            |
| ----- | ----- | ----------------------------- |
| ì´ì§„ ë¶„ë¥˜ | âœ…     | ë¨¸ì‹  ê³ ì¥ ì—¬ë¶€ ì˜ˆì¸¡                   |
| ë‹¤ì¤‘ ë¶„ë¥˜ | âœ…     | TWF, HDF, PWF ë“± ê°œë³„ ê³ ì¥ ìœ í˜• ë¶„ë¥˜   |
| ì´ìƒ íƒì§€ | âœ…     | ê³ ì¥ ë°œìƒì´ ë§¤ìš° ë“œë¬¼ë‹¤ë©´ ì´ìƒíƒì§€ ë¬¸ì œë¡œ ì ‘ê·¼ ê°€ëŠ¥ |
| íšŒê·€ ë¬¸ì œ | âŒ     | í˜„ì¬ëŠ” íšŒê·€í˜• ëª©í‘œë³€ìˆ˜ ì—†ìŒ               |

---

### ë¡œì§€ìŠ¤í‹± íšŒê·€ ì‹¤ìŠµ ì½”ë“œ

```python
# 1. ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix

# 2. ë°ì´í„° ë¡œë“œ
url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00601/ai4i2020.csv'
df = pd.read_csv(url)

# 3. ë°ì´í„° ì „ì²˜ë¦¬
# ë¶ˆí•„ìš”í•œ ì—´ ì œê±°
df.drop(['UDI', 'Product ID'], axis=1, inplace=True)


## ë²”ì£¼í˜• ë³€ìˆ˜ ì²˜ë¦¬
print(df.info())
print(df['Type'].value_counts())

df['Type'] = df['Type'].map({'H': 0, 'L': 1, 'M': 2})

# íƒ€ê²Ÿ ë³€ìˆ˜ì™€ íŠ¹ì„± ë¶„ë¦¬
X = df[['Type', 'Air temperature [K]', 'Process temperature [K]',
       'Rotational speed [rpm]', 'Torque [Nm]', 'Tool wear [min]' ] ]
y = df['Machine failure']

print(X.info())

# 4. ë°ì´í„° ë¶„í• 
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 5. ì •ê·œí™”
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# 6. ë¡œì§€ìŠ¤í‹± íšŒê·€ ëª¨ë¸ í•™ìŠµ
model = LogisticRegression(max_iter=1000)
model.fit(X_train_scaled, y_train)

# 7. ì˜ˆì¸¡ ë° í‰ê°€
y_pred = model.predict(X_test_scaled)

# ë¶„ë¥˜ ì„±ëŠ¥ í‰ê°€
print("Classification Report:")
print(classification_report(y_test, y_pred))

# 8. í˜¼ë™ í–‰ë ¬ ì‹œê°í™”
cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(6,4))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['No Failure', 'Failure'], yticklabels=['No Failure', 'Failure'])
plt.ylabel('Actual')
plt.xlabel('Predicted')
plt.title('Confusion Matrix')
plt.show()
```

---
# ğŸ“˜ 4ì¥. ë¶„ë¥˜ ëª¨ë¸

---
# ğŸ“˜ 5ì¥. k-ìµœê·¼ì ‘ ì´ì›ƒ ì•Œê³ ë¦¬ì¦˜ (k-Nearest Neighbors, kNN)


## 1. ê°œë…

\*\*k-ìµœê·¼ì ‘ ì´ì›ƒ ì•Œê³ ë¦¬ì¦˜(kNN)\*\*ì€ ê°€ì¥ ë‹¨ìˆœí•˜ë©´ì„œë„ ê°•ë ¥í•œ **ë¹„ëª¨ìˆ˜(non-parametric)** ì§€ë„ í•™ìŠµ ì•Œê³ ë¦¬ì¦˜ ì¤‘ í•˜ë‚˜ì…ë‹ˆë‹¤.

* ì£¼ì–´ì§„ ì…ë ¥ ë°ì´í„°ì— ëŒ€í•´ **ê°€ì¥ ê°€ê¹Œìš´ kê°œì˜ ì´ì›ƒ**ì„ ì°¾ê³ ,
* ê·¸ ì´ì›ƒë“¤ì˜ ë ˆì´ë¸”ì„ ë°”íƒ•ìœ¼ë¡œ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.


## 2. ì›ë¦¬

1. **í›ˆë ¨ ë‹¨ê³„ (Training)**

   * íŠ¹ë³„í•œ í•™ìŠµ ê³¼ì •ì´ ì—†ìŠµë‹ˆë‹¤. ëª¨ë“  í•™ìŠµ ë°ì´í„°ë¥¼ **ê¸°ì–µ**í•´ë‘¡ë‹ˆë‹¤.
   * ì¦‰, **ê¸°ì–µ ê¸°ë°˜ ëª¨ë¸(Memory-based model)** ë˜ëŠ” **Lazy Learning**ì´ë¼ê³  í•©ë‹ˆë‹¤.

2. **ì˜ˆì¸¡ ë‹¨ê³„ (Prediction)**
   ìƒˆë¡œìš´ ë°ì´í„° í¬ì¸íŠ¸ $x$ê°€ ë“¤ì–´ì˜¤ë©´:

   * í•™ìŠµ ë°ì´í„° ì „ì²´ì™€ì˜ ê±°ë¦¬ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
   * ê±°ë¦¬ ê¸°ì¤€ìœ¼ë¡œ ê°€ì¥ ê°€ê¹Œìš´ **kê°œì˜ ë°ì´í„°**ë¥¼ ì„ íƒí•©ë‹ˆë‹¤.
   * **ë¶„ë¥˜ ë¬¸ì œ**:

     * ë‹¤ìˆ˜ê²° íˆ¬í‘œ(Majority Voting)ë¥¼ í†µí•´ ê°€ì¥ ë§ì´ ë“±ì¥í•œ í´ë˜ìŠ¤ ì„ íƒ
   * **íšŒê·€ ë¬¸ì œ**:

     * kê°œì˜ í‰ê· ì„ ì‚¬ìš©í•´ ì˜ˆì¸¡


### ê±°ë¦¬ ê³„ì‚°

ê°€ì¥ ë„ë¦¬ ì“°ì´ëŠ” ê±°ë¦¬ í•¨ìˆ˜ëŠ” \*\*ìœ í´ë¦¬ë“œ ê±°ë¦¬(Euclidean distance)\*\*ì…ë‹ˆë‹¤:

$$
d(x, x_i) = \sqrt{ \sum_{j=1}^{n} (x_j - x_{ij})^2 }
$$

ê·¸ ì™¸ì—ë„:

* ë§¨í•´íŠ¼ ê±°ë¦¬: $\sum |x_j - x_{ij}|$
* ì½”ì‚¬ì¸ ê±°ë¦¬: $1 - \cos(\theta)$

---

## 3. í•˜ì´í¼íŒŒë¼ë¯¸í„°

| í•˜ì´í¼íŒŒë¼ë¯¸í„°      | ì„¤ëª…                                             |
| ------------ | ---------------------------------------------- |
| **k** (ì´ì›ƒ ìˆ˜) | ë„ˆë¬´ ì‘ìœ¼ë©´ ê³¼ì í•©, ë„ˆë¬´ í¬ë©´ ê³¼ì†Œì í•©                         |
| **ê±°ë¦¬ ì²™ë„**    | ìœ í´ë¦¬ë“œ, ë§¨í•´íŠ¼, ì½”ì‚¬ì¸ ë“±                               |
| **ê°€ì¤‘ì¹˜ ë°©ì‹**   | ì´ì›ƒ ê±°ë¦¬ì— ë”°ë¼ ê°€ì¤‘ì¹˜ë¥¼ ë‘˜ ìˆ˜ë„ ìˆìŒ (`uniform`, `distance`) |

---

## 4. ì¥ì ê³¼ ë‹¨ì 

| ì¥ì                     | ë‹¨ì                             |
| --------------------- | ----------------------------- |
| êµ¬í˜„ì´ ê°„ë‹¨í•¨               | ê³„ì‚° ë¹„ìš©ì´ í¼ (ì˜ˆì¸¡ ì‹œ ì „ì²´ ë°ì´í„°ì™€ ê±°ë¦¬ ê³„ì‚°) |
| ë¹„ëª¨ìˆ˜ ëª¨ë¸ (ë°ì´í„° ë¶„í¬ ê°€ì • ì—†ìŒ) | ê³ ì°¨ì›ì—ì„œëŠ” ì„±ëŠ¥ ì €í•˜ (ì°¨ì›ì˜ ì €ì£¼)         |
| ë‹¤ì¤‘ í´ë˜ìŠ¤/íšŒê·€ ëª¨ë‘ ê°€ëŠ¥       | í›ˆë ¨ ë°ì´í„°ê°€ ë§ì„ìˆ˜ë¡ ì†ë„ ëŠë¦¼            |


---

# ğŸ“˜ 6ì¥. ì„œí¬íŠ¸ ë²¡í„° ë¨¸ì‹ (Support Vector Machine, SVM)

## 1. ì—­ì‚¬ì  ë°°ê²½

* **1992ë…„**: ëŸ¬ì‹œì•„ ì¶œì‹ ì˜ **Vladimir Vapnik**ê³¼ **Alexey Chervonenkis**ê°€ ì´ë¡ ì  ê¸°ì´ˆì¸ **VC ì°¨ì›**(Vapnikâ€“Chervonenkis dimension)ê³¼ **êµ¬ê°„ ë¦¬ìŠ¤í¬ ìµœì†Œí™”** ê°œë…ì„ ë°œí‘œí–ˆìŠµë‹ˆë‹¤.
* **1995ë…„**: Vapnikê³¼ Cortesê°€ í˜„ëŒ€ì  ì˜ë¯¸ì˜ SVM ì•Œê³ ë¦¬ì¦˜ì„ ê³µì‹í™”í•¨. ì´ ë…¼ë¬¸ì€ "Support-Vector Networks"ë¼ëŠ” ì œëª©ìœ¼ë¡œ ë°œí‘œë˜ë©°, **ë§ˆì§„ ìµœëŒ€í™”**ì™€ \*\*ì»¤ë„ íŠ¸ë¦­(Kernel Trick)\*\*ì„ í†µí•´ ë¹„ì„ í˜• ë¶„ë¥˜ê¹Œì§€ í™•ì¥ë¨.
* **2000ë…„ëŒ€**: Bioinformatics, ë¬¸ì„œ ë¶„ë¥˜, ì´ë¯¸ì§€ ì¸ì‹ ë“± ë‹¤ì–‘í•œ ë¶„ì•¼ì—ì„œ **ê³ ì°¨ì› ì†Œê·œëª¨ ë°ì´í„°**ì— ê°•í•œ ë¶„ë¥˜ê¸°ë¡œ ë„ë¦¬ í™œìš©ë¨.

## 2. SVMì˜ í•µì‹¬ ì•„ì´ë””ì–´

* **ë§ˆì§„ ìµœëŒ€í™”**: í´ë˜ìŠ¤ë¥¼ êµ¬ë¶„í•˜ëŠ” **ê²°ì • ê²½ê³„**(Decision Boundary) ì¤‘, ê°€ì¥ \*\*ë„“ì€ ì—¬ë°±(Margin)\*\*ì„ ê°€ì§€ëŠ” ì„ í˜• ê²°ì • ê²½ê³„ë¥¼ ì°¾ìŒ.
* **ì„œí¬íŠ¸ ë²¡í„°**: ê²°ì • ê²½ê³„ì— ê°€ì¥ ê°€ê¹Œìš´ ë°ì´í„° í¬ì¸íŠ¸.
* **ì»¤ë„ ê¸°ë²•**: ë¹„ì„ í˜• ë°ì´í„°ë¥¼ ê³ ì°¨ì›ìœ¼ë¡œ ë§¤í•‘í•˜ì—¬ ì„ í˜• ë¶„ë¦¬ ê°€ëŠ¥í•˜ê²Œ ë§Œë“œëŠ” ë°©ë²•.


## 3. ìˆ˜í•™ì  ìˆ˜ì‹

### ëª©ì : ìµœëŒ€ ë§ˆì§„ ë¶„ë¦¬ ì´ˆí‰ë©´ ì°¾ê¸°

ì„ í˜• SVMì˜ ëª©ì ì€ ë‹¤ìŒê³¼ ê°™ì€ ì´ˆí‰ë©´ì„ ì°¾ëŠ” ê²ƒì…ë‹ˆë‹¤.

$$
\mathbf{w}^\top \mathbf{x} + b = 0
$$

í´ë˜ìŠ¤ëŠ” ë‹¤ìŒ ì¡°ê±´ì„ ë§Œì¡±í•´ì•¼ í•©ë‹ˆë‹¤:

$$
y_i (\mathbf{w}^\top \mathbf{x}_i + b) \geq 1 \quad \forall i
$$

### ìµœì í™” ë¬¸ì œ

$$
\min_{\mathbf{w}, b} \frac{1}{2} \|\mathbf{w}\|^2 \quad \text{subject to} \quad y_i(\mathbf{w}^\top \mathbf{x}_i + b) \geq 1
$$

ì´ ë¬¸ì œëŠ” **Convex Quadratic Programming** í˜•íƒœì´ë©°, Lagrange multiplier ê¸°ë²•ìœ¼ë¡œ ìµœì í™”ë©ë‹ˆë‹¤.

### ğŸ”„ ë¹„ì„ í˜• SVM (Kernel Trick)

$$
\phi(\mathbf{x})^\top \phi(\mathbf{x'}) = K(\mathbf{x}, \mathbf{x'})
$$

* ëŒ€í‘œ ì»¤ë„: ì„ í˜•(linear), ë‹¤í•­ì‹(polynomial), RBF(Gaussian), ì‹œê·¸ëª¨ì´ë“œ(sigmoid)

---

# ğŸ“˜ 7ì¥. ì˜ì‚¬ê²°ì •ë‚˜ë¬´ (Decision Tree) ì•Œê³ ë¦¬ì¦˜

## 1. ì—­ì‚¬ì  ë°°ê²½

* **1960ë…„ëŒ€**: í†µê³„í•™ ë¶„ì•¼ì—ì„œ ë¶„ë¥˜ ë° íšŒê·€ë¥¼ ìœ„í•œ íŠ¸ë¦¬ ê¸°ë°˜ ëª¨ë¸ì´ ì—°êµ¬ë˜ê¸° ì‹œì‘í•¨.
* **1986ë…„**: **J. Ross Quinlan**ì´ ë°œí‘œí•œ **ID3(Iterative Dichotomiser 3)** ì•Œê³ ë¦¬ì¦˜ì´ ë„ë¦¬ ì£¼ëª©ë°›ìœ¼ë©° ì˜ì‚¬ê²°ì •ë‚˜ë¬´ ì•Œê³ ë¦¬ì¦˜ì˜ í‘œì¤€ì´ ë¨.
* ì´í›„ **C4.5**(1993), **CART(Classification and Regression Tree)**(Breiman et al., 1984) ë“± ë‹¤ì–‘í•œ ë²„ì „ì´ ê°œë°œë¨.
* í˜„ì¬ëŠ” **Random Forest**, **XGBoost** ë“±ì˜ ì•™ìƒë¸” ê¸°ë°˜ íŠ¸ë¦¬ ëª¨ë¸ì˜ ê¸°ë³¸ ë‹¨ìœ„ë¡œë„ ì‚¬ìš©ë¨.


## 2. ì´ë¡ ì  ê°œë…

### ê¸°ë³¸ ì•„ì´ë””ì–´

ì˜ì‚¬ê²°ì •ë‚˜ë¬´ëŠ” ë°ì´í„°ë¥¼ \*\*íŠ¹ì„±(feature)\*\*ì— ë”°ë¼ ë¶„í• (split)í•˜ì—¬ **íŠ¸ë¦¬ í˜•íƒœë¡œ ë¶„ë¥˜** ë˜ëŠ” **ì˜ˆì¸¡**ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

* ë£¨íŠ¸ ë…¸ë“œ: ì „ì²´ ë°ì´í„°
* ë‚´ë¶€ ë…¸ë“œ: íŠ¹ì„± ê¸°ì¤€ìœ¼ë¡œ ë°ì´í„°ë¥¼ ë¶„í• 
* ë¦¬í”„ ë…¸ë“œ: ìµœì¢… ì˜ˆì¸¡ ê²°ê³¼(í´ë˜ìŠ¤ or ìˆ˜ì¹˜ ê°’)


### ë¶„í•  ê¸°ì¤€ (ì§€ë‹ˆ, ì—”íŠ¸ë¡œí”¼, ë¶„ì‚°)

#### (1) **ë¶„ë¥˜(Classification)** ë¬¸ì œ:

* **ì§€ë‹ˆ ë¶ˆìˆœë„(Gini Impurity)**

  $$
  Gini = 1 - \sum_{i=1}^n p_i^2
  $$
* **ì—”íŠ¸ë¡œí”¼(Entropy)**

  $$
  Entropy = - \sum_{i=1}^n p_i \log_2 p_i
  $$

â†’ ë‘ ê¸°ì¤€ ëª¨ë‘ ë¶ˆìˆœë„(í˜¼í•©ë„)ë¥¼ ìµœì†Œí™”í•˜ë„ë¡ ë¶„í• í•©ë‹ˆë‹¤.

#### (2) **íšŒê·€(Regression)** ë¬¸ì œ:

* **MSE (Mean Squared Error)** ë˜ëŠ” **MAE**ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¶„í• 

---

###  ê°€ì§€ì¹˜ê¸° (Pruning)

* **ì‚¬ì „ ê°€ì§€ì¹˜ê¸° (Pre-pruning)**: ê¹Šì´ ì œí•œ, ìµœì†Œ ë…¸ë“œ ìˆ˜ ì„¤ì • ë“±
* **ì‚¬í›„ ê°€ì§€ì¹˜ê¸° (Post-pruning)**: íŠ¸ë¦¬ë¥¼ ì™„ì„±í•œ í›„ ë¶ˆí•„ìš”í•œ ë…¸ë“œë¥¼ ì œê±°í•˜ì—¬ ê³¼ì í•© ë°©ì§€

---

## 3. ì•Œê³ ë¦¬ì¦˜ ìš”ì•½

1. ë£¨íŠ¸ ë…¸ë“œì—ì„œ ì‹œì‘
2. ê° íŠ¹ì„±ì— ëŒ€í•´ ìµœì  ë¶„í•  ê¸°ì¤€ì„ í‰ê°€ (ì§€ë‹ˆ, ì—”íŠ¸ë¡œí”¼ ë“±)
3. ê°€ì¥ ë¶ˆìˆœë„ë¥¼ ë§ì´ ì¤„ì´ëŠ” íŠ¹ì„±ìœ¼ë¡œ ë¶„í• 
4. ë¦¬í”„ ë…¸ë“œê°€ ë  ì¡°ê±´(ìˆœë„ê°€ ë†’ê±°ë‚˜ ìµœëŒ€ ê¹Šì´ ë„ë‹¬ ë“±)ê¹Œì§€ ë°˜ë³µ
5. ì˜ˆì¸¡ì€ ë¦¬í”„ ë…¸ë“œì˜ í´ë˜ìŠ¤(ë˜ëŠ” í‰ê· ê°’)ë¡œ ê²°ì •

---

# ğŸ“˜ 8ì¥. Random Forest ì•Œê³ ë¦¬ì¦˜


## 1. ì—­ì‚¬ì  ë°°ê²½

| í•­ëª©        | ë‚´ìš©                                                        |
| --------- | --------------------------------------------------------- |
| **ê³ ì•ˆì**   | ë ˆì˜¤ ë¸Œë ˆì´ë¨¼ (Leo Breiman), 2001ë…„ ë°œí‘œ                           |
| **ë…¼ë¬¸**    | â€œRandom Forestsâ€ (2001)                                   |
| **ê¸°ë°˜ ê°œë…** | ë°°ê¹…(Bagging: Bootstrap Aggregating) + ê²°ì • íŠ¸ë¦¬(Decision Tree) |
| **ê°œë°œ ëª©ì ** | ê°œë³„ ê²°ì •íŠ¸ë¦¬ì˜ ê³¼ì í•©(overfitting)ì„ ì¤„ì´ê³  ì˜ˆì¸¡ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•´            |

**ì´ì „ ë°°ê²½**

* 1996ë…„: Breimanì´ Bagging(ë°°ê¹…) ê¸°ë²• ì œì•ˆ
* ì´í›„, ì—¬ëŸ¬ ê°œì˜ ë°°ê¹…ëœ ê²°ì • íŠ¸ë¦¬ì— ë¬´ì‘ìœ„ì„±ì„ ë”í•´ **Random Forest**ë¡œ í™•ì¥

---

## 2. ì´ë¡ ì  ë°°ê²½

### í•µì‹¬ ê°œë…

**Random ForestëŠ” ì—¬ëŸ¬ ê°œì˜ Decision Treeë¥¼ í›ˆë ¨ì‹œí‚¨ ë’¤, ê° íŠ¸ë¦¬ì˜ ê²°ê³¼ë¥¼ ì¢…í•©í•˜ì—¬ ìµœì¢… ì˜ˆì¸¡ì„ ìˆ˜í–‰í•˜ëŠ” ì•™ìƒë¸” í•™ìŠµ ê¸°ë²•ì…ë‹ˆë‹¤.**

---

### ğŸ”· Bagging: Bootstrap Aggregating

* **Bootstrap**: ë°ì´í„°ì…‹ì—ì„œ **ì¤‘ë³µ í—ˆìš© ë¬´ì‘ìœ„ ìƒ˜í”Œë§**ìœ¼ë¡œ Nê°œì˜ í•™ìŠµìš© ìƒ˜í”Œ ìƒì„±
* **Aggregating**: ê°ê°ì˜ ëª¨ë¸ ê²°ê³¼ë¥¼ í‰ê· (íšŒê·€) ë˜ëŠ” íˆ¬í‘œ(ë¶„ë¥˜)ë¥¼ í†µí•´ ì¢…í•©

---

### ğŸ”· Randomness (ë¬´ì‘ìœ„ì„±) ë„ì…

1. **ë°ì´í„° ìƒ˜í”Œ ë¬´ì‘ìœ„ ì„ íƒ** (Bagging)
2. **ê° ë…¸ë“œì—ì„œ íŠ¹ì„±(feature) ë¬´ì‘ìœ„ ì„ íƒ** (ì˜ˆ: âˆšp ê°œ ì¤‘ ìµœì  ë¶„í•  íŠ¹ì„± ì„ íƒ)

ì´ ë‘ ê°€ì§€ ë¬´ì‘ìœ„ì„±ìœ¼ë¡œ ì¸í•´ **íŠ¸ë¦¬ ê°„ ìƒê´€ì„± ê°ì†Œ**, ê²°ê³¼ì ìœ¼ë¡œ **ì•™ìƒë¸” íš¨ê³¼ í–¥ìƒ** ë° **ê³¼ì í•© ê°ì†Œ** íš¨ê³¼ë¥¼ ì–»ìŒ.

---

### ğŸ”· ì•Œê³ ë¦¬ì¦˜ ë™ì‘ ê³¼ì •

1. **Tê°œì˜ ê²°ì • íŠ¸ë¦¬ ìƒì„±**

   * ê° íŠ¸ë¦¬ëŠ” Bootstrappingëœ ë°ì´í„°ë¡œ í•™ìŠµ
2. **ê° íŠ¸ë¦¬ì—ì„œ ë¬´ì‘ìœ„ í”¼ì²˜ ì„œë¸Œì…‹ ì„ íƒ**
3. **ê° íŠ¸ë¦¬ì˜ ê²°ê³¼ ì˜ˆì¸¡**

   * ë¶„ë¥˜: **ë‹¤ìˆ˜ê²° íˆ¬í‘œ(Majority Voting)**
   * íšŒê·€: **í‰ê· ê°’ ì‚°ì¶œ(Averaging)**


### ìš”ì•½ ë‹¤ì´ì–´ê·¸ë¨

```
                [ Training Set ]
                    â†“ Bootstrapping
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚              â”‚              â”‚              â”‚
[ Tree 1 ]     [ Tree 2 ]     [ Tree 3 ]   ...  [ Tree N ]
     â†“              â†“              â†“              â†“
[ ì˜ˆì¸¡ê°’ 1 ]   [ ì˜ˆì¸¡ê°’ 2 ]   [ ì˜ˆì¸¡ê°’ 3 ]   ...  [ ì˜ˆì¸¡ê°’ N ]
     â†“â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Aggregation â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†“
                [ ìµœì¢… ì˜ˆì¸¡ê°’ ]
```

---

### ğŸ”· ì£¼ìš” í•˜ì´í¼íŒŒë¼ë¯¸í„°

| í•˜ì´í¼íŒŒë¼ë¯¸í„°             | ì„¤ëª…                    |
| ------------------- | --------------------- |
| `n_estimators`      | ìƒì„±í•  íŠ¸ë¦¬ ê°œìˆ˜             |
| `max_features`      | ê° ë…¸ë“œ ë¶„í•  ì‹œ ê³ ë ¤í•  ìµœëŒ€ íŠ¹ì„± ìˆ˜ |
| `max_depth`         | ê° íŠ¸ë¦¬ì˜ ìµœëŒ€ ê¹Šì´           |
| `min_samples_split` | ë…¸ë“œë¥¼ ë¶„í• í•˜ê¸° ìœ„í•œ ìµœì†Œ ìƒ˜í”Œ ìˆ˜   |
| `bootstrap`         | ë¶€íŠ¸ìŠ¤íŠ¸ë© ìƒ˜í”Œ ì‚¬ìš© ì—¬ë¶€        |

---


## 3. ì¥ì  vs ë‹¨ì 

| ì¥ì                    | ë‹¨ì                  |
| -------------------- | ------------------ |
| ë†’ì€ ì˜ˆì¸¡ ì„±ëŠ¥             | í•´ì„ ì–´ë ¤ì›€ (ë¸”ë™ë°•ìŠ¤)      |
| ê³¼ì í•© ë°©ì§€ íš¨ê³¼            | ëŠë¦° í•™ìŠµ ì†ë„ (íŠ¸ë¦¬ê°€ ë§ìœ¼ë©´) |
| ë³€ìˆ˜ ì¤‘ìš”ë„ ì œê³µ ê°€ëŠ¥         | í° ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰          |
| ë²”ì£¼í˜•, ì—°ì†í˜• ë³€ìˆ˜ ëª¨ë‘ ì²˜ë¦¬ ê°€ëŠ¥ |                    |

---

## 4. í™œìš© ì˜ˆì‹œ

* **IoT**: ì„¼ì„œ ê³ ì¥ ì˜ˆì¸¡, ì¥ë¹„ ì´ìƒ íƒì§€
* **í—¬ìŠ¤ì¼€ì–´**: ì§ˆë³‘ ì§„ë‹¨ ë¶„ë¥˜
* **ê¸ˆìœµ**: ë¶€ë„ ìœ„í—˜ í‰ê°€
* **ì‚°ì—… ê³µì •**: ì˜ˆì§€ ì •ë¹„(Predictive Maintenance)

---
# ğŸ“˜ 9ì¥. XGBoost (eXtreme Gradient Boosting) ì•Œê³ ë¦¬ì¦˜

## **1. ì—­ì‚¬ì  ë°°ê²½**

### (1) ë¶€ìŠ¤íŒ… ì•Œê³ ë¦¬ì¦˜ì˜ íë¦„

| ì—°ë„     | ì•Œê³ ë¦¬ì¦˜                         | ì„¤ëª…                                   |
| ------ | ---------------------------- | ------------------------------------ |
| 1990ë…„ëŒ€ | AdaBoost                     | ê°€ì¥ ì²˜ìŒ ë„ë¦¬ ì‚¬ìš©ëœ ë¶€ìŠ¤íŒ… ëª¨ë¸. ê°€ì¤‘ì¹˜ ê¸°ë°˜ ë¶„ë¥˜ê¸° ì¡°í•©   |
| 2000ë…„ëŒ€ | Gradient Boosting (GBM)      | ì”ì°¨(residual)ì— ëŒ€í•œ ê¸°ìš¸ê¸°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì•½í•œ í•™ìŠµê¸° ì¶”ê°€ |
| 2014ë…„  | **XGBoost** (by Tianqi Chen) | GBMì˜ ë‹¨ì  ë³´ì™„ â†’ ì†ë„, ì„±ëŠ¥, ë³‘ë ¬ì„±ì—ì„œ í˜ì‹ ì  ê°œì„     |

> ğŸ“ ì°¸ê³ : XGBoostëŠ” **Kaggle** ë“±ì˜ ë¨¸ì‹ ëŸ¬ë‹ ê²½ì§„ëŒ€íšŒì—ì„œ ì••ë„ì  ì„±ëŠ¥ì„ ë³´ì—¬ì£¼ë©° ëŒ€ì¤‘ì ìœ¼ë¡œ ë„ë¦¬ í¼ì¡ŒìŠµë‹ˆë‹¤.

---

## **2. ì´ë¡ ì  ë°°ê²½**

### (1) Gradient Boostingì˜ ê¸°ë³¸ ê°œë…

* ëª©ì : ì—¬ëŸ¬ ê°œì˜ **ì•½í•œ í•™ìŠµê¸°(weak learner, ë³´í†µì€ ê²°ì • íŠ¸ë¦¬)** ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ í•™ìŠµí•˜ì—¬ ì ì  ì˜ˆì¸¡ë ¥ì„ ë†’ì„.
* ë°©ì‹: ì´ì „ ëª¨ë¸ì´ ë§Œë“  **ì˜¤ì°¨(ì”ì°¨)** ë¥¼ ì˜ˆì¸¡í•˜ë„ë¡ ë‹¤ìŒ ëª¨ë¸ì„ í›ˆë ¨

#### ê¸°ë³¸ ìˆ˜ì‹

ëª¨ë¸ì˜ ì˜ˆì¸¡ê°’ì„ $F(x)$ë¼ í•  ë•Œ, ì´ë¥¼ ë°˜ë³µì ìœ¼ë¡œ ê°±ì‹ :

$$
F_{m}(x) = F_{m-1}(x) + \gamma h_m(x)
$$

* $h_m(x)$: í˜„ì¬ ë‹¨ê³„ì—ì„œ í•™ìŠµí•˜ëŠ” ìƒˆë¡œìš´ íŠ¸ë¦¬
* $\gamma$: í•™ìŠµë¥  (learning rate)

---

### (2) XGBoostì˜ í•µì‹¬ ì•„ì´ë””ì–´

XGBoostëŠ” ê¸°ì¡´ Gradient Boostingì˜ ì•½ì ì„ ë³´ì™„í•˜ë©´ì„œ **ì†ë„ì™€ ì •í™•ë„ë¥¼ ê·¹ëŒ€í™”**í•˜ëŠ” ë° ì´ˆì ì„ ë§ì¶˜ ì•Œê³ ë¦¬ì¦˜ì…ë‹ˆë‹¤.

#### ğŸ”§ ê°œì„  ìš”ì†Œ

| ìš”ì†Œ              | ì„¤ëª…                          |
| --------------- | --------------------------- |
| **ì •ê·œí™” ì¶”ê°€**      | ê³¼ì í•© ë°©ì§€ë¥¼ ìœ„í•´ **L1/L2** ì •ê·œí™” í¬í•¨ |
| **ë³‘ë ¬ íŠ¸ë¦¬ ìƒì„±**    | íŠ¸ë¦¬ì˜ ë…¸ë“œë¥¼ ë³‘ë ¬ë¡œ ë¶„í• í•˜ì—¬ ì—°ì‚° ì†ë„ í–¥ìƒ   |
| **íˆìŠ¤í† ê·¸ë¨ ê¸°ë°˜ í•™ìŠµ** | ì—°ì†ê°’ì„ ì´ì‚°í™”í•˜ì—¬ í•™ìŠµ íš¨ìœ¨ í–¥ìƒ         |
| **ìŠ¤íŒŒìŠ¤ ë°ì´í„° ì²˜ë¦¬**  | ê²°ì¸¡ê°’ì„ ìë™ ê°ì§€í•˜ì—¬ ìµœì  ë¶„ê¸° ìƒì„±       |
| **Cache ìµœì í™”**   | ë‚´ë¶€ ë©”ëª¨ë¦¬ ì ‘ê·¼ ìµœì í™”ë¡œ ë¹ ë¥¸ ì—°ì‚°        |

---

### (3) XGBoostì˜ ëª©ì  í•¨ìˆ˜ (Objective Function)

XGBoostëŠ” ëª©ì  í•¨ìˆ˜ $Obj$ë¥¼ ë‹¤ìŒê³¼ ê°™ì´ ì •ì˜í•©ë‹ˆë‹¤:

$$
Obj = \sum_{i=1}^{n} l(y_i, \hat{y}_i) + \sum_{k=1}^{K} \Omega(f_k)
$$

* $l$: ì†ì‹¤ í•¨ìˆ˜ (ì˜ˆ: MSE, Log loss ë“±)
* $\Omega(f_k)$: ë³µì¡ë„ íŒ¨ë„í‹° (íŠ¸ë¦¬ì˜ ê¹Šì´, ë…¸ë“œ ìˆ˜ ë“±)

#### ë³µì¡ë„ í•­

$$
\Omega(f) = \gamma T + \frac{1}{2} \lambda \sum_{j=1}^{T} w_j^2
$$

* $T$: ë¦¬í”„ ë…¸ë“œì˜ ìˆ˜
* $w_j$: ë¦¬í”„ ë…¸ë“œì˜ ì¶œë ¥ ê°’
* $\gamma$, $\lambda$: ì •ê·œí™” ê³„ìˆ˜

---

### (4) XGBoost ì£¼ìš” í•˜ì´í¼íŒŒë¼ë¯¸í„°

| íŒŒë¼ë¯¸í„°                      | ì„¤ëª…                |
| ------------------------- | ----------------- |
| `n_estimators`            | ìƒì„±í•  íŠ¸ë¦¬ ìˆ˜          |
| `max_depth`               | íŠ¸ë¦¬ ìµœëŒ€ ê¹Šì´          |
| `learning_rate`           | ê° ë‹¨ê³„ì˜ ê¸°ì—¬ìœ¨         |
| `subsample`               | í›ˆë ¨ ìƒ˜í”Œ ë¹„ìœ¨ (ê³¼ì í•© ë°©ì§€) |
| `colsample_bytree`        | íŠ¸ë¦¬ë§ˆë‹¤ ì‚¬ìš©í•  íŠ¹ì„± ë¹„ìœ¨    |
| `reg_alpha`, `reg_lambda` | L1, L2 ì •ê·œí™” ê³„ìˆ˜     |

---
# 10ì¥. ë¶„ë¥˜ ëª¨ë¸ì— ëŒ€í•œ ì‹¤ìŠµ

## 1. ì‹¤ìŠµ ì½”ë“œ

```python
# 1. ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸°
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
import xgboost as xgb
import matplotlib.pyplot as plt
import seaborn as sns

# 2. ë°ì´í„° ë¡œë“œ
url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00601/ai4i2020.csv'
df = pd.read_csv(url)

# 3. ì „ì²˜ë¦¬
df.drop(['UDI', 'Product ID'], axis=1, inplace=True)
df['Type'] = df['Type'].map({'H': 0, 'L': 1, 'M': 2})
X = df[['Type', 'Air temperature [K]', 'Process temperature [K]',
        'Rotational speed [rpm]', 'Torque [Nm]', 'Tool wear [min]']]
X.columns = ['Type', 'AirTemp', 'ProcTemp', 'RotSpeed', 'Torque', 'ToolWear']
y = df['Machine failure']

print(X.head())

# 4. í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë¶„í• 
X_train, X_test, y_train, y_test = train_test_split(X, y,
                                                    test_size=0.2,
                                                    random_state=42,
                                                    stratify=y)

# 5. ì •ê·œí™” (kNN, SVMë§Œ ì‚¬ìš©)
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# 6. ëª¨ë¸ ì •ì˜
models = {
    "kNN": KNeighborsClassifier(),
    "SVM": SVC(),
    "Decision Tree": DecisionTreeClassifier(random_state=42),
    "Random Forest": RandomForestClassifier(random_state=42),
    "XGBoost": xgb.XGBClassifier(eval_metric='logloss', random_state=42)
}

# 7. ê²°ê³¼ ì €ì¥
results = {}

# 8. í•™ìŠµ ë° ì˜ˆì¸¡
for name, model in models.items():
    if name in ['kNN', 'SVM']:
        model.fit(X_train_scaled, y_train)
        y_pred = model.predict(X_test_scaled)
    else:
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)

    cm = confusion_matrix(y_test, y_pred)
    cr = classification_report(y_test, y_pred, output_dict=True)
    results[name] = {
        "confusion_matrix": cm,
        "classification_report": cr
    }

# 9. í˜¼ë™ í–‰ë ¬ ì‹œê°í™”
fig, axes = plt.subplots(2, 3, figsize=(12, 8))
axes = axes.flatten()

for ax, (name, result) in zip(axes, results.items()):
    sns.heatmap(result["confusion_matrix"], annot=True, fmt='d', cmap='Blues', ax=ax)
    ax.set_title(f"{name} Confusion Matrix")
    ax.set_xlabel("Predicted")
    ax.set_ylabel("Actual")

plt.tight_layout()
plt.show()

# 10. ì„±ëŠ¥ ì¶œë ¥
for name, result in results.items():
    print(f"\n===== {name} =====")
    print("Confusion Matrix:")
    print(result["confusion_matrix"])
    print("\nClassification Report:")
    print(pd.DataFrame(result["classification_report"]).transpose())
```

## 2. íŠ¹ì§• ì¤‘ìš”ë„

```python
# 11. ì¤‘ìš”ë„ ì¶”ì¶œ ë° ë¹„êµ
features = X.columns
dt_importance = models['Decision Tree'].feature_importances_
rf_importance = models['XGBoost'].feature_importances_

# 12. ì‹œê°í™”
import numpy as np
fig, ax = plt.subplots(figsize=(10, 6))
x = np.arange(len(features))
width = 0.35

bars1 = ax.bar(x - width/2, dt_importance, width, label='Decision Tree')
bars2 = ax.bar(x + width/2, rf_importance, width, label='Random Forest')

# ìƒë‹¨ì— ê°’ í‘œì‹œ
for bar in bars1 + bars2:
    height = bar.get_height()
    ax.annotate(f'{height:.2f}', xy=(bar.get_x() + bar.get_width()/2, height),
                xytext=(0, 3), textcoords="offset points", ha='center', va='bottom', fontsize=9)

# ê·¸ë˜í”„ ì„¤ì •
ax.set_ylabel("Feature Importance")
ax.set_title("Feature Importance: Decision Tree vs Random Forest")
ax.set_xticks(x)
ax.set_xticklabels(features, rotation=45)
ax.legend()
plt.tight_layout()
plt.show()

=======
## - https://shorturl.at/SduTO
## ë°ì´í„°
## - https://shorturl.at/toAqE
## - https://shorturl.at/4LiWF
---
# ğŸ“˜ **3ë¶€. ìŠ¤ë§ˆíŠ¸ í—¬ìŠ¤ ê°œìš” ë° ê¸°ë°˜ ê¸°ìˆ **

# ğŸ“— **1ì¥. ìŠ¤ë§ˆíŠ¸ í—¬ìŠ¤ë€ ë¬´ì—‡ì¸ê°€**


## ğŸ”¹ 1. ìŠ¤ë§ˆíŠ¸ í—¬ìŠ¤ì˜ ì •ì˜ ë° ë“±ì¥ ë°°ê²½

ìŠ¤ë§ˆíŠ¸ í—¬ìŠ¤(Smart Health)ë€ ì •ë³´í†µì‹ ê¸°ìˆ (ICT), ì¸ê³µì§€ëŠ¥(AI), IoT ì„¼ì„œ, ë¹…ë°ì´í„° ë“±ì„ í™œìš©í•˜ì—¬ ê°œì¸ ë§ì¶¤í˜• ê±´ê°• ê´€ë¦¬ì™€ ì˜ˆë°© ì¤‘ì‹¬ì˜ í—¬ìŠ¤ì¼€ì–´ ì„œë¹„ìŠ¤ë¥¼ ì œê³µí•˜ëŠ” íŒ¨ëŸ¬ë‹¤ì„ì…ë‹ˆë‹¤. ê¸°ì¡´ì˜ ë³‘ì› ì¤‘ì‹¬ ì¹˜ë£Œ ìœ„ì£¼ì—ì„œ ë²—ì–´ë‚˜, **ì–¸ì œ ì–´ë””ì„œë‚˜ ê±´ê°• ì •ë³´ë¥¼ ìˆ˜ì§‘Â·ë¶„ì„í•˜ê³ , ì‹¤ì‹œê°„ìœ¼ë¡œ í”¼ë“œë°±ì„ ì œê³µ**í•¨ìœ¼ë¡œì¨ ì˜ˆë°©ê³¼ ìê¸° ì£¼ë„ ê±´ê°•ê´€ë¦¬ë¥¼ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤.

### â–ª ì£¼ìš” ë°°ê²½

* **ê³ ë ¹í™” ì‚¬íšŒì˜ ë„ë˜**: ë§Œì„±ì§ˆí™˜ ì¦ê°€ì™€ ì˜ë£Œë¹„ ë¶€ë‹´ ì¦ê°€
* **ICT ê¸°ìˆ  ë°œì „**: IoT ì„¼ì„œ, ì›¨ì–´ëŸ¬ë¸” ë””ë°”ì´ìŠ¤ ë³´ê¸‰
* **ë°ì´í„° ê¸°ë°˜ ì˜ë£Œ**: EHR, PHR, ì›¨ì–´ëŸ¬ë¸” ë¡œê·¸ ë“± ë‹¤ì–‘í•œ ì˜ë£Œ ë°ì´í„°
* **ì˜ë£Œ ìì›ì˜ ë¶ˆê· í˜•**: ì§€ì—­ ê°„ ì˜ë£Œ ì ‘ê·¼ì„± ê²©ì°¨ í•´ì†Œ í•„ìš”ì„±

---

## ğŸ”¹ 2. ê¸°ì¡´ í—¬ìŠ¤ì¼€ì–´ì™€ ìŠ¤ë§ˆíŠ¸ í—¬ìŠ¤ì˜ ë¹„êµ

| êµ¬ë¶„     | ê¸°ì¡´ í—¬ìŠ¤ì¼€ì–´      | ìŠ¤ë§ˆíŠ¸ í—¬ìŠ¤                  |
| ------ | ------------ | ----------------------- |
| ì¤‘ì‹¬ ë°©ì‹  | ë³‘ì› ë°©ë¬¸, ì§„ë£Œ ì¤‘ì‹¬ | ë¹„ëŒ€ë©´, ì‹¤ì‹œê°„ ë°ì´í„° ê¸°ë°˜         |
| ì‚¬ìš©ì ì—­í•  | ìˆ˜ë™ì (ì˜ì‚¬ ì£¼ë„)   | ëŠ¥ë™ì (ì‚¬ìš©ì ìŠ¤ìŠ¤ë¡œ ê±´ê°• ê´€ë¦¬)      |
| ë°ì´í„° ìˆ˜ì§‘ | ë³‘ì› ë‚´ ê²€ì‚¬      | ì„¼ì„œ, ì›¨ì–´ëŸ¬ë¸”, ìŠ¤ë§ˆíŠ¸í° ë“± ì‹¤ì‹œê°„ ìˆ˜ì§‘ |
| ê¸°ìˆ  í™œìš©  | ì œí•œì  (EMR ë“±)  | IoT, AI, ë¹…ë°ì´í„°, í´ë¼ìš°ë“œ í™œìš©  |
| ëª©ì      | ì§ˆë³‘ ì§„ë‹¨ ë° ì¹˜ë£Œ   | ì˜ˆë°©, ì¡°ê¸° ë°œê²¬, ê±´ê°• ì¦ì§„        |

---

## ğŸ”¹ 3. ìŠ¤ë§ˆíŠ¸ í—¬ìŠ¤ êµ¬ì„± ìš”ì†Œ

ìŠ¤ë§ˆíŠ¸ í—¬ìŠ¤ëŠ” ì—¬ëŸ¬ ê¸°ìˆ ê³¼ ì‹œìŠ¤í…œì´ í†µí•©ì ìœ¼ë¡œ ì‘ë™í•˜ì—¬ ê°œì¸ì˜ ê±´ê°•ì„ ê´€ë¦¬í•©ë‹ˆë‹¤. êµ¬ì„± ìš”ì†ŒëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.

| êµ¬ì„± ìš”ì†Œ            | ì„¤ëª…                                  |
| ---------------- | ----------------------------------- |
| **IoT ì„¼ì„œ/ë””ë°”ì´ìŠ¤**  | ì‹¬ë°•ìˆ˜, ìš´ë™ëŸ‰, ìˆ˜ë©´ ë“±ì„ ì‹¤ì‹œê°„ ì¸¡ì •í•˜ëŠ” ì›¨ì–´ëŸ¬ë¸” ê¸°ê¸°    |
| **ë°ì´í„° ìˆ˜ì§‘ ë° í†µì‹ **  | BLE, WiFi, NB-IoT ë“± ë‹¤ì–‘í•œ ë°©ì‹ìœ¼ë¡œ ë°ì´í„° ì „ì†¡ |
| **í—¬ìŠ¤ ë°ì´í„° í”Œë«í¼**   | ìˆ˜ì§‘ëœ ë°ì´í„°ë¥¼ í†µí•© ì €ì¥, ë¶„ì„ ê°€ëŠ¥í•œ í™˜ê²½           |
| **AI/ML ë¶„ì„ ê¸°ìˆ **  | ê±´ê°• ìƒíƒœ ì˜ˆì¸¡, ì´ìƒ ì§•í›„ ê°ì§€ ë“± ì§€ëŠ¥í˜• ë¶„ì„ ìˆ˜í–‰      |
| **í”¼ë“œë°± ë° ì•Œë¦¼ ì‹œìŠ¤í…œ** | ì‚¬ìš©ì ë§ì¶¤í˜• ê±´ê°• ë¦¬í¬íŠ¸, ê²½ê³  ë©”ì‹œì§€ ì œê³µ           |

---

## ğŸ”¹ 4. ìŠ¤ë§ˆíŠ¸ í—¬ìŠ¤ ê¸°ìˆ  ë°œì „ ì—°í‘œ

| ì—°ë„        | ì£¼ìš” ë°œì „ ë‚´ìš©                               |
| --------- | -------------------------------------- |
| 2010ë…„ëŒ€ ì´ˆë°˜ | ì›¨ì–´ëŸ¬ë¸” ê¸°ê¸°(ì˜ˆ: Fitbit, Jawbone) ìƒìš©í™”        |
| 2014ë…„     | ì• í”Œ í—¬ìŠ¤í‚·(HealthKit), êµ¬ê¸€ í•(Google Fit) ì¶œì‹œ |
| 2016ë…„     | ë”¥ëŸ¬ë‹ ê¸°ë°˜ í”¼ë¶€ë³‘, ì•ˆì € ë¶„ì„ ê¸°ìˆ  ìƒìš©í™”               |
| 2020ë…„ ì´í›„  | ì½”ë¡œë‚˜19 ëŒ€ì‘ ë¹„ëŒ€ë©´ ì§„ë£Œ, ìŠ¤ë§ˆíŠ¸ ë³‘ì› í™•ì‚°             |
| 2023ë…„ ì´í›„  | ìƒì²´ì‹ í˜¸ ê¸°ë°˜ ìŠ¤íŠ¸ë ˆìŠ¤, ìˆ˜ë©´, ì‹¬í˜ˆê´€ ë¦¬ìŠ¤í¬ ì˜ˆì¸¡ ì†”ë£¨ì…˜ ë“±ì¥    |

---

# ğŸ“— **2ì¥. ìŠ¤ë§ˆíŠ¸ í—¬ìŠ¤ë¥¼ ìœ„í•œ ë°ì´í„° ì´í•´**



## ğŸ”¹ 1. í—¬ìŠ¤ì¼€ì–´ ë°ì´í„°ì˜ ìœ í˜•

ìŠ¤ë§ˆíŠ¸ í—¬ìŠ¤ì—ì„œ í™œìš©ë˜ëŠ” ë°ì´í„°ëŠ” ë§¤ìš° ë‹¤ì–‘í•˜ë©°, ê°ê¸° ë‹¤ë¥¸ í˜•ì‹ê³¼ íŠ¹ì„±ì„ ê°€ì§‘ë‹ˆë‹¤. ëŒ€í‘œì ì¸ í—¬ìŠ¤ì¼€ì–´ ë°ì´í„°ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.

| ë°ì´í„° ìœ í˜•                              | ì„¤ëª…                      | ì˜ˆì‹œ                           |
| ----------------------------------- | ----------------------- | ---------------------------- |
| **EMR (Electronic Medical Record)** | ë³‘ì› ë‚´ì—ì„œ ìˆ˜ì§‘ë˜ëŠ” í™˜ì ì§„ë£Œ ê¸°ë¡    | ì§„ë‹¨ì½”ë“œ, íˆ¬ì•½ ë‚´ì—­, ê²€ì‚¬ ê²°ê³¼ ë“±         |
| **EHR (Electronic Health Record)**  | ì—¬ëŸ¬ ê¸°ê´€ ê°„ ê³µìœ  ê°€ëŠ¥í•œ ì˜ë£Œê¸°ë¡     | EMR + ìƒí™œìŠµê´€, ë°±ì‹ , ì˜ìƒ ë“±         |
| **PHR (Personal Health Record)**    | ê°œì¸ì´ ìˆ˜ì§‘/ê´€ë¦¬í•˜ëŠ” ê±´ê°• ë°ì´í„°      | ìŠ¤ë§ˆíŠ¸ì›Œì¹˜, ì•± ê¸°ë°˜ ìê°€ ê¸°ë¡ ë“±          |
| **ìƒì²´ì‹ í˜¸ (Biosignals)**               | ì‹ ì²´ ê¸°ëŠ¥ì—ì„œ ì¸¡ì •ë˜ëŠ” ì „ê¸°ì /ë¬¼ë¦¬ì  ì‹ í˜¸ | ECG, PPG, EMG, EEG, ì²´ì˜¨, í˜¸í¡ ë“± |
| **í–‰ë™ ë° í™˜ê²½ ë°ì´í„°**                     | ì‚¬ìš©ìì˜ ìš´ë™, ìˆ˜ë©´, ìœ„ì¹˜, ë‚ ì”¨ ë“±   | ê±¸ìŒ ìˆ˜, ìˆ˜ë©´ ì‹œê°„, GPS, ì˜¨ìŠµë„ ë“±      |

---

## ğŸ”¹ 2. ëŒ€í‘œì ì¸ ìƒì²´ì‹ í˜¸ì™€ íŠ¹ì§•

ìŠ¤ë§ˆíŠ¸ í—¬ìŠ¤ì—ì„œëŠ” ë‹¤ì–‘í•œ \*\*ìƒì²´ì‹ í˜¸(Biosignal)\*\*ë¥¼ ë¶„ì„í•˜ì—¬ ê±´ê°• ìƒíƒœë¥¼ ì¶”ì •í•©ë‹ˆë‹¤. ëŒ€í‘œì ì¸ ì‹ í˜¸ë“¤ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.

| ì‹ í˜¸              | ì¸¡ì • ëŒ€ìƒ      | ì£¼ìš” í™œìš©            | íŠ¹ì§•                 |
| --------------- | ---------- | ---------------- | ------------------ |
| **ECG (ì‹¬ì „ë„)**   | ì‹¬ì¥ ì „ê¸° ì‹ í˜¸   | ì‹¬ë°•ìˆ˜, HRV, ë¶€ì •ë§¥ ì§„ë‹¨ | ê³ í•´ìƒë„, R-peak ê²€ì¶œ    |
| **PPG (ê´‘ìš©ì ë§¥íŒŒ)** | í˜ˆë¥˜ ë³€í™”      | ë§¥ë°•ìˆ˜, í˜ˆì¤‘ ì‚°ì†Œí¬í™”ë„    | ì°©ìš© ê°„í¸, ìš´ë™ ì‹œ ë…¸ì´ì¦ˆ ë¯¼ê° |
| **EEG (ë‡ŒíŒŒ)**    | ë‡Œì˜ ì „ê¸°í™œë™    | ìˆ˜ë©´ ë¶„ì„, ë°œì‘ ê°ì§€     | ì±„ë„ ìˆ˜ ë§ê³  ì²˜ë¦¬ ë³µì¡      |
| **EMG (ê·¼ì „ë„)**   | ê·¼ìœ¡ ìˆ˜ì¶•      | ê·¼í”¼ë¡œë„ ë¶„ì„, ì¬í™œì¹˜ë£Œ    | ì§§ì€ ì‹œê°„ ì‹ í˜¸, ì¡ìŒ ì˜í–¥ í¼  |
| **í˜¸í¡/ì²´ì˜¨**       | í˜¸í¡ë¥ , ì²´ì˜¨ ë³€í™” | í˜¸í¡ê¸°ì§ˆí™˜, ë°œì—´ ê°ì§€     | í™˜ê²½ ì˜¨ë„ì— ì˜í–¥ ë°›ì„ ìˆ˜ ìˆìŒ  |

> ECG: [ìœ„í‚¤ë°±ê³¼ ì‹¬ì „ë„](https://ko.wikipedia.org/wiki/%EC%8B%AC%EC%A0%84%EB%8F%84)
> PPG: [LEDë¡œ ì‹¬ë°•ìˆ˜ë¥¼ ì¸¡ì •í•œë‹¤ê³ ? 'ê´‘í˜ˆë¥˜ì¸¡ì • ì„¼ì„œ(PPG)'](https://news.samsungdisplay.com/30140)
> EEG: [ìœ„í‚¤ë°±ê³¼ ë‡ŒíŒŒ](https://ko.wikipedia.org/wiki/%EB%87%8C%ED%8C%8C)
> EMG: [ìœ„í‚¤ë°±ê³¼ ê·¼ì „ë„ ê²€ì‚¬](https://ko.wikipedia.org/wiki/%EA%B7%BC%EC%A0%84%EB%8F%84_%EA%B2%80%EC%82%AC)
> í˜¸í¡ ì„¼ì„œ: [í˜¸í¡ë¶„ì„ê¸° 'PACER'](https://blog.naver.com/geekstarter/223752501610)
---


## ğŸ”¹ 3. ì›¨ì–´ëŸ¬ë¸” í—¬ìŠ¤ ì„¼ì„œì˜ ê°œìš”

ì›¨ì–´ëŸ¬ë¸” í—¬ìŠ¤ ì„¼ì„œëŠ” ì‚¬ìš©ìì˜ ìƒì²´ì‹ í˜¸ ë˜ëŠ” í–‰ë™ ì •ë³´ë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ì¸¡ì •í•˜ê³  ê¸°ë¡í•˜ëŠ” IoT ê¸°ë°˜ ì¥ì¹˜ì…ë‹ˆë‹¤. ì†ëª©, ê°€ìŠ´, ê·€, ë°œëª©, í”¼ë¶€ ë“±ì— ë¶€ì°©ë˜ì–´ ë™ì‘í•˜ë©°, ìŠ¤ë§ˆíŠ¸ í—¬ìŠ¤ì˜ í•µì‹¬ ë°ì´í„° ìˆ˜ì§‘ ë„êµ¬ë¡œ í™œìš©ë©ë‹ˆë‹¤.

| ì„¼ì„œ í˜•íƒœ | ì˜ˆì‹œ ê¸°ê¸°                       | ì¸¡ì • ì •ë³´            |
| ----- | --------------------------- | ---------------- |
| ì†ëª©í˜•   | Apple Watch, Galaxy Watch   | ì‹¬ë°•ìˆ˜, ìš´ë™ëŸ‰, ìˆ˜ë©´, ì²´ì˜¨ |
| íŒ¨ì¹˜í˜•   | Zephyr BioPatch, VitalPatch | ECG, PPG, í˜¸í¡, ì²´ì˜¨ |
| ê·€ê±¸ì´í˜•  | Earin, Cosinuss One         | ì‹¬ë°•ìˆ˜, ì²´ì˜¨          |
| ë°˜ì§€í˜•   | Oura Ring                   | HRV, ìˆ˜ë©´ ë‹¨ê³„       |
| ì˜ë¥˜í˜•   | Hexoskin, Athos             | í˜¸í¡, EMG, ì‹¬ì „ë„     |

---

## ğŸ”¹ 4. ì„¼ì„œì˜ ì¸¡ì • ì›ë¦¬

| ì„¼ì„œ ì¢…ë¥˜            | ì¸¡ì • ì›ë¦¬                    | ì¸¡ì • í•­ëª©               |
| ---------------- | ------------------------ | ------------------- |
| **ECG ì„¼ì„œ**       | í”¼ë¶€ í‘œë©´ ì „ê·¹ì„ í†µí•´ ì‹¬ì¥ ì „ê¸°ì‹ í˜¸ ì¸¡ì •  | ì‹¬ë°•ìˆ˜, R-R ê°„ê²©, ë¶€ì •ë§¥ íƒì§€ |
| **PPG ì„¼ì„œ**       | ì ì™¸ì„ /ë…¹ìƒ‰ê´‘ì„ í˜ˆê´€ì— ì¡°ì‚¬í•˜ì—¬ ë°˜ì‚¬ê´‘ ì¸¡ì • | ë§¥ë°•ìˆ˜, í˜ˆì¤‘ ì‚°ì†Œí¬í™”ë„       |
| **IMU (ê´€ì„±ì¸¡ì •ì„¼ì„œ)** | ê°€ì†ë„ê³„ì™€ ìì´ë¡œìŠ¤ì½”í”„ ê¸°ë°˜          | ê±¸ìŒ ìˆ˜, ìì„¸, í™œë™ ì¸ì‹     |
| **ì²´ì˜¨ ì„¼ì„œ**        | ì„œë¯¸ìŠ¤í„°, ì ì™¸ì„  ì¸¡ì •             | í”¼ë¶€ ì˜¨ë„, ì¤‘ì‹¬ ì²´ì˜¨ ì¶”ì •     |
| **í˜¸í¡ ì„¼ì„œ**        | ì••ë ¥ ë³€í™”, ìŠ¤íŠ¸ë ˆì¸ ê²Œì´ì§€ í™œìš©       | í˜¸í¡ë¥ , íí™œëŸ‰ ì¶”ì •         |

---

## ğŸ”¹ 5. ë°ì´í„° ì „ì†¡ ë° í†µì‹  ê¸°ìˆ 

ì›¨ì–´ëŸ¬ë¸” ì„¼ì„œëŠ” ìˆ˜ì§‘ëœ ë°ì´í„°ë¥¼ ìŠ¤ë§ˆíŠ¸í° ë˜ëŠ” í´ë¼ìš°ë“œë¡œ ì „ì†¡í•˜ê¸° ìœ„í•´ ë‹¤ì–‘í•œ í†µì‹  ê¸°ìˆ ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.

| í†µì‹  ê¸°ìˆ                           | íŠ¹ì§•               | ì ìš© ì‚¬ë¡€               |
| ------------------------------ | ---------------- | ------------------- |
| **BLE (Bluetooth Low Energy)** | ì§§ì€ ê±°ë¦¬, ì €ì „ë ¥       | ìŠ¤ë§ˆíŠ¸ì›Œì¹˜ â†” ìŠ¤ë§ˆíŠ¸í°        |
| **Wi-Fi**                      | ë¹ ë¥¸ ì†ë„, ì „ë ¥ ì†Œëª¨ í¼   | ìŠ¤ë§ˆíŠ¸ ì²´ì¤‘ê³„ â†” ê°€ì •ìš© Wi-Fi |
| **NB-IoT / LTE-M**             | ì €ì „ë ¥, ì¥ê±°ë¦¬, ì…€ë£°ëŸ¬ ê¸°ë°˜ | ë³‘ì› ì„œë²„ë¡œ ë°ì´í„° ì „ì†¡       |
| **ZigBee**                     | ì €ì „ë ¥, ë‹¤ìˆ˜ ì„¼ì„œ ì—°ê²°    | ì‹¤ë‚´ìš© ê±´ê°• ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ     |
| **UWB (ì´ˆê´‘ëŒ€ì—­)**                 | ìœ„ì¹˜ ì •í™•ë„ ë†’ìŒ        | ì‹¤ë‚´ í™˜ì ì¶”ì , ë‚™ìƒ ê°ì§€     |

---

## ğŸ”¹ 4. ì›¨ì–´ëŸ¬ë¸” ì„¼ì„œì˜ ë°ì´í„° íŠ¹ì„±

* **ì—°ì†ì„±**: ì‹¤ì‹œê°„ ì—°ì† ì¸¡ì •ìœ¼ë¡œ ì‹œê³„ì—´ ë°ì´í„° ìƒì„±
* **ë…¸ì´ì¦ˆ í¬í•¨**: ì›€ì§ì„, í”¼ë¶€ ì ‘ì´‰ ë¶ˆëŸ‰ ë“±ìœ¼ë¡œ ì¸í•œ ì¡ìŒ ì¡´ì¬
* **ì‚¬ìš©ì ê°„ ë‹¤ì–‘ì„±**: ìƒë¦¬ì  ì°¨ì´ë¡œ ì¸í•´ ê°œì¸ë³„ ê¸°ì¤€ ìƒì´
* **ì „ë ¥ ì†Œëª¨ ê³ ë ¤ í•„ìš”**: ì„¼ì„œ ì„¤ê³„ ë° ìˆ˜ì§‘ ì£¼ê¸° ìµœì í™” í•„ìš”

---

## ğŸ”¹ 6. ì›¨ì–´ëŸ¬ë¸” ì„¼ì„œ ì„ íƒ ì‹œ ê³ ë ¤ ìš”ì†Œ

| ê³ ë ¤ í•­ëª©       | ì„¤ëª…                         |
| ----------- | -------------------------- |
| **ì •í™•ë„**     | ì˜ë£Œ ê¸°ì¤€ ì¶©ì¡± ì—¬ë¶€ (ì˜ˆ: FDA ì¸ì¦ ì—¬ë¶€) |
| **ë°°í„°ë¦¬ ìˆ˜ëª…**  | ì§€ì†ì ì¸ ì¸¡ì • ê°€ëŠ¥ ì‹œê°„              |
| **í¸ì˜ì„±**     | ì‚¬ìš©ìì˜ ì°©ìš©ê°, ìœ„ì¹˜ ì œí•œ            |
| **í†µì‹  ë°©ì‹**   | ì‚¬ìš© í™˜ê²½ì— ë§ëŠ” ì—°ê²°ì„±              |
| **ë°ì´í„° ì ‘ê·¼ì„±** | API ì œê³µ ì—¬ë¶€, ë°ì´í„° ë‚´ë³´ë‚´ê¸° ê°€ëŠ¥ì„±    |

---

# ğŸ“— **4ì¥. ìŠ¤ë§ˆíŠ¸ í—¬ìŠ¤ ì„œë¹„ìŠ¤ ì‚¬ë¡€**



## ğŸ”¹ 1. ìŠ¤ë§ˆíŠ¸ í—¬ìŠ¤ ì„œë¹„ìŠ¤ì˜ ë¶„ë¥˜

ìŠ¤ë§ˆíŠ¸ í—¬ìŠ¤ ì„œë¹„ìŠ¤ëŠ” ì œê³µ ì£¼ì²´ì™€ ê¸°ìˆ  ë°©ì‹ì— ë”°ë¼ ë‹¤ìŒê³¼ ê°™ì´ êµ¬ë¶„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

| ìœ í˜•            | ì„¤ëª…                 | ì˜ˆì‹œ                           |
| ------------- | ------------------ | ---------------------------- |
| **ê°œì¸ ê±´ê°• ê´€ë¦¬í˜•** | ì›¨ì–´ëŸ¬ë¸” ê¸°ë°˜ ì‹¤ì‹œê°„ ê±´ê°• ê´€ë¦¬  | Apple Health, Samsung Health |
| **ì§ˆë³‘ ì˜ˆì¸¡/ì§„ë‹¨í˜•** | AI ê¸°ë°˜ ì¡°ê¸° ì§„ë‹¨, ìœ„í—˜ ì˜ˆì¸¡ | SkinVision, Lunit INSIGHT    |
| **ì›ê²© ëª¨ë‹ˆí„°ë§í˜•**  | ë³‘ì›ê³¼ í™˜ì ê°„ ì—°ê²°, ì§€ì† ì¶”ì  | Livongo, Dexcom              |
| **ìŠ¤ë§ˆíŠ¸ ë³‘ì›í˜•**   | ë³‘ì› ë‚´ ë””ì§€í„¸ ì‹œìŠ¤í…œ í†µí•©    | ì„¸ë¸Œë€ìŠ¤ ìŠ¤ë§ˆíŠ¸ ë³‘ì›, Mayo Clinic     |

---

## ğŸ”¹ 2. ìŠ¤ë§ˆíŠ¸ í—¬ìŠ¤ ì„œë¹„ìŠ¤ ì‚¬ë¡€

### (1) **Apple Health [(ì• í”Œ í—¬ìŠ¤)](https://www.apple.com/health/)**

* **ê¸°ëŠ¥**: ì‹¬ë°•ìˆ˜, ìš´ë™ëŸ‰, ìˆ˜ë©´ ê¸°ë¡, ì‹¬ë°©ì„¸ë™ ê°ì§€
* **ì„¼ì„œ**: Apple Watch (ECG, PPG, IMU ë“± ë‚´ì¥)
* **ë¶„ì„**: iOS ê¸°ë°˜ì˜ ê±´ê°• ì•±ì—ì„œ ì‹œê°í™”
* **íŠ¹ì§•**: EHR ì—°ë™, ë¯¸êµ­ ë‚´ ì¼ë¶€ ë³‘ì›ê³¼ ì§ì ‘ ì—°ê²° ê°€ëŠ¥

### (2) **Fitbit [(by Google)](https://store.google.com/gb/category/watches_trackers?hl=en-GB)**

* **ê¸°ëŠ¥**: ìš´ë™, ìˆ˜ë©´, ìŠ¤íŠ¸ë ˆìŠ¤ ì¶”ì 
* **AI ê¸°ìˆ **: ìˆ˜ë©´ ì ìˆ˜ ê³„ì‚°, HRV ê¸°ë°˜ ìŠ¤íŠ¸ë ˆìŠ¤ ì§€ìˆ˜
* **ë°ì´í„° í†µí•©**: Fitbit ì•± + Google Health í†µí•© í”Œë«í¼
* **íŠ¹ì§•**: FDA ìŠ¹ì¸ ECG ê¸°ëŠ¥ ì œê³µ

### (3) **SkinVision [(ë„¤ëœë€ë“œ)](https://www.skinvision.com/)**

* **ê¸°ëŠ¥**: í”¼ë¶€ì•” ìœ„í—˜ë„ ìê°€ ì§„ë‹¨
* **ê¸°ìˆ **: ìŠ¤ë§ˆíŠ¸í° ì¹´ë©”ë¼ ê¸°ë°˜ CNN í”¼ë¶€ ë¶„ì„
* **ì„±ê³¼**: í‘ìƒ‰ì¢… ì¡°ê¸° ë°œê²¬ ì •í™•ë„ 95% ì´ìƒ
* **í™œìš©**: ì‚¬ìš©ìê°€ ì£¼ê¸°ì  ì‚¬ì§„ ì´¬ì˜ â†’ AI ë¶„ì„ ê²°ê³¼ í™•ì¸


### (4) **ì‚¼ì„± í—¬ìŠ¤ [(Samsung Health)](https://www.samsung.com/sec/apps/samsung-health/)**

* **ê¸°ëŠ¥**: ê±¸ìŒ ìˆ˜, ìˆ˜ë©´, ìŠ¤íŠ¸ë ˆìŠ¤, í˜ˆì¤‘ ì‚°ì†Œí¬í™”ë„ ì¸¡ì •
* **ì„¼ì„œ ì—°ë™**: Galaxy Watch ì‹œë¦¬ì¦ˆ
* **ë¶„ì„**: HRV ê¸°ë°˜ ìŠ¤íŠ¸ë ˆìŠ¤ ì¶”ì •, ìˆ˜ë©´ ë‹¨ê³„ ìë™ ë¶„ì„
* **íŠ¹ì§•**: ì‚¼ì„± ìŠ¤ë§ˆíŠ¸í°ê³¼ ìë™ ì—°ë™, ê¸€ë¡œë²Œ 1ì–µ ì´ìƒ ì‚¬ìš©ì

---

## ğŸ”¹ 3. ìŠ¤ë§ˆíŠ¸ í—¬ìŠ¤ ì„œë¹„ìŠ¤ ì„¤ê³„ ì‹œ ê³ ë ¤ì‚¬í•­

| í•­ëª©             | ê³ ë ¤ ìš”ì†Œ                     |
| -------------- | ------------------------- |
| **ë°ì´í„° ì •í™•ì„±**    | ì˜ë£Œê¸°ê¸° ìˆ˜ì¤€ ì¸ì¦ í•„ìš” (FDA, CE ë“±) |
| **ê°œì¸í™” ìˆ˜ì¤€**     | ì—°ë ¹, ì„±ë³„, ìƒíƒœë³„ ë§ì¶¤í˜• ì•Œê³ ë¦¬ì¦˜      |
| **ì—°ë™ì„±**        | EHR, ë³‘ì› ì‹œìŠ¤í…œ, ëª¨ë°”ì¼ ì•± ì—°ê³„ ê°€ëŠ¥ì„± |
| **ì„¤ëª… ê°€ëŠ¥ì„±**     | AI ê²°ê³¼ì˜ ê·¼ê±° ì œì‹œ ì—¬ë¶€           |
| **ë³´ì•ˆ ë° í”„ë¼ì´ë²„ì‹œ** | ìƒì²´ì •ë³´ ì•”í˜¸í™”, GDPR/ê°œì¸ì •ë³´ë³´í˜¸ë²• ì¤€ìˆ˜ |

---

# 4ë¶€: ë¨¸ì‹ ëŸ¬ë‹ì˜ ì´í•´ì™€ í™œìš©

---

# ğŸ“– **1ì¥. ë¨¸ì‹ ëŸ¬ë‹ ê°œìš”**



## âœ¨ 1. ë¨¸ì‹ ëŸ¬ë‹ì´ë€ ë¬´ì—‡ì¸ê°€

ë¨¸ì‹ ëŸ¬ë‹(Machine Learning)ì´ë€,  
ëª…ì‹œì ìœ¼ë¡œ í”„ë¡œê·¸ë¨ì„ ì‘ì„±í•˜ì§€ ì•Šê³ ë„ ë°ì´í„°ë¥¼ ì´ìš©í•˜ì—¬ ì»´í“¨í„°ê°€ ìŠ¤ìŠ¤ë¡œ í•™ìŠµí•˜ê³  ì„±ëŠ¥ì„ ê°œì„ í•˜ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤.

Arthur Samuelì€ ë¨¸ì‹ ëŸ¬ë‹ì„ "**ëª…ì‹œì ìœ¼ë¡œ í”„ë¡œê·¸ë˜ë°í•˜ì§€ ì•Šê³  ì»´í“¨í„°ê°€ í•™ìŠµí•  ìˆ˜ ìˆê²Œ í•˜ëŠ” ì—°êµ¬ ë¶„ì•¼**"ë¼ê³  ì •ì˜í•˜ì˜€ìŠµë‹ˆë‹¤.

ë¨¸ì‹ ëŸ¬ë‹ì€ ì…ë ¥ ë°ì´í„°ë¡œë¶€í„° íŒ¨í„´ì„ í•™ìŠµí•˜ì—¬,  
**ìƒˆë¡œìš´ ë°ì´í„°ì— ëŒ€í•´ ì˜ˆì¸¡í•˜ê±°ë‚˜ ë¶„ë¥˜í•˜ëŠ” ëª¨ë¸**ì„ êµ¬ì¶•í•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•©ë‹ˆë‹¤.

### â¡ï¸ ë¨¸ì‹ ëŸ¬ë‹ ê¸°ë³¸ êµ¬ì„± ìš”ì†Œ
| êµ¬ì„± ìš”ì†Œ | ì„¤ëª… |
|:--|:--|
| ë°ì´í„° | í•™ìŠµ ë° ì˜ˆì¸¡ì„ ìœ„í•œ ì…ë ¥ ìë£Œ |
| ëª¨ë¸ | ë°ì´í„°ì˜ íŒ¨í„´ì„ í•™ìŠµí•˜ëŠ” êµ¬ì¡° |
| í•™ìŠµ ì•Œê³ ë¦¬ì¦˜ | ëª¨ë¸ì„ ìµœì í™”í•˜ëŠ” ë°©ë²• |
| ì˜ˆì¸¡ | í•™ìŠµí•œ ëª¨ë¸ë¡œ ìƒˆë¡œìš´ ë°ì´í„°ì— ëŒ€í•œ ê²°ê³¼ ìƒì„± |

## âœ¨ 2. ë¨¸ì‹ ëŸ¬ë‹ì˜ ì£¼ìš” ë¶„ë¥˜

ë¨¸ì‹ ëŸ¬ë‹ì€ í•™ìŠµ ë°©ì‹ì— ë”°ë¼ í¬ê²Œ ì„¸ ê°€ì§€ë¡œ ë¶„ë¥˜ë©ë‹ˆë‹¤.

| ë¶„ë¥˜ | ì„¤ëª… | ì˜ˆì‹œ |
|:--|:--|:--|
| ì§€ë„í•™ìŠµ (Supervised Learning) | ì…ë ¥ê³¼ ì •ë‹µ(label)ì„ ì´ìš©í•˜ì—¬ í•™ìŠµ | ë¶„ë¥˜(Classification), íšŒê·€(Regression) |
| ë¹„ì§€ë„í•™ìŠµ (Unsupervised Learning) | ì •ë‹µ ì—†ì´ ë°ì´í„° êµ¬ì¡°ë¥¼ í•™ìŠµ | í´ëŸ¬ìŠ¤í„°ë§(Clustering), ì°¨ì› ì¶•ì†Œ(Dimensionality Reduction) |
| ê°•í™”í•™ìŠµ (Reinforcement Learning) | ë³´ìƒì„ í†µí•´ ìµœì  í–‰ë™ì„ í•™ìŠµ | ê²Œì„ í”Œë ˆì´, ë¡œë´‡ ì œì–´ |


---

## âœ¨ 3. ë¨¸ì‹ ëŸ¬ë‹ ì›Œí¬í”Œë¡œìš°

ë¨¸ì‹ ëŸ¬ë‹ í”„ë¡œì íŠ¸ëŠ” ë‹¤ìŒê³¼ ê°™ì€ ë‹¨ê³„ë¥¼ ê±°ì¹©ë‹ˆë‹¤.

### â¡ï¸ ì „í˜•ì ì¸ ë¨¸ì‹ ëŸ¬ë‹ ì›Œí¬í”Œë¡œìš°

1. **ë¬¸ì œ ì •ì˜**
2. **ë°ì´í„° ìˆ˜ì§‘**
3. **ë°ì´í„° ì „ì²˜ë¦¬ ë° íƒìƒ‰**
4. **íŠ¹ì„± ì„ íƒ ë° ìƒì„±**
5. **ëª¨ë¸ ì„ íƒ ë° í•™ìŠµ**
6. **ëª¨ë¸ í‰ê°€**
7. **ëª¨ë¸ ê°œì„  ë° ìµœì í™”**
8. **ìµœì¢… ëª¨ë¸ ë°°í¬**

```
ë°ì´í„° ìˆ˜ì§‘ â†’ ë°ì´í„° ì „ì²˜ë¦¬ â†’ ëª¨ë¸ í•™ìŠµ â†’ ëª¨ë¸ í‰ê°€ â†’ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ â†’ ìµœì¢… ì˜ˆì¸¡
```

- ì´ ê³¼ì •ì—ì„œ **ë°ì´í„° ì „ì²˜ë¦¬ì™€ ëª¨ë¸ ì„ íƒ**ì´ ì„±ëŠ¥ì— ê°€ì¥ í° ì˜í–¥ì„ ë¯¸ì¹©ë‹ˆë‹¤.
---

# ğŸ“– **2ì¥. ë°ì´í„° ì „ì²˜ë¦¬ì™€ íŠ¹ì„± ê³µí•™**



## âœ¨ 1. ê²°ì¸¡ì¹˜ ì²˜ë¦¬ì™€ ì´ìƒê°’ íƒì§€

### â¡ï¸ ê²°ì¸¡ì¹˜(Missing Value) ì²˜ë¦¬

ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì€ ê²°ì¸¡ê°’ì„ í¬í•¨í•˜ëŠ” ë°ì´í„°ë¥¼ ì§ì ‘ ë‹¤ë£¨ì§€ ëª»í•˜ëŠ” ê²½ìš°ê°€ ë§ìŠµë‹ˆë‹¤.  
ë”°ë¼ì„œ ì ì ˆí•œ ë°©ë²•ìœ¼ë¡œ ê²°ì¸¡ê°’ì„ ì²˜ë¦¬í•´ì•¼ í•©ë‹ˆë‹¤.

| ë°©ë²• | ì„¤ëª… | ì˜ˆì‹œ |
|:--|:--|:--|
| ì‚­ì œ (Drop) | ê²°ì¸¡ì¹˜ê°€ ìˆëŠ” í–‰ ë˜ëŠ” ì—´ì„ ì œê±° | `dropna()` |
| ëŒ€ì²´ (Imputation) | í‰ê· , ì¤‘ì•™ê°’, ìµœë¹ˆê°’ ë“±ìœ¼ë¡œ ëŒ€ì²´ | `fillna(value)` |

> âœ… ë°ì´í„°ì˜ ë¶„í¬ë¥¼ ê³ ë ¤í•˜ì—¬ ëŒ€ì²´í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤.

### â¡ï¸ ì´ìƒê°’(Outlier) íƒì§€

ì´ìƒê°’ì€ ë°ì´í„° ë¶„í¬ì—ì„œ ë²—ì–´ë‚œ ê°’ì…ë‹ˆë‹¤.  
ì£¼ë¡œ IQR, Z-Score ë“±ì„ í™œìš©í•˜ì—¬ íƒì§€í•©ë‹ˆë‹¤.

| ë°©ë²• | ì„¤ëª… |
|:--|:--|
| IQR ë°©ë²• | Q1, Q3 ê¸°ì¤€ìœ¼ë¡œ ì´ìƒ ë²”ìœ„ ì™¸ ê°’ íƒì§€ |
| Z-Score ë°©ë²• | í‰ê·  ëŒ€ë¹„ í‘œì¤€í¸ì°¨ ë²”ìœ„ë¥¼ ë²—ì–´ë‚œ ê°’ íƒì§€ |

---

## âœ¨ 2. ë²”ì£¼í˜• ë³€ìˆ˜ ì¸ì½”ë”©

ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì€ ìˆ˜ì¹˜í˜• ë°ì´í„°ë§Œ ì…ë ¥ìœ¼ë¡œ ë°›ê¸° ë•Œë¬¸ì—,  
ë²”ì£¼í˜•(categorical) ë°ì´í„°ëŠ” ìˆ˜ì¹˜ë¡œ ë³€í™˜í•´ì•¼ í•©ë‹ˆë‹¤.

| ì¸ì½”ë”© ë°©ë²• | ì„¤ëª… | ì˜ˆì‹œ |
|:--|:--|:--|
| ë ˆì´ë¸” ì¸ì½”ë”© (Label Encoding) | ê° ì¹´í…Œê³ ë¦¬ë¥¼ ì •ìˆ˜ë¡œ ë§¤í•‘ | Male â†’ 0, Female â†’ 1 |
| ì›-í•« ì¸ì½”ë”© (One-Hot Encoding) | ê° ì¹´í…Œê³ ë¦¬ë¥¼ 0/1ë¡œ ë³€í™˜í•˜ëŠ” ë²¡í„° ìƒì„± | `get_dummies(), to_categorical()` ì‚¬ìš© |

> âœ… ë² ì´ì§€ì•ˆ ë£°, íŠ¸ë¦¬ ê¸°ë°˜ ëª¨ë¸ì€ ë ˆì´ë¸” ì¸ì½”ë”©ì„ ì‚¬ìš©í•´ë„ ê´œì°®ì§€ë§Œ,  
> âœ… ì„ í˜• ëª¨ë¸(SVM, ë¡œì§€ìŠ¤í‹± íšŒê·€ ë“±)ì—ì„œëŠ” ì›-í•« ì¸ì½”ë”©ì´ ë” ì í•©í•©ë‹ˆë‹¤.

---

## âœ¨ 3. ì •ê·œí™”ì™€ í‘œì¤€í™”

íŠ¹ì„±(feature)ë“¤ì˜ ìŠ¤ì¼€ì¼ì´ ë‹¤ë¥¼ ê²½ìš°,  
ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì€ íŠ¹ì • íŠ¹ì„±ì— ì§€ë‚˜ì¹˜ê²Œ ë¯¼ê°í•˜ê²Œ ë°˜ì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.  
ì´ë¥¼ ë°©ì§€í•˜ê¸° ìœ„í•´ ìŠ¤ì¼€ì¼ ì¡°ì •ì´ í•„ìš”í•©ë‹ˆë‹¤.

| ë°©ë²• | ì„¤ëª… | ìˆ˜ì‹ |
|:--|:--|:--|
| ì •ê·œí™” (Normalization) | ëª¨ë“  ê°’ì„ 0~1 ë²”ìœ„ë¡œ ë³€í™˜ | $x' = \frac{x - x_{min}}{x_{max} - x_{min}}$ |
| í‘œì¤€í™” (Standardization) | í‰ê·  0, í‘œì¤€í¸ì°¨ 1ë¡œ ë³€í™˜ | $x' = \frac{x - \mu}{\sigma}$ |

> âœ… KNN, SVM ê°™ì€ ê±°ë¦¬ ê¸°ë°˜ ì•Œê³ ë¦¬ì¦˜ì€ ì •ê·œí™”/í‘œì¤€í™”ê°€ ë§¤ìš° ì¤‘ìš”í•©ë‹ˆë‹¤.

---

## âœ¨ 4. íŠ¹ì„± ì„ íƒê³¼ ì°¨ì› ì¶•ì†Œ

ëª¨ë“  íŠ¹ì„±ì´ ì˜ˆì¸¡ì— ìœ ìš©í•œ ê²ƒì€ ì•„ë‹™ë‹ˆë‹¤.  
**íŠ¹ì„± ì„ íƒ(Feature Selection)** ì€ ì¤‘ìš”í•œ íŠ¹ì„±ë§Œ ê³¨ë¼ ëª¨ë¸ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ëŠ” ê³¼ì •ì…ë‹ˆë‹¤.

| ë°©ë²• | ì„¤ëª… |
|:--|:--|
| í•„í„° ë°©ì‹ (Filter) | í†µê³„ì  ê¸°ì¤€(ìƒê´€ê³„ìˆ˜ ë“±)ìœ¼ë¡œ ì„ íƒ |
| ë˜í¼ ë°©ì‹ (Wrapper) | ëª¨ë¸ì„ í†µí•´ ìµœì  íŠ¹ì„± ì¡°í•© íƒìƒ‰ |
| ì„ë² ë””ë“œ ë°©ì‹ (Embedded) | ëª¨ë¸ í•™ìŠµ ì¤‘ íŠ¹ì„± ì„ íƒ (ex. Lasso) |

ë˜í•œ ê³ ì°¨ì› ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´  
**ì°¨ì› ì¶•ì†Œ(Dimensionality Reduction)** ê¸°ë²•(PCA ë“±)ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

---

## âœ¨ 5. ë°ì´í„° ë¶„í• : í•™ìŠµ/ê²€ì¦/í…ŒìŠ¤íŠ¸ì…‹

ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ì •í™•íˆ í‰ê°€í•˜ê¸° ìœ„í•´, ë°ì´í„°ë¥¼ ë‹¤ìŒê³¼ ê°™ì´ ë¶„í• í•©ë‹ˆë‹¤.

| êµ¬ë¶„ | ì„¤ëª… | ì¼ë°˜ì ì¸ ë¹„ìœ¨ |
|:--|:--|:--|
| í•™ìŠµì…‹ (Training Set) | ëª¨ë¸ì„ í•™ìŠµì‹œí‚¤ëŠ” ë°ì´í„° | 60~80% |
| ê²€ì¦ì…‹ (Validation Set) | í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ìš© ë°ì´í„° | 10~20% |
| í…ŒìŠ¤íŠ¸ì…‹ (Test Set) | ìµœì¢… ì„±ëŠ¥ í‰ê°€ìš© ë°ì´í„° | 10~20% |

> âœ… êµì°¨ ê²€ì¦(Cross Validation) ê¸°ë²•ì„ ì‚¬ìš©í•˜ë©´ ë³´ë‹¤ ì•ˆì •ì ì¸ í‰ê°€ê°€ ê°€ëŠ¥í•©ë‹ˆë‹¤.

---

## ğŸ› ï¸ ì‹¤ìŠµ: íƒ€ì´íƒ€ë‹‰ ë°ì´í„° ì „ì²˜ë¦¬ 

```python
# íƒ€ì´íƒ€ë‹‰ ë°ì´í„° ì „ì²˜ë¦¬

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

# ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
titanic = pd.read_csv('https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv')
print(titanic.info())
print(titanic.head(10))

# 1. ê²°ì¸¡ì¹˜ ì²˜ë¦¬
titanic['Age'] = titanic['Age'].fillna(titanic['Age'].median())
titanic['Embarked'] = titanic['Embarked'].fillna(titanic['Embarked'].mode()[0])
print(titanic.info())
print(titanic.head(10))

# 2. ë²”ì£¼í˜• ë³€ìˆ˜ ì¸ì½”ë”©
print(titanic['Sex'].value_counts())
print(titanic['Embarked'].value_counts())
titanic['Sex'] = titanic['Sex'].map({'female': 0, 'male': 1})
titanic['Embarked'] = titanic['Embarked'].map({'C':0, 'S':1, 'Q':2})
print(titanic.head(10))

# 3. ë¶ˆí•„ìš”í•œ ì—´ ì œê±°
titanic.drop(['Name', 'Ticket', 'Cabin', 'PassengerId'], axis=1, inplace=True)
print(titanic.head(10))

# 4. íŠ¹ì„±ê³¼ íƒ€ê¹ƒ ë¶„ë¦¬
X = titanic.drop('Survived', axis=1)
y = titanic['Survived']

# 5. ë°ì´í„° ë¶„í• 
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 6. ì •ê·œí™” (í‘œì¤€í™”)
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

print("íƒ€ì´íƒ€ë‹‰ ë°ì´í„° ì „ì²˜ë¦¬ ì™„ë£Œ!")
print("í›ˆë ¨ ë°ì´í„° í¬ê¸°:", X_train.shape)
print("í…ŒìŠ¤íŠ¸ ë°ì´í„° í¬ê¸°:", X_test.shape)
```
---


# ğŸ“˜ 3ì¥. íšŒê·€ ë¶„ì„(Regression)

íšŒê·€ ë¶„ì„ì€ **ì—°ì†ì ì¸ ê°’ì„ ì˜ˆì¸¡**í•  ë•Œ ì‚¬ìš©í•˜ëŠ” ëŒ€í‘œì ì¸ ê¸°ê³„í•™ìŠµ ì•Œê³ ë¦¬ì¦˜ì…ë‹ˆë‹¤.

| í•­ëª©      | ì„¤ëª…                                                |
| ------- | ------------------------------------------------- |
| ëª©ì       | ì…ë ¥ ë³€ìˆ˜ë¡œë¶€í„° ìˆ˜ì¹˜í˜• ì¶œë ¥ê°’ ì˜ˆì¸¡                               |
| ì˜ˆì‹œ      | ê¸°ì˜¨, ìŠµë„ â†’ ì‘ë¬¼ ìƒì¥ëŸ‰, ìˆ˜í™•ëŸ‰ ì˜ˆì¸¡                           |
| ëŒ€í‘œ ì•Œê³ ë¦¬ì¦˜ | ì„ í˜• íšŒê·€(Linear Regression), ë¦¿ì§€ íšŒê·€(Ridge), ë¼ì˜(Lasso) |

### ì ìš© ì˜ˆ

* ê¸°ìƒ ë°ì´í„° ê¸°ë°˜ **ìˆ˜í™•ëŸ‰ ì˜ˆì¸¡**
* ì´ì‚°í™”íƒ„ì†Œ ë†ë„ì— ë”°ë¥¸ **ìƒìœ¡ ì†ë„ ì˜ˆì¸¡**
---

# ğŸ”¹ ì„ í˜• íšŒê·€ (Linear Regression)



## 1. ì—­ì‚¬ì  ë°°ê²½


#### 1.. ê¸°ì›

* **1805ë…„**: í”„ë‘ìŠ¤ ìˆ˜í•™ì **Adrien-Marie Legendre**ê°€ â€˜ìµœì†Œì œê³±ë²•(Least Squares Method)â€™ì„ ë„ì…í•˜ì—¬ ì²œë¬¸í•™ì  ê´€ì¸¡ ë°ì´í„°ì˜ ì˜¤ì°¨ë¥¼ ìµœì†Œí™”í•˜ë ¤ í–ˆìŠµë‹ˆë‹¤.
* **1809ë…„**: ë…ì¼ ìˆ˜í•™ì **Carl Friedrich Gauss**ë„ ë™ì¼í•œ ë°©ë²•ì„ ë…ìì ìœ¼ë¡œ ê°œë°œí•˜ì—¬ **ì •ê·œë¶„í¬ì™€ì˜ ì—°ê²°**ì„ ì´ë¡ í™”í•˜ì˜€ìŠµë‹ˆë‹¤.

#### 2.. í†µê³„í•™ìœ¼ë¡œì˜ í™•ì¥

* **19ì„¸ê¸° í›„ë°˜**: í†µê³„í•™ì **Francis Galton**ì´ ì¸ê°„ í‚¤ì˜ ìƒê´€ê´€ê³„ ë¶„ì„ì„ í†µí•´ â€˜íšŒê·€(regression)â€™ë¼ëŠ” ìš©ì–´ë¥¼ ë„ì…í•˜ì˜€ìŠµë‹ˆë‹¤.

  * ì•„ë²„ì§€ í‚¤ì™€ ì•„ë“¤ í‚¤ ê°„ì˜ ê´€ê³„ì—ì„œ í‰ê· ìœ¼ë¡œ ë˜ëŒì•„ê°€ëŠ” ì„±ì§ˆ â†’ â€œíšŒê·€(regression) toward the meanâ€

#### 3.. ì»´í“¨í„° ì‹œëŒ€ ì´í›„

* 20ì„¸ê¸° ì¤‘ë°˜ ì´í›„ íšŒê·€ ë¶„ì„ì€ ì»´í“¨í„°ë¥¼ í†µí•´ ìë™í™”ë˜ë©° í†µê³„í•™, ê²½ì œí•™, ê³µí•™, ìƒë¬¼í•™ ë“± ë‹¤ì–‘í•œ ë¶„ì•¼ì—ì„œ **ê¸°ì´ˆ ì˜ˆì¸¡ ë„êµ¬**ë¡œ ìë¦¬ì¡ê²Œ ë©ë‹ˆë‹¤.

---

## 2. ì´ë¡ ì  ì•Œê³ ë¦¬ì¦˜ 

#### 1.. ëª©í‘œ
ì…ë ¥ ë³€ìˆ˜ $X$ì™€ ì¶œë ¥ ë³€ìˆ˜ $y$ ì‚¬ì´ì˜ **ì„ í˜• ê´€ê³„**ë¥¼ ëª¨ë¸ë§í•˜ì—¬, ìƒˆë¡œìš´ ì…ë ¥ ê°’ì— ëŒ€í•œ **ì—°ì†ì  ì¶œë ¥ ê°’**ì„ ì˜ˆì¸¡í•˜ëŠ” ê²ƒ.

#### 2.. ìˆ˜ì‹ í‘œí˜„

$$
\hat{y} = w_1 x_1 + w_2 x_2 + \cdots + w_n x_n + b = \mathbf{Xw} + b
$$

* $\hat{y}$: ì˜ˆì¸¡ê°’
* $\mathbf{X}$: ì…ë ¥ ë²¡í„°
* $\mathbf{w}$: ê°€ì¤‘ì¹˜ ë²¡í„°
* $b$: ì ˆí¸(intercept)

#### 3.. ëª©ì  í•¨ìˆ˜ (ë¹„ìš© í•¨ìˆ˜, Loss Function)

\*\*MSE (Mean Squared Error)\*\*ë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜¤ì°¨ë¥¼ ìµœì†Œí™”í•©ë‹ˆë‹¤:

$$
J(\mathbf{w}, b) = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2
$$

---

## 3. ê°€ì • ì¡°ê±´

ì„ í˜• íšŒê·€ëŠ” ë‹¤ìŒì˜ í†µê³„ì  ê°€ì •ì„ ì „ì œë¡œ í•©ë‹ˆë‹¤:

| ê°€ì •                              | ì„¤ëª…                    |
| ------------------------------- | --------------------- |
| ì„ í˜•ì„± (Linearity)                 | ì…ë ¥ ë³€ìˆ˜ì™€ ì¶œë ¥ ë³€ìˆ˜ ê°„ì˜ ì„ í˜• ê´€ê³„ |
| ë…ë¦½ì„± (Independence)              | ê´€ì¸¡ê°’ ê°„ì˜ ë…ë¦½ì„±            |
| ë“±ë¶„ì‚°ì„± (Homoscedasticity)         | ì˜¤ì°¨ì˜ ë¶„ì‚°ì´ ì¼ì •í•¨           |
| ì •ê·œì„± (Normality)                 | ì”ì°¨(ì˜¤ì°¨)ê°€ ì •ê·œ ë¶„í¬ë¥¼ ë”°ë¦„     |
| ë‹¤ì¤‘ê³µì„ ì„± ì—†ìŒ (No multicollinearity) | ì…ë ¥ ë³€ìˆ˜ ê°„ ê³¼ë„í•œ ìƒê´€ê´€ê³„ ì—†ìŒ   |

---

## 4. íšŒê·€ë¶„ì„ í”„ë¡œì íŠ¸ ì‚¬ë¡€

### ğŸ”¹ 1. ì‘ë¬¼ ìƒì¥ ì˜ˆì¸¡ 

íšŒê·€ ë¶„ì„ì€ ì‘ë¬¼ì˜ ìƒì¥ëŸ‰(ì˜ˆ: ì ë©´ì , í‚¤, ìƒì¤‘ëŸ‰ ë“±)ì„ ì˜ˆì¸¡í•˜ê¸° ìœ„í•´ ì£¼ë¡œ ì‚¬ìš©ë©ë‹ˆë‹¤. ì…ë ¥ ë³€ìˆ˜ë¡œëŠ” ì˜¨ë„, ìŠµë„, COâ‚‚, ì¼ì¡°ëŸ‰ ë“±ì˜ **í™˜ê²½ ì •ë³´**ê°€ ì‚¬ìš©ë˜ë©°, ì¶œë ¥ì€ **ìƒìœ¡ ì§€í‘œì˜ ì—°ì†ì  ìˆ˜ì¹˜**ì…ë‹ˆë‹¤.

#### íšŒê·€ ë¶„ì„ íë¦„

1. ë°ì´í„° ìˆ˜ì§‘: ì‹œê³„ì—´ ì„¼ì„œ + ìƒìœ¡ ì¸¡ì • ë°ì´í„°
2. íŠ¹ì„± ì„ íƒ: í‰ê·  ì˜¨ë„, ëˆ„ì  ì¼ì¡°ëŸ‰ ë“±
3. ëª¨ë¸ í•™ìŠµ: ì„ í˜• íšŒê·€ ë˜ëŠ” ë‹¤í•­ íšŒê·€
4. ì„±ëŠ¥ í‰ê°€: MAE, RMSE, RÂ²

---

### ğŸ”¹ 2. ë‚ ì”¨ ë°ì´í„° ê¸°ë°˜ ìˆ˜í™• ì‹œê¸° ì˜ˆì¸¡

ìˆ˜í™• ì‹œê¸° ì˜ˆì¸¡ì€ ìƒìœ¡ë¥ ê³¼ ì™¸ë¶€ í™˜ê²½ ìš”ì¸ì„ ê¸°ë°˜ìœ¼ë¡œ ì‘ë¬¼ì˜ **ìµœì  ìˆ˜í™• ì‹œì **ì„ ë¶„ë¥˜í•˜ê±°ë‚˜ íšŒê·€ ë¬¸ì œë¡œ ëª¨ë¸ë§í•©ë‹ˆë‹¤.

| ì…ë ¥ ë³€ìˆ˜ | ì„¤ëª…            |
| ----- | ------------- |
| ìƒìœ¡ì¼ìˆ˜  | íŒŒì¢… í›„ ê²½ê³¼ ì¼ìˆ˜    |
| í‰ê·  ê¸°ì˜¨ | ìƒìœ¡ê¸° í‰ê·  ê¸°ì˜¨     |
| ì´ ì¼ì¡°ëŸ‰ | ëˆ„ì  ì¼ì¡° ì‹œê°„      |
| ê°•ìˆ˜ëŸ‰   | ìˆ˜ë¶„ ìŠ¤íŠ¸ë ˆìŠ¤ ì˜í–¥ ê³ ë ¤ |

####  ì˜ˆì¸¡ ì ‘ê·¼ ë°©ì‹

* **íšŒê·€ ëª¨ë¸**: ìˆ˜í™•ê¹Œì§€ ë‚¨ì€ ì¼ìˆ˜ ì˜ˆì¸¡
* **ì´ì§„ ë¶„ë¥˜ ëª¨ë¸**: â€˜ìˆ˜í™• ì ê¸° ì—¬ë¶€â€™ (ì˜ˆ/ì•„ë‹ˆì˜¤)


---

## ì‹¤ìŠµ 1: ë‹¤ì¤‘ ì„ í˜• íšŒê·€ë¥¼ í™œìš©í•œ ë³´ìŠ¤í„´ ì£¼íƒ ê°€ê²© ì˜ˆì¸¡



**Boston Housing ë°ì´í„°ì…‹**ì€ ë¯¸êµ­ ë³´ìŠ¤í„´ ì§€ì—­ì˜ ì£¼íƒ ê°€ê²©ì— ì˜í–¥ì„ ì£¼ëŠ” ë‹¤ì–‘í•œ ë³€ìˆ˜ë“¤(ë°© ìˆ˜, ì§€ì—­ ë²”ì£„ìœ¨, êµìœ¡ ìˆ˜ì¤€ ë“±)ì„ í¬í•¨í•œ ë°ì´í„°ì…ë‹ˆë‹¤.
ë‹¤ì¤‘ ì„ í˜• íšŒê·€ ëª¨ë¸ì„ í•™ìŠµì‹œì¼œ, **ì£¼ì–´ì§„ íŠ¹ì„±ë“¤ë¡œë¶€í„° ì§‘ê°’ì„ ì˜ˆì¸¡**í•˜ëŠ” ëª¨ë¸ì„ êµ¬í˜„í•©ë‹ˆë‹¤.
> OpenMLì—ì„œ ë³´ìŠ¤í„´ ì£¼íƒ ë°ì´í„°ì…‹ì„ ê°€ì ¸ì˜´.


### ë°ì´í„° ì •ë³´

Boston Housing ë°ì´í„°ì…‹ì—ëŠ” ë‹¤ìŒê³¼ ê°™ì€ íŠ¹ì„±(Feature)ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤:

| ë³€ìˆ˜ëª…      | ì„¤ëª…                        |
| -------- | ------------------------- |
| CRIM     | ì§€ì—­ ë²”ì£„ìœ¨                    |
| ZN       | 25,000 í‰ë°©í”¼íŠ¸ ì´ìƒ ê±°ì£¼ì§€ì—­ ë¹„ìœ¨    |
| INDUS    | ë¹„ì†Œë§¤ìƒì—…ì§€ì—­ ë©´ì  ë¹„ìœ¨             |
| CHAS     | ì°°ìŠ¤ê°• ì¸ì ‘ ì—¬ë¶€ (1: ì¸ì ‘, 0: ê·¸ ì™¸) |
| NOX      | ì¼ì‚°í™”ì§ˆì†Œ ë†ë„                  |
| RM       | ì£¼íƒ 1ê°€êµ¬ë‹¹ í‰ê·  ë°© ê°œìˆ˜           |
| AGE      | 1940ë…„ ì´ì „ì— ì§€ì–´ì§„ ì£¼íƒ ë¹„ìœ¨       |
| DIS      | 5ê°œ ë³´ìŠ¤í„´ ê³ ìš©ì„¼í„°ê¹Œì§€ ê±°ë¦¬          |
| RAD      | ë°©ì‚¬í˜• ê³ ì†ë„ë¡œ ì ‘ê·¼ì„± ì§€ìˆ˜           |
| TAX      | ì¬ì‚°ì„¸ìœ¨                      |
| PTRATIO  | í•™ìƒ-êµì‚¬ ë¹„ìœ¨                  |
| B        | í‘ì¸ ì¸êµ¬ ë¹„ìœ¨ ì§€í‘œ               |
| LSTAT    | ì €ì†Œë“ì¸µ ë¹„ìœ¨ (%)               |
| **MEDV** | ì£¼íƒ ê°€ê²© (ëª©í‘œê°’, ë‹¨ìœ„: \$1000s)  |



```python
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.datasets import fetch_openml

# 1. ë°ì´í„° ë¡œë”©
boston = fetch_openml(name='boston', version=1, as_frame=True)
X = boston.data
y = boston.target

print(X.info())

# categorical ë³€ìˆ˜ --> ìˆ˜ì¹˜í˜•ìœ¼ë¡œ ë³€ê²½
X['CHAS'] = X['CHAS'].astype(int)
X['RAD'] = X['RAD'].astype(int)

# 2. í›ˆë ¨/í…ŒìŠ¤íŠ¸ ë¶„í• 
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 3. ëª¨ë¸ í•™ìŠµ
model = LinearRegression()
model.fit(X_train, y_train)

# ì˜ˆì¸¡ ë° í‰ê°€
y_pred = model.predict(X_test)
mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)
r2 = r2_score(y_test, y_pred)

print("âœ… ëª¨ë¸ í‰ê°€")
print(f"â–¶ MSE: {mse:.2f}")
print(f"â–¶ RMSE: {rmse:.2f}")
print(f"â–¶ RÂ² Score: {r2:.2f}")

# 4. íšŒê·€ ê³„ìˆ˜ ì¶œë ¥ ë° í•´ì„
coefficients = pd.Series(model.coef_, index=X.columns)

print("\nâœ… íšŒê·€ ê³„ìˆ˜:")
print(coefficients.sort_values(ascending=False))

print("\nâœ… ì£¼ìš” ë³€ìˆ˜ í•´ì„:")
print(f"NOX (ì¼ì‚°í™”ì§ˆì†Œ ë†ë„): {coefficients['NOX']:.3f} â†’ ì¼ì‚°í™”ì§ˆì†Œ ë†ë„ ë†’ì„ìˆ˜ë¡ ì§‘ê°’ í•˜ë½")
print(f"RM (ë°© ê°œìˆ˜): {coefficients['RM']:.3f} â†’ ë°©ì´ ë§ì„ìˆ˜ë¡ ì§‘ê°’ ìƒìŠ¹")
print(f"CHAS (ì°°ìŠ¤ê°• ì¸ì ‘ ì—¬ë¶€): {coefficients['CHAS']:.3f} â†’ ì°°ìŠ¤ê°• ì¸ì ‘í• ìˆ˜ë¡ ì§‘ê°’ ìƒìŠ¹")
```
---
## ì‹¤ìŠµ 2: GreenHouse ìˆ˜í™•ëŸ‰ ì˜ˆì¸¡

### ë°ì´í„° ì…‹
- Autonomous Greenhouse Challenge (AGC) ë°ì´í„°ì…‹
- ë§í¬: https://www.kaggle.com/datasets/piantic/autonomous-greenhouse-challengeagc-2nd-2019/data
- **Autonomous Greenhouse Challenge (AGC)** ë°ì´í„°ì…‹ì—ëŠ” ì—¬ëŸ¬ í´ë”ê°€ ì¡´ì¬í•˜ëŠ”ë°, ê°ê°ì´ ì˜ë¯¸í•˜ëŠ” ë°”ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:


### í´ë” êµ¬ì¡° ë° ì„¤ëª…

| í´ë”ëª…            | ì„¤ëª…                                                                                                             |
| -------------- | -------------------------------------------------------------------------------------------------------------- |
| **AICU**       | 2019â€“2020ë…„ ì±Œë¦°ì§€ì— ì°¸ê°€í•œ **AiCU íŒ€**ì´ ì‚¬ìš©í•œ ì˜¨ì‹¤ ë°ì´í„°ë¥¼ í¬í•¨í•©ë‹ˆë‹¤. ì„¼ì„œ ì…ë ¥ ê°’(ì˜¨ë„, ìŠµë„, COâ‚‚, PAR, í† ì–‘ ìˆ˜ë¶„ ë“±)ê³¼ AI ê¸°ë°˜ ì œì–´ ì „ëµì´ ê¸°ë¡ë˜ì–´ ìˆìŠµë‹ˆë‹¤. |
| **Automatoes** | **Automatoes íŒ€** (2ë“± ë˜ëŠ” ìš°ìŠ¹ íŒ€)ì˜ ë°ì´í„°ë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤. ì´ë²ˆ ëŒ€íšŒì—ì„œ í† ë§ˆí†  ì¬ë°°ì— ì‚¬ìš©ëœ í™˜ê²½ ì¡°ì‘ ì „ëµê³¼ í•´ë‹¹ ì„¼ì„œ ë°ì´í„°ë¥¼ í¬í•¨í•©ë‹ˆë‹¤.                     |
| **Dialog**     | ë°ì´í„°ì…‹ ì œê³µ êµ¬ì¡°ìƒ **Dialog**ëŠ” ì±Œë¦°ì§€ì˜ â€œì°¸ê°€ìâ€“ì£¼ìµœ ì¸¡ ê°„ ëŒ€í™” ë°ì´í„°â€ì¼ ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤. ì‹¤ì œ í™˜ê²½ ì„¼ì„œ ê°’ì´ë‚˜ ì‹¤í—˜ ë°ì´í„°ë¥¼ ë‹´ê³  ìˆì§€ëŠ” ì•Šì„ í™•ë¥ ì´ í½ë‹ˆë‹¤.           |

### ì‚¬ìš© í´ë”:  **Automatoes** 

### ì‚¬ìš© íŒŒì¼ ëª©ë¡

| íŒŒì¼ëª…                     | ì„¤ëª…                          | ì‚¬ìš© ëª©ì          |
| ----------------------- | --------------------------- | ------------- |
| `GreenhouseClimate.csv` | ì˜¨ì‹¤ ë‚´ë¶€ ì˜¨ë„, ìŠµë„, COâ‚‚, ê´‘ëŸ‰, ê¸‰ìˆ˜ ë“± | **ì…ë ¥ ë³€ìˆ˜ (X)** |
| `Production.csv`        | í’ˆì§ˆ ë“±ê¸‰ë³„ ìˆ˜í™•ëŸ‰ (A, B), ìˆ˜í™• ì¼ì í¬í•¨ | **ëª©í‘œ ë³€ìˆ˜ (y)** |


### ì„ íƒëœ ì£¼ìš” ë³€ìˆ˜

| ë³€ìˆ˜ëª…       | ì„¤ëª…                          | ë‹¨ìœ„        | íŒŒì¼                |
| --------- | --------------------------- | --------- | ----------------- |
| `Tair`    | ì˜¨ì‹¤ ë‚´ ê³µê¸° ì˜¨ë„                  | Â°C        | GreenhouseClimate |
| `Rhair`   | ì˜¨ì‹¤ ë‚´ ìƒëŒ€ ìŠµë„                  | %         | GreenhouseClimate |
| `CO2air`  | ì˜¨ì‹¤ ë‚´ COâ‚‚ ë†ë„                 | ppm       | GreenhouseClimate |
| `Tot_PAR` | ì´ ê´‘í•©ì„± ìœ íš¨ ë³µì‚¬ëŸ‰ (íƒœì–‘ + LED/HPS) | Î¼mol/mÂ²/s | GreenhouseClimate |
| `Cum_irr` | í•˜ë£¨ ëˆ„ì  ê´€ìˆ˜ëŸ‰                   | L/mÂ²      | GreenhouseClimate |
| `ProdA`   | ìƒê¸‰ í’ˆì§ˆ í† ë§ˆí†  ìˆ˜í™•ëŸ‰               | kg/mÂ²     | Production        |

â€» ì‹œê°„ ë‹¨ìœ„ëŠ” 5ë¶„ ê°„ê²©ì´ë©°, ì¼ ë‹¨ìœ„ë¡œ ë¦¬ìƒ˜í”Œë§ í›„ ì‚¬ìš©í•©ë‹ˆë‹¤.


* ë¨¼ì €, AICU í´ë”ì˜ GreenhouseClimate.csvì™€ Production.csv ë¥¼ ì—…ë¡œë“œí•©ë‹ˆë‹¤. 

```python
import pandas as pd
import numpy as np
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_squared_error, r2_score
import matplotlib.pyplot as plt

# 1. íŒŒì¼ ê²½ë¡œ ì„¤ì •
climate_path = "/content/GreenhouseClimate.csv"
prod_path = "/content/Production.csv"

# 2. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
climate = pd.read_csv(climate_path)
climate['Time'] = pd.to_datetime(climate['Time'], unit='D', origin='1900-01-01')

production = pd.read_csv(prod_path)
production['Time'] = pd.to_datetime(production['Time'], unit='D', origin='1900-01-01')

# 3. í•„ìš”í•œ ë³€ìˆ˜ë§Œ ì¶”ì¶œ
climate = climate[['Time', 'Tair', 'Rhair', 'CO2air', 'Tot_PAR', 'Cum_irr']]
production = production[['Time', 'ProdA']]  # ëª©í‘œ: Class A ìˆ˜í™•ëŸ‰

# 4. ì‹œê°„ ë‹¨ìœ„ í‰ê·  (í•˜ë£¨ ë‹¨ìœ„ë¡œ)
climate_indexed = climate.set_index('Time') 
production_indexed = production.set_index('Time')

numerical_cols = ['Tair', 'Rhair', 'CO2air', 'Tot_PAR', 'Cum_irr']
for col in numerical_cols:
    climate_indexed[col] = pd.to_numeric(climate_indexed[col], errors='coerce')

climate_daily = climate_indexed[numerical_cols].resample('D').mean().reset_index()
production_daily = production_indexed.resample('D').sum().reset_index()

# 5. ë³‘í•©
df = pd.merge(climate_daily, production_daily, on='Time')

# 6. ê²°ì¸¡ì¹˜ ì œê±°
df.dropna(inplace=True)

# 7. X, y ë¶„ë¦¬
X = df[numerical_cols]
y = df['ProdA']

# 8. í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë¶„í• 
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 9. ìŠ¤ì¼€ì¼ë§
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# 10. ëª¨ë¸ í›ˆë ¨ (Linear Regression)
model = LinearRegression()
model.fit(X_train_scaled, y_train)

# 11. ì˜ˆì¸¡ ë° í‰ê°€
y_pred = model.predict(X_test_scaled)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))
r2 = r2_score(y_test, y_pred)

print(f"RMSE: {rmse:.2f}")
print(f"RÂ² Score: {r2:.2f}")

# 12. ì‹œê°í™”
plt.figure(figsize=(10, 5))
plt.plot(y_test.values, label='Ground Truth')
plt.plot(y_pred, label='Predicted (LinearReg)', linestyle='--')
plt.title("Tomato Production Prediction (Linear Regression)")
plt.xlabel("Sample Index")
plt.ylabel("Production (kg/mÂ²)")
plt.legend()
plt.grid()
plt.show()
```


---
# ğŸ”¹ ë¡œì§€ìŠ¤í‹± íšŒê·€(Logistic Regression)


## 1. ë¡œì§€ìŠ¤í‹± íšŒê·€ë€?


ë¡œì§€ìŠ¤í‹± íšŒê·€ëŠ” **ë¶„ë¥˜(classification)** ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ” ì§€ë„ í•™ìŠµ ì•Œê³ ë¦¬ì¦˜ì…ë‹ˆë‹¤. ì´ë¦„ì€ "íšŒê·€"ì´ì§€ë§Œ, ì‹¤ì œë¡œëŠ” **ì¶œë ¥ê°’ì„ í™•ë¥ ë¡œ ì˜ˆì¸¡í•˜ê³ , ì´ í™•ë¥ ì„ ë°”íƒ•ìœ¼ë¡œ í´ë˜ìŠ¤(0 ë˜ëŠ” 1)ë¥¼ ë¶„ë¥˜**í•˜ëŠ” ë° ì‚¬ìš©ë©ë‹ˆë‹¤.


* ì¶œë ¥ê°’ì€ **0ê³¼ 1 ì‚¬ì´ì˜ í™•ë¥ **ë¡œ í‘œí˜„ë©ë‹ˆë‹¤.
* **ì‹œê·¸ëª¨ì´ë“œ í•¨ìˆ˜**ë¥¼ ì‚¬ìš©í•´ ì„ í˜• ì¡°í•©ì„ í™•ë¥ ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
* **ì´ì§„ ë¶„ë¥˜**ì— ì£¼ë¡œ ì‚¬ìš©ë˜ë©°, **ë‹¤ì¤‘ í´ë˜ìŠ¤ í™•ì¥**ë„ ê°€ëŠ¥í•©ë‹ˆë‹¤.



| í•­ëª©    | ì„¤ëª…                                      |
| ----- | --------------------------------------- |
| ëª©ì     | í™•ë¥  ê¸°ë°˜ ì´ì§„ ë¶„ë¥˜                             |
| ì˜ˆì¸¡ê°’   | ì‹œê·¸ëª¨ì´ë“œ í•¨ìˆ˜ ì¶œë ¥ $\hat{y} \in (0,1)$         |
| ê²°ì • ê¸°ì¤€ | $\hat{y} \ge 0.5 \rightarrow 1$, ê·¸ ì™¸ëŠ” 0 |
| ì†ì‹¤ í•¨ìˆ˜ | ë¡œì§€ìŠ¤í‹± ì†ì‹¤ (Binary Cross-Entropy)          |
| ìµœì í™”   | ê²½ì‚¬í•˜ê°•ë²• ë“± ì‚¬ìš©                              |
| í™•ì¥    | Scikit-learnì€ ë‹¤ì¤‘ í´ë˜ìŠ¤ ë¶„ë¥˜ ê°€ëŠ¥                |

---

### ë¬¸ì œ 1. ë¡œì§€ìŠ¤í‹± íšŒê·€ì—ì„œ ì˜ˆì¸¡ê°’ $\hat{y}$ëŠ” ì–´ë–¤ ë²”ìœ„ë¥¼ ê°€ì§€ëŠ”ê°€?

â‘  0 ë˜ëŠ” 1
â‘¡ ìŒìˆ˜ì—ì„œ ì–‘ìˆ˜
â‘¢ 0 ì´ìƒ 1 ì´í•˜ì˜ ì‹¤ìˆ˜
â‘£ ì •ìˆ˜

**ì •ë‹µ**: â‘¢ 0 ì´ìƒ 1 ì´í•˜ì˜ ì‹¤ìˆ˜
**í•´ì„¤**: ì‹œê·¸ëª¨ì´ë“œ í•¨ìˆ˜ì˜ ì¶œë ¥ê°’ì€ í•­ìƒ **(0, 1)** ì‚¬ì´ì˜ **í™•ë¥ ê°’**ì…ë‹ˆë‹¤.


### ë¬¸ì œ 2. ë¡œì§€ìŠ¤í‹± íšŒê·€ì—ì„œ ì‹œê·¸ëª¨ì´ë“œ í•¨ìˆ˜ì˜ ì—­í• ì€?

â‘  íŠ¹ì„± ì„ íƒ
â‘¡ ì •ê·œí™”
â‘¢ ì„ í˜• ì¡°í•©ì„ í™•ë¥ ê°’ìœ¼ë¡œ ë³€í™˜
â‘£ ê°€ì¤‘ì¹˜ ê°ì†Œ

**ì •ë‹µ**: â‘¢ ì„ í˜• ì¡°í•©ì„ í™•ë¥ ê°’ìœ¼ë¡œ ë³€í™˜
**í•´ì„¤**: $\sigma(z) = \frac{1}{1 + e^{-z}}$ì€ ì„ í˜• ì¡°í•© $z$ë¥¼ 0\~1 ì‚¬ì´ì˜ í™•ë¥ ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.

---
## 2. ë¡œì§€ìŠ¤í‹± íšŒê·€ ì‹¤ìŠµ


### ğŸ“¦ ë°ì´í„°ì…‹: Ai4I 2020 Predictive Maintenance Dataset

ì´ ë°ì´í„°ì…‹ì€ **ìŠ¤ë§ˆíŠ¸ ì œì¡° í™˜ê²½ì—ì„œì˜ ì˜ˆì¸¡ ìœ ì§€ë³´ìˆ˜**ë¥¼ ìœ„í•œ ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„°ë¡œ, ì„¼ì„œ ì¸¡ì •ê°’ê³¼ ê¸°ê³„ ê³ ì¥ ì—¬ë¶€ë¥¼ í¬í•¨í•©ë‹ˆë‹¤. ê³µê°œì ìœ¼ë¡œ ì ‘ê·¼ ê°€ëŠ¥í•œ ì´ ë°ì´í„°ì…‹ì€ ë‹¤ì–‘í•œ ì—°êµ¬ì— í™œìš©ë˜ê³  ìˆìŠµë‹ˆë‹¤.


* **ì¶œì²˜**: UCI Machine Learning Repository
* **ë°ì´í„° í˜•íƒœ**: CSV (ì•½ 10,000ê°œ ìƒ˜í”Œ, 14ê°œ ì—´)
* **ëª©ì **: ê³µì¥ ì„¤ë¹„ì—ì„œ ë°œìƒí•  ìˆ˜ ìˆëŠ” \*\*ê¸°ê³„ ê³ ì¥(Machine Failure)\*\*ì„ ì˜ˆì¸¡í•˜ê¸° ìœ„í•œ **ì´ì§„ ë¶„ë¥˜(binary classification)** ë¬¸ì œì…ë‹ˆë‹¤.



#### ì „ì²´ ì»¬ëŸ¼ ì„¤ëª…í‘œ

| ë³€ìˆ˜ëª… (ì»¬ëŸ¼ëª…)                 | ë°ì´í„° ìœ í˜•     | ì„¤ëª…                                    |
| ------------------------- | ---------- | ------------------------------------- |
| `UDI`                     | ì •ìˆ˜ (int)   | ê³ ìœ  ì‹ë³„ì (Unique ID)                    |
| `Product ID`              | ë¬¸ìì—´ (str)  | ì œí’ˆ ê³ ìœ  ì‹ë³„ì                             |
| `Type`                    | ë¬¸ìì—´ (str)  | ì œí’ˆ ìœ í˜• (L, M, H ì„¸ ê°€ì§€ íƒ€ì…)               |
| `Air temperature [K]`     | ì‹¤ìˆ˜ (float) | ê³µê¸° ì˜¨ë„ (ì¼ˆë¹ˆ ë‹¨ìœ„)                         |
| `Process temperature [K]` | ì‹¤ìˆ˜ (float) | ê³µì • ì˜¨ë„ (ì¼ˆë¹ˆ ë‹¨ìœ„)                         |
| `Rotational speed [rpm]`  | ì‹¤ìˆ˜ (float) | íšŒì „ ì†ë„ (ë¶„ë‹¹ íšŒì „ìˆ˜, rpm)                   |
| `Torque [Nm]`             | ì‹¤ìˆ˜ (float) | í† í¬ (Nm)                               |
| `Tool wear [min]`         | ì‹¤ìˆ˜ (float) | ê³µêµ¬ ë§ˆëª¨ ì‹œê°„ (ë¶„)                          |
| `TWF`                     | 0/1 (int)  | Tool Wear Failure (ê³µêµ¬ ë§ˆëª¨ ê³ ì¥ ì—¬ë¶€)       |
| `HDF`                     | 0/1 (int)  | Heat Dissipation Failure (ì—´ ë°©ì¶œ ê³ ì¥ ì—¬ë¶€) |
| `PWF`                     | 0/1 (int)  | Power Failure (ì „ë ¥ ê³ ì¥ ì—¬ë¶€)              |
| `OSF`                     | 0/1 (int)  | Overstrain Failure (ê³¼ë¶€í•˜ ê³ ì¥ ì—¬ë¶€)        |
| `RNF`                     | 0/1 (int)  | Random Failures (ì„ì˜ ê³ ì¥ ì—¬ë¶€)            |
| `Machine failure`         | 0/1 (int)  | **ìµœì¢… ê³ ì¥ ë°œìƒ ì—¬ë¶€ (Target ë³€ìˆ˜)**           |

---

#### íƒ€ê²Ÿ ë³€ìˆ˜ (Machine failure)

* `Machine failure`ëŠ” ìœ„ì˜ TWF, HDF, PWF, OSF, RNF ë‹¤ì„¯ ê°œì˜ ê³ ì¥ ì¤‘ **í•˜ë‚˜ë¼ë„ ë°œìƒí•˜ë©´ 1**, ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ 0ì…ë‹ˆë‹¤.

$$
\text{Machine failure} = \begin{cases}
1 & \text{(TWF or HDF or PWF or OSF or RNF = 1)} \\
0 & \text{(ëª¨ë‘ 0)}
\end{cases}
$$


#### ì˜ˆì‹œ í–‰ ë°ì´í„°

| UDI | Product ID | Type | Air Temp \[K] | Proc Temp \[K] | Rot Speed | Torque | Tool Wear | TWF | HDF | PWF | OSF | RNF | Machine failure |
| --- | ---------- | ---- | ------------- | -------------- | --------- | ------ | --------- | --- | --- | --- | --- | --- | --------------- |
| 1   | M14860     | M    | 298.1         | 308.6          | 1551      | 42.8   | 0         | 0   | 0   | 0   | 0   | 0   | 0               |


#### ì£¼ìš” ë¶„ì„ í¬ì¸íŠ¸

* **ì œí’ˆ ìœ í˜•(Type)**: L, M, H ê°„ ì„±ëŠ¥ ì°¨ì´ ì¡´ì¬ ê°€ëŠ¥
* **ì˜¨ë„/íšŒì „ìˆ˜/í† í¬ ë“± ë¬¼ë¦¬ ì„¼ì„œ ë³€ìˆ˜**ì™€ **ê³ ì¥ ë°œìƒ ì—¬ë¶€** ê°„ ê´€ê³„ ë¶„ì„ ê°€ëŠ¥
* **ê³ ì¥ ë¹„ìœ¨ì´ ë‚®ì•„ í´ë˜ìŠ¤ ë¶ˆê· í˜• ë¬¸ì œê°€ ì¡´ì¬í•  ìˆ˜ ìˆìŒ**


#### í™œìš© ê°€ëŠ¥ ë¬¸ì œ ìœ í˜•

| ë¬¸ì œ ìœ í˜• | ê°€ëŠ¥ ì—¬ë¶€ | ì„¤ëª…                            |
| ----- | ----- | ----------------------------- |
| ì´ì§„ ë¶„ë¥˜ | âœ…     | ë¨¸ì‹  ê³ ì¥ ì—¬ë¶€ ì˜ˆì¸¡                   |
| ë‹¤ì¤‘ ë¶„ë¥˜ | âœ…     | TWF, HDF, PWF ë“± ê°œë³„ ê³ ì¥ ìœ í˜• ë¶„ë¥˜   |
| ì´ìƒ íƒì§€ | âœ…     | ê³ ì¥ ë°œìƒì´ ë§¤ìš° ë“œë¬¼ë‹¤ë©´ ì´ìƒíƒì§€ ë¬¸ì œë¡œ ì ‘ê·¼ ê°€ëŠ¥ |
| íšŒê·€ ë¬¸ì œ | âŒ     | í˜„ì¬ëŠ” íšŒê·€í˜• ëª©í‘œë³€ìˆ˜ ì—†ìŒ               |

---

### ë¡œì§€ìŠ¤í‹± íšŒê·€ ì‹¤ìŠµ ì½”ë“œ

```python
# 1. ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix

# 2. ë°ì´í„° ë¡œë“œ
url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00601/ai4i2020.csv'
df = pd.read_csv(url)

# 3. ë°ì´í„° ì „ì²˜ë¦¬
# ë¶ˆí•„ìš”í•œ ì—´ ì œê±°
df.drop(['UDI', 'Product ID'], axis=1, inplace=True)


## ë²”ì£¼í˜• ë³€ìˆ˜ ì²˜ë¦¬
print(df.info())
print(df['Type'].value_counts())

df['Type'] = df['Type'].map({'H': 0, 'L': 1, 'M': 2})

# íƒ€ê²Ÿ ë³€ìˆ˜ì™€ íŠ¹ì„± ë¶„ë¦¬
X = df[['Type', 'Air temperature [K]', 'Process temperature [K]',
       'Rotational speed [rpm]', 'Torque [Nm]', 'Tool wear [min]' ] ]
y = df['Machine failure']

print(X.info())

# 4. ë°ì´í„° ë¶„í• 
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 5. ì •ê·œí™”
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# 6. ë¡œì§€ìŠ¤í‹± íšŒê·€ ëª¨ë¸ í•™ìŠµ
model = LogisticRegression(max_iter=1000)
model.fit(X_train_scaled, y_train)

# 7. ì˜ˆì¸¡ ë° í‰ê°€
y_pred = model.predict(X_test_scaled)

# ë¶„ë¥˜ ì„±ëŠ¥ í‰ê°€
print("Classification Report:")
print(classification_report(y_test, y_pred))

# 8. í˜¼ë™ í–‰ë ¬ ì‹œê°í™”
cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(6,4))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['No Failure', 'Failure'], yticklabels=['No Failure', 'Failure'])
plt.ylabel('Actual')
plt.xlabel('Predicted')
plt.title('Confusion Matrix')
plt.show()
```

---
# ğŸ“˜ 4ì¥. ë¶„ë¥˜ ëª¨ë¸

---
# ğŸ“˜ 5ì¥. k-ìµœê·¼ì ‘ ì´ì›ƒ ì•Œê³ ë¦¬ì¦˜ (k-Nearest Neighbors, kNN)


## 1. ê°œë…

\*\*k-ìµœê·¼ì ‘ ì´ì›ƒ ì•Œê³ ë¦¬ì¦˜(kNN)\*\*ì€ ê°€ì¥ ë‹¨ìˆœí•˜ë©´ì„œë„ ê°•ë ¥í•œ **ë¹„ëª¨ìˆ˜(non-parametric)** ì§€ë„ í•™ìŠµ ì•Œê³ ë¦¬ì¦˜ ì¤‘ í•˜ë‚˜ì…ë‹ˆë‹¤.

* ì£¼ì–´ì§„ ì…ë ¥ ë°ì´í„°ì— ëŒ€í•´ **ê°€ì¥ ê°€ê¹Œìš´ kê°œì˜ ì´ì›ƒ**ì„ ì°¾ê³ ,
* ê·¸ ì´ì›ƒë“¤ì˜ ë ˆì´ë¸”ì„ ë°”íƒ•ìœ¼ë¡œ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.


## 2. ì›ë¦¬

1. **í›ˆë ¨ ë‹¨ê³„ (Training)**

   * íŠ¹ë³„í•œ í•™ìŠµ ê³¼ì •ì´ ì—†ìŠµë‹ˆë‹¤. ëª¨ë“  í•™ìŠµ ë°ì´í„°ë¥¼ **ê¸°ì–µ**í•´ë‘¡ë‹ˆë‹¤.
   * ì¦‰, **ê¸°ì–µ ê¸°ë°˜ ëª¨ë¸(Memory-based model)** ë˜ëŠ” **Lazy Learning**ì´ë¼ê³  í•©ë‹ˆë‹¤.

2. **ì˜ˆì¸¡ ë‹¨ê³„ (Prediction)**
   ìƒˆë¡œìš´ ë°ì´í„° í¬ì¸íŠ¸ $x$ê°€ ë“¤ì–´ì˜¤ë©´:

   * í•™ìŠµ ë°ì´í„° ì „ì²´ì™€ì˜ ê±°ë¦¬ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
   * ê±°ë¦¬ ê¸°ì¤€ìœ¼ë¡œ ê°€ì¥ ê°€ê¹Œìš´ **kê°œì˜ ë°ì´í„°**ë¥¼ ì„ íƒí•©ë‹ˆë‹¤.
   * **ë¶„ë¥˜ ë¬¸ì œ**:

     * ë‹¤ìˆ˜ê²° íˆ¬í‘œ(Majority Voting)ë¥¼ í†µí•´ ê°€ì¥ ë§ì´ ë“±ì¥í•œ í´ë˜ìŠ¤ ì„ íƒ
   * **íšŒê·€ ë¬¸ì œ**:

     * kê°œì˜ í‰ê· ì„ ì‚¬ìš©í•´ ì˜ˆì¸¡


### ê±°ë¦¬ ê³„ì‚°

ê°€ì¥ ë„ë¦¬ ì“°ì´ëŠ” ê±°ë¦¬ í•¨ìˆ˜ëŠ” \*\*ìœ í´ë¦¬ë“œ ê±°ë¦¬(Euclidean distance)\*\*ì…ë‹ˆë‹¤:

$$
d(x, x_i) = \sqrt{ \sum_{j=1}^{n} (x_j - x_{ij})^2 }
$$

ê·¸ ì™¸ì—ë„:

* ë§¨í•´íŠ¼ ê±°ë¦¬: $\sum |x_j - x_{ij}|$
* ì½”ì‚¬ì¸ ê±°ë¦¬: $1 - \cos(\theta)$

---

## 3. í•˜ì´í¼íŒŒë¼ë¯¸í„°

| í•˜ì´í¼íŒŒë¼ë¯¸í„°      | ì„¤ëª…                                             |
| ------------ | ---------------------------------------------- |
| **k** (ì´ì›ƒ ìˆ˜) | ë„ˆë¬´ ì‘ìœ¼ë©´ ê³¼ì í•©, ë„ˆë¬´ í¬ë©´ ê³¼ì†Œì í•©                         |
| **ê±°ë¦¬ ì²™ë„**    | ìœ í´ë¦¬ë“œ, ë§¨í•´íŠ¼, ì½”ì‚¬ì¸ ë“±                               |
| **ê°€ì¤‘ì¹˜ ë°©ì‹**   | ì´ì›ƒ ê±°ë¦¬ì— ë”°ë¼ ê°€ì¤‘ì¹˜ë¥¼ ë‘˜ ìˆ˜ë„ ìˆìŒ (`uniform`, `distance`) |

---

## 4. ì¥ì ê³¼ ë‹¨ì 

| ì¥ì                     | ë‹¨ì                             |
| --------------------- | ----------------------------- |
| êµ¬í˜„ì´ ê°„ë‹¨í•¨               | ê³„ì‚° ë¹„ìš©ì´ í¼ (ì˜ˆì¸¡ ì‹œ ì „ì²´ ë°ì´í„°ì™€ ê±°ë¦¬ ê³„ì‚°) |
| ë¹„ëª¨ìˆ˜ ëª¨ë¸ (ë°ì´í„° ë¶„í¬ ê°€ì • ì—†ìŒ) | ê³ ì°¨ì›ì—ì„œëŠ” ì„±ëŠ¥ ì €í•˜ (ì°¨ì›ì˜ ì €ì£¼)         |
| ë‹¤ì¤‘ í´ë˜ìŠ¤/íšŒê·€ ëª¨ë‘ ê°€ëŠ¥       | í›ˆë ¨ ë°ì´í„°ê°€ ë§ì„ìˆ˜ë¡ ì†ë„ ëŠë¦¼            |


---

# ğŸ“˜ 6ì¥. ì„œí¬íŠ¸ ë²¡í„° ë¨¸ì‹ (Support Vector Machine, SVM)

## 1. ì—­ì‚¬ì  ë°°ê²½

* **1992ë…„**: ëŸ¬ì‹œì•„ ì¶œì‹ ì˜ **Vladimir Vapnik**ê³¼ **Alexey Chervonenkis**ê°€ ì´ë¡ ì  ê¸°ì´ˆì¸ **VC ì°¨ì›**(Vapnikâ€“Chervonenkis dimension)ê³¼ **êµ¬ê°„ ë¦¬ìŠ¤í¬ ìµœì†Œí™”** ê°œë…ì„ ë°œí‘œí–ˆìŠµë‹ˆë‹¤.
* **1995ë…„**: Vapnikê³¼ Cortesê°€ í˜„ëŒ€ì  ì˜ë¯¸ì˜ SVM ì•Œê³ ë¦¬ì¦˜ì„ ê³µì‹í™”í•¨. ì´ ë…¼ë¬¸ì€ "Support-Vector Networks"ë¼ëŠ” ì œëª©ìœ¼ë¡œ ë°œí‘œë˜ë©°, **ë§ˆì§„ ìµœëŒ€í™”**ì™€ \*\*ì»¤ë„ íŠ¸ë¦­(Kernel Trick)\*\*ì„ í†µí•´ ë¹„ì„ í˜• ë¶„ë¥˜ê¹Œì§€ í™•ì¥ë¨.
* **2000ë…„ëŒ€**: Bioinformatics, ë¬¸ì„œ ë¶„ë¥˜, ì´ë¯¸ì§€ ì¸ì‹ ë“± ë‹¤ì–‘í•œ ë¶„ì•¼ì—ì„œ **ê³ ì°¨ì› ì†Œê·œëª¨ ë°ì´í„°**ì— ê°•í•œ ë¶„ë¥˜ê¸°ë¡œ ë„ë¦¬ í™œìš©ë¨.

## 2. SVMì˜ í•µì‹¬ ì•„ì´ë””ì–´

* **ë§ˆì§„ ìµœëŒ€í™”**: í´ë˜ìŠ¤ë¥¼ êµ¬ë¶„í•˜ëŠ” **ê²°ì • ê²½ê³„**(Decision Boundary) ì¤‘, ê°€ì¥ \*\*ë„“ì€ ì—¬ë°±(Margin)\*\*ì„ ê°€ì§€ëŠ” ì„ í˜• ê²°ì • ê²½ê³„ë¥¼ ì°¾ìŒ.
* **ì„œí¬íŠ¸ ë²¡í„°**: ê²°ì • ê²½ê³„ì— ê°€ì¥ ê°€ê¹Œìš´ ë°ì´í„° í¬ì¸íŠ¸.
* **ì»¤ë„ ê¸°ë²•**: ë¹„ì„ í˜• ë°ì´í„°ë¥¼ ê³ ì°¨ì›ìœ¼ë¡œ ë§¤í•‘í•˜ì—¬ ì„ í˜• ë¶„ë¦¬ ê°€ëŠ¥í•˜ê²Œ ë§Œë“œëŠ” ë°©ë²•.


## 3. ìˆ˜í•™ì  ìˆ˜ì‹

### ëª©ì : ìµœëŒ€ ë§ˆì§„ ë¶„ë¦¬ ì´ˆí‰ë©´ ì°¾ê¸°

ì„ í˜• SVMì˜ ëª©ì ì€ ë‹¤ìŒê³¼ ê°™ì€ ì´ˆí‰ë©´ì„ ì°¾ëŠ” ê²ƒì…ë‹ˆë‹¤.

$$
\mathbf{w}^\top \mathbf{x} + b = 0
$$

í´ë˜ìŠ¤ëŠ” ë‹¤ìŒ ì¡°ê±´ì„ ë§Œì¡±í•´ì•¼ í•©ë‹ˆë‹¤:

$$
y_i (\mathbf{w}^\top \mathbf{x}_i + b) \geq 1 \quad \forall i
$$

### ìµœì í™” ë¬¸ì œ

$$
\min_{\mathbf{w}, b} \frac{1}{2} \|\mathbf{w}\|^2 \quad \text{subject to} \quad y_i(\mathbf{w}^\top \mathbf{x}_i + b) \geq 1
$$

ì´ ë¬¸ì œëŠ” **Convex Quadratic Programming** í˜•íƒœì´ë©°, Lagrange multiplier ê¸°ë²•ìœ¼ë¡œ ìµœì í™”ë©ë‹ˆë‹¤.

### ğŸ”„ ë¹„ì„ í˜• SVM (Kernel Trick)

$$
\phi(\mathbf{x})^\top \phi(\mathbf{x'}) = K(\mathbf{x}, \mathbf{x'})
$$

* ëŒ€í‘œ ì»¤ë„: ì„ í˜•(linear), ë‹¤í•­ì‹(polynomial), RBF(Gaussian), ì‹œê·¸ëª¨ì´ë“œ(sigmoid)

---

# ğŸ“˜ 7ì¥. ì˜ì‚¬ê²°ì •ë‚˜ë¬´ (Decision Tree) ì•Œê³ ë¦¬ì¦˜

## 1. ì—­ì‚¬ì  ë°°ê²½

* **1960ë…„ëŒ€**: í†µê³„í•™ ë¶„ì•¼ì—ì„œ ë¶„ë¥˜ ë° íšŒê·€ë¥¼ ìœ„í•œ íŠ¸ë¦¬ ê¸°ë°˜ ëª¨ë¸ì´ ì—°êµ¬ë˜ê¸° ì‹œì‘í•¨.
* **1986ë…„**: **J. Ross Quinlan**ì´ ë°œí‘œí•œ **ID3(Iterative Dichotomiser 3)** ì•Œê³ ë¦¬ì¦˜ì´ ë„ë¦¬ ì£¼ëª©ë°›ìœ¼ë©° ì˜ì‚¬ê²°ì •ë‚˜ë¬´ ì•Œê³ ë¦¬ì¦˜ì˜ í‘œì¤€ì´ ë¨.
* ì´í›„ **C4.5**(1993), **CART(Classification and Regression Tree)**(Breiman et al., 1984) ë“± ë‹¤ì–‘í•œ ë²„ì „ì´ ê°œë°œë¨.
* í˜„ì¬ëŠ” **Random Forest**, **XGBoost** ë“±ì˜ ì•™ìƒë¸” ê¸°ë°˜ íŠ¸ë¦¬ ëª¨ë¸ì˜ ê¸°ë³¸ ë‹¨ìœ„ë¡œë„ ì‚¬ìš©ë¨.


## 2. ì´ë¡ ì  ê°œë…

### ê¸°ë³¸ ì•„ì´ë””ì–´

ì˜ì‚¬ê²°ì •ë‚˜ë¬´ëŠ” ë°ì´í„°ë¥¼ \*\*íŠ¹ì„±(feature)\*\*ì— ë”°ë¼ ë¶„í• (split)í•˜ì—¬ **íŠ¸ë¦¬ í˜•íƒœë¡œ ë¶„ë¥˜** ë˜ëŠ” **ì˜ˆì¸¡**ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

* ë£¨íŠ¸ ë…¸ë“œ: ì „ì²´ ë°ì´í„°
* ë‚´ë¶€ ë…¸ë“œ: íŠ¹ì„± ê¸°ì¤€ìœ¼ë¡œ ë°ì´í„°ë¥¼ ë¶„í• 
* ë¦¬í”„ ë…¸ë“œ: ìµœì¢… ì˜ˆì¸¡ ê²°ê³¼(í´ë˜ìŠ¤ or ìˆ˜ì¹˜ ê°’)


### ë¶„í•  ê¸°ì¤€ (ì§€ë‹ˆ, ì—”íŠ¸ë¡œí”¼, ë¶„ì‚°)

#### (1) **ë¶„ë¥˜(Classification)** ë¬¸ì œ:

* **ì§€ë‹ˆ ë¶ˆìˆœë„(Gini Impurity)**

  $$
  Gini = 1 - \sum_{i=1}^n p_i^2
  $$
* **ì—”íŠ¸ë¡œí”¼(Entropy)**

  $$
  Entropy = - \sum_{i=1}^n p_i \log_2 p_i
  $$

â†’ ë‘ ê¸°ì¤€ ëª¨ë‘ ë¶ˆìˆœë„(í˜¼í•©ë„)ë¥¼ ìµœì†Œí™”í•˜ë„ë¡ ë¶„í• í•©ë‹ˆë‹¤.

#### (2) **íšŒê·€(Regression)** ë¬¸ì œ:

* **MSE (Mean Squared Error)** ë˜ëŠ” **MAE**ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¶„í• 

---

###  ê°€ì§€ì¹˜ê¸° (Pruning)

* **ì‚¬ì „ ê°€ì§€ì¹˜ê¸° (Pre-pruning)**: ê¹Šì´ ì œí•œ, ìµœì†Œ ë…¸ë“œ ìˆ˜ ì„¤ì • ë“±
* **ì‚¬í›„ ê°€ì§€ì¹˜ê¸° (Post-pruning)**: íŠ¸ë¦¬ë¥¼ ì™„ì„±í•œ í›„ ë¶ˆí•„ìš”í•œ ë…¸ë“œë¥¼ ì œê±°í•˜ì—¬ ê³¼ì í•© ë°©ì§€

---

## 3. ì•Œê³ ë¦¬ì¦˜ ìš”ì•½

1. ë£¨íŠ¸ ë…¸ë“œì—ì„œ ì‹œì‘
2. ê° íŠ¹ì„±ì— ëŒ€í•´ ìµœì  ë¶„í•  ê¸°ì¤€ì„ í‰ê°€ (ì§€ë‹ˆ, ì—”íŠ¸ë¡œí”¼ ë“±)
3. ê°€ì¥ ë¶ˆìˆœë„ë¥¼ ë§ì´ ì¤„ì´ëŠ” íŠ¹ì„±ìœ¼ë¡œ ë¶„í• 
4. ë¦¬í”„ ë…¸ë“œê°€ ë  ì¡°ê±´(ìˆœë„ê°€ ë†’ê±°ë‚˜ ìµœëŒ€ ê¹Šì´ ë„ë‹¬ ë“±)ê¹Œì§€ ë°˜ë³µ
5. ì˜ˆì¸¡ì€ ë¦¬í”„ ë…¸ë“œì˜ í´ë˜ìŠ¤(ë˜ëŠ” í‰ê· ê°’)ë¡œ ê²°ì •

---

# ğŸ“˜ 8ì¥. Random Forest ì•Œê³ ë¦¬ì¦˜


## 1. ì—­ì‚¬ì  ë°°ê²½

| í•­ëª©        | ë‚´ìš©                                                        |
| --------- | --------------------------------------------------------- |
| **ê³ ì•ˆì**   | ë ˆì˜¤ ë¸Œë ˆì´ë¨¼ (Leo Breiman), 2001ë…„ ë°œí‘œ                           |
| **ë…¼ë¬¸**    | â€œRandom Forestsâ€ (2001)                                   |
| **ê¸°ë°˜ ê°œë…** | ë°°ê¹…(Bagging: Bootstrap Aggregating) + ê²°ì • íŠ¸ë¦¬(Decision Tree) |
| **ê°œë°œ ëª©ì ** | ê°œë³„ ê²°ì •íŠ¸ë¦¬ì˜ ê³¼ì í•©(overfitting)ì„ ì¤„ì´ê³  ì˜ˆì¸¡ ì„±ëŠ¥ì„ í–¥ìƒì‹œí‚¤ê¸° ìœ„í•´            |

**ì´ì „ ë°°ê²½**

* 1996ë…„: Breimanì´ Bagging(ë°°ê¹…) ê¸°ë²• ì œì•ˆ
* ì´í›„, ì—¬ëŸ¬ ê°œì˜ ë°°ê¹…ëœ ê²°ì • íŠ¸ë¦¬ì— ë¬´ì‘ìœ„ì„±ì„ ë”í•´ **Random Forest**ë¡œ í™•ì¥

---

## 2. ì´ë¡ ì  ë°°ê²½

### í•µì‹¬ ê°œë…

**Random ForestëŠ” ì—¬ëŸ¬ ê°œì˜ Decision Treeë¥¼ í›ˆë ¨ì‹œí‚¨ ë’¤, ê° íŠ¸ë¦¬ì˜ ê²°ê³¼ë¥¼ ì¢…í•©í•˜ì—¬ ìµœì¢… ì˜ˆì¸¡ì„ ìˆ˜í–‰í•˜ëŠ” ì•™ìƒë¸” í•™ìŠµ ê¸°ë²•ì…ë‹ˆë‹¤.**

---

### ğŸ”· Bagging: Bootstrap Aggregating

* **Bootstrap**: ë°ì´í„°ì…‹ì—ì„œ **ì¤‘ë³µ í—ˆìš© ë¬´ì‘ìœ„ ìƒ˜í”Œë§**ìœ¼ë¡œ Nê°œì˜ í•™ìŠµìš© ìƒ˜í”Œ ìƒì„±
* **Aggregating**: ê°ê°ì˜ ëª¨ë¸ ê²°ê³¼ë¥¼ í‰ê· (íšŒê·€) ë˜ëŠ” íˆ¬í‘œ(ë¶„ë¥˜)ë¥¼ í†µí•´ ì¢…í•©

---

### ğŸ”· Randomness (ë¬´ì‘ìœ„ì„±) ë„ì…

1. **ë°ì´í„° ìƒ˜í”Œ ë¬´ì‘ìœ„ ì„ íƒ** (Bagging)
2. **ê° ë…¸ë“œì—ì„œ íŠ¹ì„±(feature) ë¬´ì‘ìœ„ ì„ íƒ** (ì˜ˆ: âˆšp ê°œ ì¤‘ ìµœì  ë¶„í•  íŠ¹ì„± ì„ íƒ)

ì´ ë‘ ê°€ì§€ ë¬´ì‘ìœ„ì„±ìœ¼ë¡œ ì¸í•´ **íŠ¸ë¦¬ ê°„ ìƒê´€ì„± ê°ì†Œ**, ê²°ê³¼ì ìœ¼ë¡œ **ì•™ìƒë¸” íš¨ê³¼ í–¥ìƒ** ë° **ê³¼ì í•© ê°ì†Œ** íš¨ê³¼ë¥¼ ì–»ìŒ.

---

### ğŸ”· ì•Œê³ ë¦¬ì¦˜ ë™ì‘ ê³¼ì •

1. **Tê°œì˜ ê²°ì • íŠ¸ë¦¬ ìƒì„±**

   * ê° íŠ¸ë¦¬ëŠ” Bootstrappingëœ ë°ì´í„°ë¡œ í•™ìŠµ
2. **ê° íŠ¸ë¦¬ì—ì„œ ë¬´ì‘ìœ„ í”¼ì²˜ ì„œë¸Œì…‹ ì„ íƒ**
3. **ê° íŠ¸ë¦¬ì˜ ê²°ê³¼ ì˜ˆì¸¡**

   * ë¶„ë¥˜: **ë‹¤ìˆ˜ê²° íˆ¬í‘œ(Majority Voting)**
   * íšŒê·€: **í‰ê· ê°’ ì‚°ì¶œ(Averaging)**


### ìš”ì•½ ë‹¤ì´ì–´ê·¸ë¨

```
                [ Training Set ]
                    â†“ Bootstrapping
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚              â”‚              â”‚              â”‚
[ Tree 1 ]     [ Tree 2 ]     [ Tree 3 ]   ...  [ Tree N ]
     â†“              â†“              â†“              â†“
[ ì˜ˆì¸¡ê°’ 1 ]   [ ì˜ˆì¸¡ê°’ 2 ]   [ ì˜ˆì¸¡ê°’ 3 ]   ...  [ ì˜ˆì¸¡ê°’ N ]
     â†“â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Aggregation â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†“
                [ ìµœì¢… ì˜ˆì¸¡ê°’ ]
```

---

### ğŸ”· ì£¼ìš” í•˜ì´í¼íŒŒë¼ë¯¸í„°

| í•˜ì´í¼íŒŒë¼ë¯¸í„°             | ì„¤ëª…                    |
| ------------------- | --------------------- |
| `n_estimators`      | ìƒì„±í•  íŠ¸ë¦¬ ê°œìˆ˜             |
| `max_features`      | ê° ë…¸ë“œ ë¶„í•  ì‹œ ê³ ë ¤í•  ìµœëŒ€ íŠ¹ì„± ìˆ˜ |
| `max_depth`         | ê° íŠ¸ë¦¬ì˜ ìµœëŒ€ ê¹Šì´           |
| `min_samples_split` | ë…¸ë“œë¥¼ ë¶„í• í•˜ê¸° ìœ„í•œ ìµœì†Œ ìƒ˜í”Œ ìˆ˜   |
| `bootstrap`         | ë¶€íŠ¸ìŠ¤íŠ¸ë© ìƒ˜í”Œ ì‚¬ìš© ì—¬ë¶€        |

---


## 3. ì¥ì  vs ë‹¨ì 

| ì¥ì                    | ë‹¨ì                  |
| -------------------- | ------------------ |
| ë†’ì€ ì˜ˆì¸¡ ì„±ëŠ¥             | í•´ì„ ì–´ë ¤ì›€ (ë¸”ë™ë°•ìŠ¤)      |
| ê³¼ì í•© ë°©ì§€ íš¨ê³¼            | ëŠë¦° í•™ìŠµ ì†ë„ (íŠ¸ë¦¬ê°€ ë§ìœ¼ë©´) |
| ë³€ìˆ˜ ì¤‘ìš”ë„ ì œê³µ ê°€ëŠ¥         | í° ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰          |
| ë²”ì£¼í˜•, ì—°ì†í˜• ë³€ìˆ˜ ëª¨ë‘ ì²˜ë¦¬ ê°€ëŠ¥ |                    |

---

## 4. í™œìš© ì˜ˆì‹œ

* **IoT**: ì„¼ì„œ ê³ ì¥ ì˜ˆì¸¡, ì¥ë¹„ ì´ìƒ íƒì§€
* **í—¬ìŠ¤ì¼€ì–´**: ì§ˆë³‘ ì§„ë‹¨ ë¶„ë¥˜
* **ê¸ˆìœµ**: ë¶€ë„ ìœ„í—˜ í‰ê°€
* **ì‚°ì—… ê³µì •**: ì˜ˆì§€ ì •ë¹„(Predictive Maintenance)

---
# ğŸ“˜ 9ì¥. XGBoost (eXtreme Gradient Boosting) ì•Œê³ ë¦¬ì¦˜

## **1. ì—­ì‚¬ì  ë°°ê²½**

### (1) ë¶€ìŠ¤íŒ… ì•Œê³ ë¦¬ì¦˜ì˜ íë¦„

| ì—°ë„     | ì•Œê³ ë¦¬ì¦˜                         | ì„¤ëª…                                   |
| ------ | ---------------------------- | ------------------------------------ |
| 1990ë…„ëŒ€ | AdaBoost                     | ê°€ì¥ ì²˜ìŒ ë„ë¦¬ ì‚¬ìš©ëœ ë¶€ìŠ¤íŒ… ëª¨ë¸. ê°€ì¤‘ì¹˜ ê¸°ë°˜ ë¶„ë¥˜ê¸° ì¡°í•©   |
| 2000ë…„ëŒ€ | Gradient Boosting (GBM)      | ì”ì°¨(residual)ì— ëŒ€í•œ ê¸°ìš¸ê¸°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì•½í•œ í•™ìŠµê¸° ì¶”ê°€ |
| 2014ë…„  | **XGBoost** (by Tianqi Chen) | GBMì˜ ë‹¨ì  ë³´ì™„ â†’ ì†ë„, ì„±ëŠ¥, ë³‘ë ¬ì„±ì—ì„œ í˜ì‹ ì  ê°œì„     |

> ğŸ“ ì°¸ê³ : XGBoostëŠ” **Kaggle** ë“±ì˜ ë¨¸ì‹ ëŸ¬ë‹ ê²½ì§„ëŒ€íšŒì—ì„œ ì••ë„ì  ì„±ëŠ¥ì„ ë³´ì—¬ì£¼ë©° ëŒ€ì¤‘ì ìœ¼ë¡œ ë„ë¦¬ í¼ì¡ŒìŠµë‹ˆë‹¤.

---

## **2. ì´ë¡ ì  ë°°ê²½**

### (1) Gradient Boostingì˜ ê¸°ë³¸ ê°œë…

* ëª©ì : ì—¬ëŸ¬ ê°œì˜ **ì•½í•œ í•™ìŠµê¸°(weak learner, ë³´í†µì€ ê²°ì • íŠ¸ë¦¬)** ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ í•™ìŠµí•˜ì—¬ ì ì  ì˜ˆì¸¡ë ¥ì„ ë†’ì„.
* ë°©ì‹: ì´ì „ ëª¨ë¸ì´ ë§Œë“  **ì˜¤ì°¨(ì”ì°¨)** ë¥¼ ì˜ˆì¸¡í•˜ë„ë¡ ë‹¤ìŒ ëª¨ë¸ì„ í›ˆë ¨

#### ê¸°ë³¸ ìˆ˜ì‹

ëª¨ë¸ì˜ ì˜ˆì¸¡ê°’ì„ $F(x)$ë¼ í•  ë•Œ, ì´ë¥¼ ë°˜ë³µì ìœ¼ë¡œ ê°±ì‹ :

$$
F_{m}(x) = F_{m-1}(x) + \gamma h_m(x)
$$

* $h_m(x)$: í˜„ì¬ ë‹¨ê³„ì—ì„œ í•™ìŠµí•˜ëŠ” ìƒˆë¡œìš´ íŠ¸ë¦¬
* $\gamma$: í•™ìŠµë¥  (learning rate)

---

### (2) XGBoostì˜ í•µì‹¬ ì•„ì´ë””ì–´

XGBoostëŠ” ê¸°ì¡´ Gradient Boostingì˜ ì•½ì ì„ ë³´ì™„í•˜ë©´ì„œ **ì†ë„ì™€ ì •í™•ë„ë¥¼ ê·¹ëŒ€í™”**í•˜ëŠ” ë° ì´ˆì ì„ ë§ì¶˜ ì•Œê³ ë¦¬ì¦˜ì…ë‹ˆë‹¤.

#### ğŸ”§ ê°œì„  ìš”ì†Œ

| ìš”ì†Œ              | ì„¤ëª…                          |
| --------------- | --------------------------- |
| **ì •ê·œí™” ì¶”ê°€**      | ê³¼ì í•© ë°©ì§€ë¥¼ ìœ„í•´ **L1/L2** ì •ê·œí™” í¬í•¨ |
| **ë³‘ë ¬ íŠ¸ë¦¬ ìƒì„±**    | íŠ¸ë¦¬ì˜ ë…¸ë“œë¥¼ ë³‘ë ¬ë¡œ ë¶„í• í•˜ì—¬ ì—°ì‚° ì†ë„ í–¥ìƒ   |
| **íˆìŠ¤í† ê·¸ë¨ ê¸°ë°˜ í•™ìŠµ** | ì—°ì†ê°’ì„ ì´ì‚°í™”í•˜ì—¬ í•™ìŠµ íš¨ìœ¨ í–¥ìƒ         |
| **ìŠ¤íŒŒìŠ¤ ë°ì´í„° ì²˜ë¦¬**  | ê²°ì¸¡ê°’ì„ ìë™ ê°ì§€í•˜ì—¬ ìµœì  ë¶„ê¸° ìƒì„±       |
| **Cache ìµœì í™”**   | ë‚´ë¶€ ë©”ëª¨ë¦¬ ì ‘ê·¼ ìµœì í™”ë¡œ ë¹ ë¥¸ ì—°ì‚°        |

---

### (3) XGBoostì˜ ëª©ì  í•¨ìˆ˜ (Objective Function)

XGBoostëŠ” ëª©ì  í•¨ìˆ˜ $Obj$ë¥¼ ë‹¤ìŒê³¼ ê°™ì´ ì •ì˜í•©ë‹ˆë‹¤:

$$
Obj = \sum_{i=1}^{n} l(y_i, \hat{y}_i) + \sum_{k=1}^{K} \Omega(f_k)
$$

* $l$: ì†ì‹¤ í•¨ìˆ˜ (ì˜ˆ: MSE, Log loss ë“±)
* $\Omega(f_k)$: ë³µì¡ë„ íŒ¨ë„í‹° (íŠ¸ë¦¬ì˜ ê¹Šì´, ë…¸ë“œ ìˆ˜ ë“±)

#### ë³µì¡ë„ í•­

$$
\Omega(f) = \gamma T + \frac{1}{2} \lambda \sum_{j=1}^{T} w_j^2
$$

* $T$: ë¦¬í”„ ë…¸ë“œì˜ ìˆ˜
* $w_j$: ë¦¬í”„ ë…¸ë“œì˜ ì¶œë ¥ ê°’
* $\gamma$, $\lambda$: ì •ê·œí™” ê³„ìˆ˜

---

### (4) XGBoost ì£¼ìš” í•˜ì´í¼íŒŒë¼ë¯¸í„°

| íŒŒë¼ë¯¸í„°                      | ì„¤ëª…                |
| ------------------------- | ----------------- |
| `n_estimators`            | ìƒì„±í•  íŠ¸ë¦¬ ìˆ˜          |
| `max_depth`               | íŠ¸ë¦¬ ìµœëŒ€ ê¹Šì´          |
| `learning_rate`           | ê° ë‹¨ê³„ì˜ ê¸°ì—¬ìœ¨         |
| `subsample`               | í›ˆë ¨ ìƒ˜í”Œ ë¹„ìœ¨ (ê³¼ì í•© ë°©ì§€) |
| `colsample_bytree`        | íŠ¸ë¦¬ë§ˆë‹¤ ì‚¬ìš©í•  íŠ¹ì„± ë¹„ìœ¨    |
| `reg_alpha`, `reg_lambda` | L1, L2 ì •ê·œí™” ê³„ìˆ˜     |

---
# 10ì¥. ë¶„ë¥˜ ëª¨ë¸ì— ëŒ€í•œ ì‹¤ìŠµ

## 1. ì‹¤ìŠµ ì½”ë“œ

```python
# 1. ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸°
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
import xgboost as xgb
import matplotlib.pyplot as plt
import seaborn as sns

# 2. ë°ì´í„° ë¡œë“œ
url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00601/ai4i2020.csv'
df = pd.read_csv(url)

# 3. ì „ì²˜ë¦¬
df.drop(['UDI', 'Product ID'], axis=1, inplace=True)
df['Type'] = df['Type'].map({'H': 0, 'L': 1, 'M': 2})
X = df[['Type', 'Air temperature [K]', 'Process temperature [K]',
        'Rotational speed [rpm]', 'Torque [Nm]', 'Tool wear [min]']]
X.columns = ['Type', 'AirTemp', 'ProcTemp', 'RotSpeed', 'Torque', 'ToolWear']
y = df['Machine failure']

print(X.head())

# 4. í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë¶„í• 
X_train, X_test, y_train, y_test = train_test_split(X, y,
                                                    test_size=0.2,
                                                    random_state=42,
                                                    stratify=y)

# 5. ì •ê·œí™” (kNN, SVMë§Œ ì‚¬ìš©)
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# 6. ëª¨ë¸ ì •ì˜
models = {
    "kNN": KNeighborsClassifier(),
    "SVM": SVC(),
    "Decision Tree": DecisionTreeClassifier(random_state=42),
    "Random Forest": RandomForestClassifier(random_state=42),
    "XGBoost": xgb.XGBClassifier(eval_metric='logloss', random_state=42)
}

# 7. ê²°ê³¼ ì €ì¥
results = {}

# 8. í•™ìŠµ ë° ì˜ˆì¸¡
for name, model in models.items():
    if name in ['kNN', 'SVM']:
        model.fit(X_train_scaled, y_train)
        y_pred = model.predict(X_test_scaled)
    else:
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)

    cm = confusion_matrix(y_test, y_pred)
    cr = classification_report(y_test, y_pred, output_dict=True)
    results[name] = {
        "confusion_matrix": cm,
        "classification_report": cr
    }

# 9. í˜¼ë™ í–‰ë ¬ ì‹œê°í™”
fig, axes = plt.subplots(2, 3, figsize=(12, 8))
axes = axes.flatten()

for ax, (name, result) in zip(axes, results.items()):
    sns.heatmap(result["confusion_matrix"], annot=True, fmt='d', cmap='Blues', ax=ax)
    ax.set_title(f"{name} Confusion Matrix")
    ax.set_xlabel("Predicted")
    ax.set_ylabel("Actual")

plt.tight_layout()
plt.show()

# 10. ì„±ëŠ¥ ì¶œë ¥
for name, result in results.items():
    print(f"\n===== {name} =====")
    print("Confusion Matrix:")
    print(result["confusion_matrix"])
    print("\nClassification Report:")
    print(pd.DataFrame(result["classification_report"]).transpose())
```

## 2. íŠ¹ì§• ì¤‘ìš”ë„

```python
# 11. ì¤‘ìš”ë„ ì¶”ì¶œ ë° ë¹„êµ
features = X.columns
dt_importance = models['Decision Tree'].feature_importances_
rf_importance = models['XGBoost'].feature_importances_

# 12. ì‹œê°í™”
import numpy as np
fig, ax = plt.subplots(figsize=(10, 6))
x = np.arange(len(features))
width = 0.35

bars1 = ax.bar(x - width/2, dt_importance, width, label='Decision Tree')
bars2 = ax.bar(x + width/2, rf_importance, width, label='Random Forest')

# ìƒë‹¨ì— ê°’ í‘œì‹œ
for bar in bars1 + bars2:
    height = bar.get_height()
    ax.annotate(f'{height:.2f}', xy=(bar.get_x() + bar.get_width()/2, height),
                xytext=(0, 3), textcoords="offset points", ha='center', va='bottom', fontsize=9)

# ê·¸ë˜í”„ ì„¤ì •
ax.set_ylabel("Feature Importance")
ax.set_title("Feature Importance: Decision Tree vs Random Forest")
ax.set_xticks(x)
ax.set_xticklabels(features, rotation=45)
ax.legend()
plt.tight_layout()
plt.show()

>>>>>>> 6759c28b4288f0c35ae1f2157cef39a269f336a9
```